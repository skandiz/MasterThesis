{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib  import cm\n",
    "import matplotlib.animation\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from scipy.spatial import KDTree, cKDTree\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import joblib\n",
    "import time\n",
    "from numba_progress import ProgressBar\n",
    "from tqdm import tqdm\n",
    "import trackpy as tp\n",
    "from numba import njit, prange\n",
    "\n",
    "from yupi import Trajectory\n",
    "import yupi.graphics as yg\n",
    "import yupi.stats as ys\n",
    "\n",
    "from utility import get_imsd, get_imsd_windowed, get_emsd, get_emsd_windowed, fit_hist, MB_2D,\\\n",
    "                    normal_distr, lorentian_distr, get_trajs, speed_windowed, theta_windowed, \\\n",
    "                    get_smooth_trajs, get_velocities\n",
    "\n",
    "show_verb = False\n",
    "save_verb = True\n",
    "anim_show_verb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>mass</th>\n",
       "      <th>size</th>\n",
       "      <th>ecc</th>\n",
       "      <th>signal</th>\n",
       "      <th>raw_mass</th>\n",
       "      <th>ep</th>\n",
       "      <th>frame</th>\n",
       "      <th>particle</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.735232</td>\n",
       "      <td>417.068536</td>\n",
       "      <td>6831.555216</td>\n",
       "      <td>10.518919</td>\n",
       "      <td>0.017850</td>\n",
       "      <td>12.622410</td>\n",
       "      <td>70005.0</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#8B0E71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>529.175095</td>\n",
       "      <td>508.570095</td>\n",
       "      <td>7479.073073</td>\n",
       "      <td>10.578953</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>14.155974</td>\n",
       "      <td>74285.0</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>#53BF7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528.655276</td>\n",
       "      <td>559.415666</td>\n",
       "      <td>7042.243300</td>\n",
       "      <td>10.341892</td>\n",
       "      <td>0.035362</td>\n",
       "      <td>15.689538</td>\n",
       "      <td>72910.0</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>#3706D8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536.996577</td>\n",
       "      <td>765.536854</td>\n",
       "      <td>7202.087843</td>\n",
       "      <td>10.486024</td>\n",
       "      <td>0.053956</td>\n",
       "      <td>14.391907</td>\n",
       "      <td>75383.0</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>#5C524E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>555.453979</td>\n",
       "      <td>172.020692</td>\n",
       "      <td>7593.854431</td>\n",
       "      <td>10.570402</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>14.038008</td>\n",
       "      <td>77709.0</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>#440066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y           x         mass       size       ecc     signal  \\\n",
       "0  171.735232  417.068536  6831.555216  10.518919  0.017850  12.622410   \n",
       "1  529.175095  508.570095  7479.073073  10.578953  0.014188  14.155974   \n",
       "2  528.655276  559.415666  7042.243300  10.341892  0.035362  15.689538   \n",
       "3  536.996577  765.536854  7202.087843  10.486024  0.053956  14.391907   \n",
       "4  555.453979  172.020692  7593.854431  10.570402  0.016828  14.038008   \n",
       "\n",
       "   raw_mass        ep  frame  particle    color  \n",
       "0   70005.0  0.001334      0         0  #8B0E71  \n",
       "1   74285.0  0.001096      0         1  #53BF7C  \n",
       "2   72910.0  0.001162      0         2  #3706D8  \n",
       "3   75383.0  0.001047      0         3  #5C524E  \n",
       "4   77709.0  0.000958      0         4  #440066  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDrops:50\n",
      "nFrames:32000 --> 3200.00 s\n",
      "window of 320.0 s, stride of 10.0 s\n",
      "number of steps: 288\n"
     ]
    }
   ],
   "source": [
    "rawTrajs = pd.read_parquet(\"../tracking/results/tracking_data/trackpy_pre_merge.parquet\")\n",
    "\n",
    "n = max(rawTrajs.particle)\n",
    "random.seed(5)\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "for i in range(max(rawTrajs.particle)+1-n):\n",
    "    colors.append(\"#00FFFF\")\n",
    "c = []\n",
    "for p in rawTrajs.particle:\n",
    "    c.append(colors[p])\n",
    "rawTrajs[\"color\"] = c\n",
    "display(rawTrajs.head())\n",
    "\n",
    "red_particle_idx = 17\n",
    "nDrops = len(rawTrajs.loc[rawTrajs.frame==0])\n",
    "nFrames = max(rawTrajs.frame) + 1\n",
    "print(f\"nDrops:{nDrops}\")\n",
    "print(f\"nFrames:{nFrames} --> {nFrames/10:.2f} s\")\n",
    "\n",
    "\n",
    "# WINDOWED ANALYSIS PARAMETERS\n",
    "window = 3200 # 320 s\n",
    "stride = 100 # 10 s\n",
    "print(f\"window of {window/10} s, stride of {stride/10} s\")\n",
    "startFrames = np.arange(0, nFrames-window, stride, dtype=int)\n",
    "endFrames = startFrames + window\n",
    "nSteps = len(startFrames)\n",
    "print(f\"number of steps: {nSteps}\")\n",
    "\n",
    "\n",
    "# step 10 with a 10 fps video --> 1 s\n",
    "units = \"px/s\"\n",
    "default_kwargs_blue = {\"color\": \"#00FFFF\", \"ec\": (0, 0, 0, 0.6), \"density\": True}\n",
    "default_kwargs_red = {\"color\": \"#EE4B2B\", \"ec\": (0, 0, 0, 0.6), \"density\": True}\n",
    "    \n",
    "maxLagtime = 1000\n",
    "#x = np.arange(0.1, 100.1, 0.1) # without initial point\n",
    "x = np.arange(0, 100, 0.1) # with initial point\n",
    "\n",
    "blueTrajs, redTraj = get_trajs(nDrops, red_particle_idx, rawTrajs)\n",
    "\n",
    "# Trajectory Smoothing: using a Savgol Filter in order to drop the noise due to the tracking procedure\n",
    "smoothTrajs = get_smooth_trajs(rawTrajs, nDrops, 30, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW UPDATES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 100 frames from the trajectory of  particle id = 10\n",
    "test = smoothTrajs.loc[(smoothTrajs.frame.between(0, 30000)) & (smoothTrajs.particle == 10)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6, 6))\n",
    "scatter = ax.scatter(test.x, test.y, c = np.arange(0, 30001, 1), s = .1, cmap = cm.jet)\n",
    "ax.set(xlabel=\"x [px]\", ylabel=\"y [px]\", title = \"Trajectory of particle id = 10\", xlim=(0, 900), ylim=(0, 900))\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "ax.legend(*scatter.legend_elements(), title = \"Time\", fontsize = 8, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECK BALLISTIC REGIME BETWEEN 0-1 S - FOR SMOOTH TRAJECTORIES\n",
    "\n",
    "note that ballistic motion msd has pw exponent 2 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 10000, 0.1)\n",
    "y = 10*x + 2*x**2\n",
    "# compute msd\n",
    "max_lagtime = 1000\n",
    "msd = np.zeros(max_lagtime-1)\n",
    "for lagtime in range(1, max_lagtime):\n",
    "    msd[lagtime-1] = np.mean((y[lagtime:] - y[:-lagtime])**2 + (x[lagtime:] - x[:-lagtime])**2)\n",
    "# fit msd with power law\n",
    "def power_law(x, a, b):\n",
    "    return a*x**b\n",
    "popt, pcov = curve_fit(power_law, np.arange(1, max_lagtime), msd, p0 = (1, 1))\n",
    "print(f\"fit parameters: {popt}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6, 6))\n",
    "ax.plot(np.arange(1, max_lagtime), msd)\n",
    "ax.set(xlabel=\"lagtime\", ylabel=\"msd\", title = \"MSD of a parabola\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxDimension = 1 # has to be fixed \n",
    "fps = 10 # fps of the video\n",
    "maxLagtime = 1000 # maximum lagtime to be considered\n",
    "#x = np.array(imsd[1:].index)\n",
    "x = np.arange(1., 100.1, .1)\n",
    "imsd, fit, pw_exp, fit_ball, pw_exp_ball = get_imsd(smoothTrajs, pxDimension, fps, maxLagtime, nDrops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(2, 1, figsize = (8, 4))\n",
    "ax.plot(imsd.index, imsd, '.',  markersize = 1)\n",
    "ax.plot(imsd[:1].index, fit_ball.T, linewidth = 1)\n",
    "ax.plot(imsd[1:].index, fit.T, linewidth = 1)\n",
    "ax.set(xlabel=\"lag time [s]\", ylabel=\"MSD [px$^2$]\", xscale = \"log\", yscale = \"log\", xlim=(0.01, 10))\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "\n",
    "ax1.errorbar(np.arange(0, nDrops, 1), pw_exp_ball[:, 0, 1], yerr = pw_exp_ball[:, 1, 0], fmt = '.', markersize = 5, label = \"ballistic\")\n",
    "ax1.errorbar(np.arange(0, nDrops, 1), pw_exp[:, 0, 1], yerr = pw_exp_ball[:, 1, 0], fmt = '.', markersize = 5, label = \"diffusive\")\n",
    "ax1.set(xlabel=\"Droplet ID\", ylabel=\"Pw exponent\")\n",
    "ax1.grid(True, linestyle='-', color = '0.75')\n",
    "ax1.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSD_b, MSD_r, diffusive_results, ballistic_results = get_emsd(imsd, x, red_particle_idx, nDrops)\n",
    "fit_b_ball, pw_exp_b_ball = ballistic_results[\"fit_b\"], ballistic_results[\"pw_exp_b\"]\n",
    "fit_b_diff, pw_exp_b_diff = diffusive_results[\"fit_b\"], diffusive_results[\"pw_exp_b\"]\n",
    "fit_r_ball, pw_exp_r_ball = ballistic_results[\"fit_r\"], ballistic_results[\"pw_exp_r\"]\n",
    "fit_r_diff, pw_exp_r_diff = diffusive_results[\"fit_r\"], diffusive_results[\"pw_exp_r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ball = [round(pw_exp_b_ball[0, 1], 3), round(pw_exp_b_ball[1, 1], 3)]\n",
    "b_ball = [round(pw_exp_r_ball[0, 1], 3), round(pw_exp_r_ball[1, 1], 3)]\n",
    "print(f\"Smooth trajs - Ballistic - Blue Particles: {a_ball[0]} ± {a_ball[1]}, Red Particle: {b_ball[0]} ± {b_ball[1]}\")\n",
    "\n",
    "a_diff = [round(pw_exp_b_diff[0, 1], 3), round(pw_exp_b_diff[1, 1], 3)]\n",
    "b_diff = [round(pw_exp_r_diff[0, 1], 3), round(pw_exp_r_diff[1, 1], 3)]\n",
    "print(f\"Smooth trajs - Diffusive - Blue Particles: {a_diff[0]} ± {a_diff[1]}, Red Particle: {b_diff[0]} ± {b_diff[1]}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 4))\n",
    "ax.plot(imsd.index, MSD_b[0], 'b-', label = \"Blue particles\") \n",
    "ax.plot(imsd[1:].index, fit_b_diff, 'b--', label = f\"Diffusive Region: {a_diff[0]} ± {a_diff[1]}\")\n",
    "ax.plot(imsd[:1].index, fit_b_ball, 'b:', label = f\"Ballistic Region: {a_ball[0]} ± {a_ball[1]}\")\n",
    "ax.fill_between(imsd.index, MSD_b[0] - MSD_b[1], MSD_b[0] + MSD_b[1], alpha=0.5, edgecolor='#00FFFF', facecolor='#F0FFFF')\n",
    "ax.plot(imsd.index, MSD_r, 'r-', label = \"Red particle\")\n",
    "ax.plot(imsd[1:].index, fit_r_diff, 'r--', label = f\"Diffusive Region: {b_diff[0]} ± {b_diff[1]}\")\n",
    "ax.plot(imsd[:1].index, fit_r_ball, 'r:', label = f\"Ballistic Region: {b_ball[0]} ± {b_ball[1]}\")\n",
    "ax.set(xscale = 'log', yscale = 'log', ylabel = r'$\\langle \\Delta r^2 \\rangle$ [$px^2$]',   \n",
    "        xlabel = 'lag time $t$ [s]', title = \"EMSD - Smooth Trajectories\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.savefig(\"./results/mean_squared_displacement/ballistic_region/EMSD_smoothTrajs.png\", bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROPLET SIZE VS THINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std droplet diameter per frame\n",
    "mean_d = 2*rawTrajs.groupby(\"frame\").mean()[\"size\"].values\n",
    "std_d = 2*rawTrajs.groupby(\"frame\").std()[\"size\"].values\n",
    "\n",
    "# mean and std droplet diameter per frame\n",
    "mean_d_wind = np.zeros(nSteps)\n",
    "std_d_wind = np.zeros(nSteps)\n",
    "for i, start in enumerate(startFrames):\n",
    "    mean_d_wind[i] = np.mean(mean_d[start:start+window])\n",
    "    std_d_wind[i] = np.std(mean_d[start:start+window])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (10, 5))\n",
    "ax.plot(np.arange(0, nFrames, 1)/10, mean_d)\n",
    "ax.fill_between(np.arange(0, nFrames, 1)/10, mean_d - std_d, mean_d + std_d, alpha=0.5)\n",
    "ax.set(xlabel = \"Time [s]\", ylabel = \"d [px]\", title = \"Droplet diameter over time\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 5))\n",
    "ax.plot(startFrames/10, mean_d_wind)\n",
    "ax.fill_between(startFrames/10, mean_d_wind - std_d_wind, mean_d_wind + std_d_wind, alpha=0.5)\n",
    "ax.set(xlabel = \"Window Time [s]\", ylabel = \"d [px]\", title = \"Droplet diameter over window time\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vs Velocity Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_verb = False\n",
    "run_windowed_analysis = False\n",
    "overwrite = False\n",
    "animated_plot_verb = False\n",
    "\n",
    "print(f\"Velocity Autocorrelation Analysis: show_verb = {show_verb}, run_windowed_analysis = {run_windowed_analysis}, animated_plot_verb = {animated_plot_verb}\")\n",
    "%run ./analysis_modules/velocity_autocorrelation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5), sharex = True, sharey = True)\n",
    "scatter = ax.scatter(vacf_b_wind[\"0\"], mean_d_wind, s = 10, c = startFrames/10, marker = 'o', cmap = cm.Blues)\n",
    "scatter1 = ax.scatter(vacf_r_wind[\"0\"], mean_d_wind, s = 10, c = startFrames/10, marker = 'o', cmap = cm.Reds)\n",
    "ax.set(title = \"Raw Trajs\", xlabel = r\"$\\sigma_v^2$\", ylabel = \"d [px]\" )\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "\n",
    "scatter2 = ax1.scatter(vacf_b_wind_smooth[\"0\"], mean_d_wind, s = 10, c = startFrames/10, marker = 'o', cmap = cm.Blues)\n",
    "scatter3 = ax1.scatter(vacf_r_wind_smooth[\"0\"], mean_d_wind, s = 10, c = startFrames/10, marker = 'o', cmap = cm.Reds)\n",
    "ax1.set(title = \"Smooth Trajs\", xlabel = r\"$\\sigma_v^2$\", ylabel = \"d [px]\")\n",
    "ax1.grid(True, linestyle='-', color = '0.75')\n",
    "\n",
    "fig.suptitle(\"Velocity Variance vs. Mean Distance\")\n",
    "fig.legend(*scatter3.legend_elements(), title = \"Window Time\", fontsize = 8, loc = 7)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=1)\n",
    "if save_verb: plt.savefig('./results/distance_scatterplots/v_variance.png', bbox_inches='tight')\n",
    "if show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vs Effective Temperature from velocity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_verb = False\n",
    "animated_plot_verb = False\n",
    "print(f\"Speed and Turning Angles Analysis: show_verb = {show_verb}, animated_plot_verb = {animated_plot_verb}\")\n",
    "%run ./analysis_modules/speed_and_turning_angles.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_T_speed_b = blue_fit_wind[:, 0]\n",
    "eff_T_speed_b_sigma = blue_fit_wind[:, 1]\n",
    "eff_T_speed_r = red_fit_wind[:, 0]\n",
    "eff_T_speed_r_sigma = red_fit_wind[:, 1]\n",
    "\n",
    "eff_T_speed_b_smooth = blue_fit_wind_smooth[:, 0]\n",
    "eff_T_speed_b_sigma_smooth = blue_fit_wind_smooth[:, 1]\n",
    "eff_T_speed_r_smooth = red_fit_wind_smooth[:, 0]\n",
    "eff_T_speed_r_sigma_smooth = red_fit_wind_smooth[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5), sharex = True, sharey = True)\n",
    "scatter = ax.scatter(eff_T_speed_b, mean_d_wind, s = 20, c = startFrames/10, marker = 'o', cmap = cm.Blues)\n",
    "scatter1 = ax.scatter(eff_T_speed_r, mean_d_wind, s = 20, c = startFrames/10, marker = 'o', cmap = cm.Reds)\n",
    "ax.set(title = \"Raw Trajs\", xlabel = r\"$T_{eff} \\; [??]$\", ylabel = \"d [px]\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "\n",
    "scatter2 = ax1.scatter(eff_T_speed_b_smooth, mean_d_wind, s = 20, c = startFrames/10, marker = 'o', cmap = cm.Blues)\n",
    "scatter3 = ax1.scatter(eff_T_speed_r_smooth, mean_d_wind, s = 20, c = startFrames/10, marker = 'o', cmap = cm.Reds)\n",
    "ax1.set(title = \"Smooth Trajs\", xlabel = r\"$T_{eff} \\; [??]$\", ylabel = \"d [px]\")\n",
    "ax1.grid(True, linestyle='-', color = '0.75')\n",
    "\n",
    "fig.suptitle(\"Effective Temperature vs. Mean Distance\")\n",
    "fig.legend(*scatter3.legend_elements(), title = \"Window Time\", fontsize = 8, loc=7)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=1)\n",
    "plt.tight_layout()\n",
    "if save_verb: plt.savefig('./results/distance_scatterplots/eff_T.png', bbox_inches='tight')\n",
    "if show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vs Power law exponent from msd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_verb = False\n",
    "run_windowed_analysis = False\n",
    "animated_plot_verb = False\n",
    "print(f\"MSD Analysis: show_verb = {show_verb}, run_windowed_analysis = {run_windowed_analysis}, animated_plot_verb = {animated_plot_verb}\")\n",
    "\n",
    "%run ./analysis_modules/msd.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_b = fit_dict[\"pw_exp_wind_b\"][:, 0, 1]\n",
    "pw_b_std = fit_dict[\"pw_exp_wind_b\"][:, 1, 1]\n",
    "pw_r = fit_dict[\"pw_exp_wind_r\"][:, 0, 1]\n",
    "pw_r_std = fit_dict[\"pw_exp_wind_r\"][:, 1, 1]\n",
    "\n",
    "pw_b_smooth = fit_dict_smooth[\"pw_exp_wind_b\"][:, 0, 1]\n",
    "pw_b_std_smooth = fit_dict_smooth[\"pw_exp_wind_b\"][:, 1, 1]\n",
    "pw_r_smooth = fit_dict_smooth[\"pw_exp_wind_r\"][:, 0, 1]\n",
    "pw_r_std_smooth = fit_dict_smooth[\"pw_exp_wind_r\"][:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5), sharex = True, sharey = True)\n",
    "scatter = ax.scatter(pw_b, mean_d_wind, s = 20, c = startFrames/10, marker = 'o', cmap = cm.Blues)\n",
    "scatter1 = ax.scatter(pw_r, mean_d_wind, s = 20, c = startFrames/10, marker = 'o', cmap = cm.Reds)\n",
    "ax.set(title = \"Raw Trajs\", xlabel =  \"pw exponent\", ylabel = \"d [px]\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "\n",
    "scatter2 = ax1.scatter(pw_b_smooth, mean_d_wind, s = 20, c = startFrames/10, marker = 'o', cmap = cm.Blues)\n",
    "scatter3 = ax1.scatter(pw_r_smooth, mean_d_wind, s = 20, c = startFrames/10, marker = 'o', cmap = cm.Reds)\n",
    "ax1.set(title = \"Smooth Trajs\", xlabel = \"pw exponent\", ylabel = \"d [px]\")\n",
    "ax1.grid(True, linestyle='-', color = '0.75')\n",
    "\n",
    "fig.suptitle(\"Power Law Exponent vs. Mean Distance\")\n",
    "fig.legend(*scatter3.legend_elements(), title = \"Window Time\", fontsize = 8, loc=7)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=1)\n",
    "plt.tight_layout()\n",
    "if save_verb: plt.savefig('./results/distance_scatterplots/pw_law.png', bbox_inches='tight')\n",
    "if show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def compute_bin(x, bin_edges):\n",
    "    # assuming uniform bins for now\n",
    "    n = bin_edges.shape[0] - 1\n",
    "    a_min = bin_edges[0]\n",
    "    a_max = bin_edges[-1]\n",
    "    # special case to mirror NumPy behavior for last bin\n",
    "    if x == a_max:\n",
    "        return n - 1 # a_max always in last bin\n",
    "    bin = int(n * (x - a_min) / (a_max - a_min))\n",
    "    if bin < 0 or bin >= n:\n",
    "        return None\n",
    "    else:\n",
    "        return bin\n",
    "@njit\n",
    "def numba_histogram(a, bin_edges, weights):\n",
    "    hist = np.zeros((len(bin_edges)-1,), dtype=np.intp)\n",
    "    for ind, x in enumerate(a):\n",
    "        bin = compute_bin(x, bin_edges)\n",
    "        if bin is not None:\n",
    "            hist[int(bin)] += weights[ind]\n",
    "    return hist\n",
    "\n",
    "@njit\n",
    "def numba_mean_ax0(a):\n",
    "    res = []\n",
    "    for i in prange(a.shape[1]):\n",
    "        res.append(a[:, i].mean())\n",
    "    return np.array(res)\n",
    "\n",
    "@njit(parallel = True, fastmath=True)\n",
    "def three_body_frame(coords, bList, sigma, hist_bins):\n",
    "    \"\"\"\n",
    "    Computes the three body distribution for a single frame\n",
    "    coords : array of shape (nDrops, 3)\n",
    "        The coordinates of the drops\n",
    "    bList : array of shape (nB)\n",
    "        The b values to compute the three body distribution for\n",
    "    sigma : float   \n",
    "        The standard deviation of the gaussian used to weight the three body distribution\n",
    "    hist_bins : array of shape (nBins)\n",
    "        The bins to compute the three body distribution for\n",
    "    Returns \n",
    "    ------- \n",
    "    mean_3_body : array of shape (nB, nBins)\n",
    "        The mean three body distribution for each b value\n",
    "    \"\"\"\n",
    "    res = np.ones((len(bList), len(hist_bins)-1))\n",
    "    three_body = np.ones((nDrops, len(hist_bins)-1))\n",
    "    angles = np.zeros(int((nDrops-1)*(nDrops-2)/2))\n",
    "    gauss_weights = np.zeros(int((nDrops-1)*(nDrops-2)/2))\n",
    "    for b_ind in prange(len(bList)):\n",
    "        b = bList[b_ind]\n",
    "        for i in prange(nDrops):\n",
    "            count = 0\n",
    "            r_i = coords[i]\n",
    "            for j in range(nDrops):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                r_ij = coords[j] - r_i\n",
    "                for k in range(j+1, nDrops):\n",
    "                    if k == i:\n",
    "                        continue\n",
    "                    r_ik = coords[k] - r_i\n",
    "                    angles[count] = np.arccos(np.dot(r_ij, r_ik) / (np.linalg.norm(r_ij) * np.linalg.norm(r_ik)))\n",
    "                    gauss_weights[count] = np.exp(-0.5*((np.linalg.norm(r_ij)-b)/sigma)**2) * np.exp(-0.5*((np.linalg.norm(r_ik)-b)/sigma)**2)\n",
    "                    count += 1\n",
    "            three_body[i] = numba_histogram(angles, hist_bins, gauss_weights)\n",
    "        res[b_ind] = numba_mean_ax0(three_body)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bList length:  800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "100%|██████████| 1/1 [01:44<00:00, 104.83s/it]\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    COORDS = np.array(rawTrajs.loc[:,[\"x\",\"y\"]])\n",
    "    bList = np.arange(0, 800, 1, dtype = int)\n",
    "    print(\"bList length: \", bList.shape[0])\n",
    "    sigma = 15\n",
    "    frames = np.arange(0, 10000, 10000, dtype = int)\n",
    "    nFrames = len(frames)\n",
    "\n",
    "    hist_bins = np.arange(0, np.pi, np.pi/100)\n",
    "    mean_3_body = np.zeros((nFrames, len(bList), len(hist_bins)-1))\n",
    "\n",
    "    for frame_ind in tqdm(range(nFrames)):\n",
    "        mean_3_body[frame_ind] = three_body_frame(COORDS[frames[frame_ind]:frames[frame_ind]+50], bList, sigma, hist_bins)\n",
    "            \n",
    "    # save to txt frames, bList and hist bins\n",
    "    if 0:\n",
    "        np.savetxt(\"./analysis_data/3_body/frames.txt\", frames)\n",
    "        np.savetxt(\"./analysis_data/3_body/bList.txt\", bList)\n",
    "        np.savetxt(\"./analysis_data/3_body/hist_bins.txt\", hist_bins)\n",
    "        for i, b in enumerate(bList):\n",
    "            temp = pd.DataFrame(mean_3_body[:, i])\n",
    "            temp.columns = [str(i) for i in temp.columns]\n",
    "            temp.to_parquet(f\"./analysis_data/3_body/mean_3_body_{b}.parquet\")\n",
    "else:\n",
    "    frames = np.loadtxt(\"./analysis_data/3_body/frames.txt\").astype(int)\n",
    "    nFrames = len(frames)\n",
    "    bList = np.loadtxt(\"./analysis_data/3_body/bList.txt\").astype(int)\n",
    "    hist_bins = np.loadtxt(\"./analysis_data/3_body/hist_bins.txt\")\n",
    "    mean_3_body = np.zeros((nFrames, len(bList), len(hist_bins)-1))\n",
    "    for i, b in enumerate(bList):\n",
    "        mean_3_body[:, i] = pd.read_parquet(f\"./analysis_data/3_body/mean_3_body_{int(b)}.parquet\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_3_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_centers = (hist_bins[:-1] + hist_bins[1:]) / 2\n",
    "frame = 5\n",
    "b_ind = 30\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 5))\n",
    "ax.plot(hist_centers, mean_3_body[frame, b_ind], label = f\"Drop {i}\")\n",
    "ax.set(title = f\"Three Body Angle Distribution - b = {bList[b_ind]}, frame = {frames[frame]}\", xlabel = \"Angle [rad]\", ylabel = \"Counts\")\n",
    "ax.grid(True, linestyle = '-', color = '0.75')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(mean_3_body!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "frame = 10\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax.imshow(counts[frame])\n",
    "ax.set(ylabel=\"b\", xlabel=\"angle\", title=f\"frame {frame}\")\n",
    "ax.set_xticklabels([f\"$\\pi$ /{i}\" for i in range(10)])\n",
    "ax.set_yticklabels(bList.astype(int))\n",
    "fig.colorbar(im, ax=ax)\n",
    "ax.set_aspect(1.8)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (5, 5))\n",
    "anim_running = True\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "im = ax.imshow(mean_3_body[0])\n",
    "ax.set(ylabel = \"b\", xlabel = \"angle\")\n",
    "title = ax.set_title(f\"frame: {0}\")\n",
    "\n",
    "ax.set_xticks(np.arange(0, len(hist_bins), 10))\n",
    "ax.set_xticklabels(np.round(hist_bins,1)[::10])\n",
    "ax.set_yticks(np.arange(0, len(bList), 10))\n",
    "ax.set_yticklabels(bList.astype(int)[::10])\n",
    "\n",
    "fig.colorbar(im, ax=ax)\n",
    "\n",
    "def animate_func(i):\n",
    "    im.set_array(mean_3_body[i])\n",
    "    title.set_text(f\"frame: {frames[i]}\")\n",
    "    return [im]\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate_func, nFrames, interval = 100)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUMULATIVE TURNING ANGLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFrames = max(smoothTrajs.frame)\n",
    "\n",
    "blueTrajs, redTraj_smooth = get_trajs(nDrops, red_particle_idx, smoothTrajs)\n",
    "theta_blue = np.zeros((nDrops-1, nFrames-1))\n",
    "for i in range(nDrops-1):\n",
    "    theta_blue[i] = ys.turning_angles_ensemble([blueTrajs[i]], centered = True, accumulate = False)\n",
    "theta_red = ys.turning_angles_ensemble(redTraj, centered = True, accumulate = False)\n",
    "\n",
    "# cumulative turning angles\n",
    "theta_blue_cum = np.cumsum(theta_blue, axis=1)\n",
    "theta_red_cum = np.cumsum(theta_red)\n",
    "\n",
    "fig, (ax,ax1) = plt.subplots(2, 1, figsize=(10, 5), sharex=True)\n",
    "ax.plot(np.arange(0, nFrames-1)/10, np.mean(theta_blue_cum, axis = 0), 'b-', label = \"Blue droplets\")\n",
    "ax.set(title = \"Cumulative turning angles\", ylabel = r\"$\\theta$ [rad]\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "ax.legend(loc = \"upper left\")\n",
    "ax1.plot(np.arange(0, nFrames-1)/10, theta_red_cum, 'r-', label = \"Red droplet\")\n",
    "ax1.set(xlabel = \"Time [s]\", ylabel = r\"$\\theta$ [rad]\")\n",
    "ax1.grid(True, linestyle='-', color = '0.75')\n",
    "ax1.legend(loc = \"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/turning_angles/cumulative_turning_angles.png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_legend_handles_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5), sharex=True)\n",
    "blue = ax.plot(np.arange(0, nFrames-1)/10, theta_blue_cum.T, linewidth = 0.5, alpha = 0.5, color = 'b')\n",
    "red = ax.plot(np.arange(0, nFrames-1)/10, theta_red_cum, 'r-')\n",
    "ax.set(title = \"Individual cumulative turning angles\", ylabel = r\"$\\theta$ [rad]\", xlabel = \"Time [s]\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "plt.savefig(\"./results/turning_angles/individual_cumulative_turning_angles.png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blueTrajs, redTraj_smooth = get_trajs(nDrops, red_particle_idx, smoothTrajs)\n",
    "theta_blue = np.zeros((nDrops-1, nFrames))\n",
    "for i in range(nDrops-1):\n",
    "    theta_blue[i] = ys.turning_angles_ensemble([blueTrajs[i]], centered = True, accumulate = True)\n",
    "theta_red = ys.turning_angles_ensemble(redTraj, centered = True, accumulate = True)\n",
    "\n",
    "fig, (ax,ax1) = plt.subplots(2, 1, figsize=(10, 5), sharex=True)\n",
    "ax.plot(np.arange(0, nFrames)/10, np.mean(theta_blue, axis = 0), 'b-', label = \"Blue droplets\")\n",
    "ax.set(title = \"Cumulative turning angles - with accumulate = True\", ylabel = r\"$\\theta$ [rad]\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "ax.legend(loc = \"upper left\")\n",
    "ax1.plot(np.arange(0, nFrames)/10, theta_red, 'r-', label = \"Red droplet\")\n",
    "ax1.set(xlabel = \"Time [s]\", ylabel = r\"$\\theta$ [rad]\")\n",
    "ax1.grid(True, linestyle='-', color = '0.75')\n",
    "ax1.legend(loc = \"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEAN SQUARED ANGULAR DIFFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msad(maxLagtime, r):\n",
    "    current_msd = np.empty(maxLagtime)\n",
    "    for lag_ in prange(1, maxLagtime + 1):\n",
    "        x_ = np.sum(r[lag_:] * r[:-lag_], axis=1) / (np.linalg.norm(r[lag_:], axis=1)*np.linalg.norm(r[:-lag_], axis=1))\n",
    "        temp = np.arccos( np.clip(x_, -1, 1) )\n",
    "        current_msd[lag_ - 1] = np.mean(temp)\n",
    "    return current_msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared angular displacement \n",
    "blueTrajs, redTraj = get_trajs(nDrops, red_particle_idx, rawTrajs)\n",
    "maxLagtime = 1000\n",
    "msad = np.empty((len(blueTrajs), maxLagtime))\n",
    "for i in tqdm(range(len(blueTrajs))):\n",
    "    r = np.array(blueTrajs[i].r)\n",
    "    current_msd = get_msad(maxLagtime, r)\n",
    "    msad[i] = current_msd\n",
    "msad_b = np.mean(msad, axis=0)\n",
    "msad_b_std = np.std(msad, axis=0)\n",
    "\n",
    "msad_r = get_msad(maxLagtime, np.array(redTraj[0].r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msad_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(1, maxLagtime+1, 1)/10, msad_b, 'b', label=\"blue\")\n",
    "ax.plot(np.arange(1, maxLagtime+1, 1)/10, msad_r, 'r', label=\"red\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set(xlabel=\"lag [s]\", ylabel=\"MSAD \", xscale=\"log\", yscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VELOCITY CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def get_corr(velocities, maxLagtime_):\n",
    "    xx = np.zeros((velocities.shape[0], maxLagtime_))\n",
    "    yy = np.zeros((velocities.shape[0], maxLagtime_))\n",
    "    xy = np.zeros((velocities.shape[0], maxLagtime_))\n",
    "    for i in prange(velocities.shape[0]):\n",
    "        v = velocities[i]\n",
    "        xx[i, 0] = np.corrcoef(v[0], v[0])[0, 1]\n",
    "        yy[i, 0] = np.corrcoef(v[1], v[1])[0, 1]\n",
    "        xy[i, 0] = np.corrcoef(v[0], v[1])[0, 1]\n",
    "        \n",
    "        for lag_ in prange(1, maxLagtime_):\n",
    "            xx[i, lag_] = np.corrcoef(v[0, :-lag_], v[0, lag_:])[0, 1]\n",
    "            yy[i, lag_] = np.corrcoef(v[1, :-lag_], v[1, lag_:])[0, 1]\n",
    "            xy[i, lag_] = np.corrcoef(v[0, :-lag_], v[1, lag_:])[0, 1]\n",
    "    return xx, yy, xy\n",
    "\n",
    "def corr_windowed(nSteps, maxLagtime, startFrames, endFrames, trajectories, red_particle_idx, nDrops):\n",
    "    corr_b = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_std_b = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_std_r = np.zeros((nSteps, 3, maxLagtime))\n",
    "\n",
    "    for k in tqdm(range(nSteps)):\n",
    "        trajs = trajectories.loc[trajectories.frame.between(startFrames[k], endFrames[k])]\n",
    "        blueTrajs, redTraj = get_trajs(nDrops, red_particle_idx, trajs)\n",
    "\n",
    "        res = np.array(get_corr(get_velocities(blueTrajs), maxLagtime))\n",
    "        corr_b[k], corr_std_b[k] = res.mean(axis=1), res.std(axis=1)\n",
    "        \n",
    "        res = np.array(get_corr(get_velocities(redTraj), maxLagtime))\n",
    "        corr_r[k], corr_std_r[k] = res.mean(axis=1), res.std(axis=1)\n",
    "\n",
    "    return corr_b, corr_std_b, corr_r, corr_std_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    maxLagtime = 300\n",
    "    corr_b, corr_std_b, corr_r, corr_std_r = corr_windowed(nSteps, maxLagtime, startFrames, endFrames, rawTrajs, red_particle_idx, nDrops)\n",
    "\n",
    "    windLenght = 10\n",
    "    polyOrder = 2\n",
    "    smoothTrajs = get_smooth_trajs(rawTrajs, nDrops, windLenght, polyOrder)\n",
    "    corr_b_smooth, corr_std_b_smooth, corr_r_smooth, corr_std_r_smooth = corr_windowed(nSteps, maxLagtime, startFrames, endFrames, smoothTrajs, red_particle_idx, nDrops)\n",
    "    if 1:\n",
    "        path = \"./analysis_data/corr/raw/\"\n",
    "        pd.DataFrame(corr_b[:,0]).to_csv(path+\"corr_b_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_b[:,1]).to_csv(path+\"corr_b_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_b[:,2]).to_csv(path+\"corr_b_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b[:,0]).to_csv(path+\"corr_std_b_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b[:,1]).to_csv(path+\"corr_std_b_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b[:,2]).to_csv(path+\"corr_std_b_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_r[:,0]).to_csv(path+\"corr_r_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_r[:,1]).to_csv(path+\"corr_r_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_r[:,2]).to_csv(path+\"corr_r_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r[:,0]).to_csv(path+\"corr_std_r_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r[:,1]).to_csv(path+\"corr_std_r_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r[:,2]).to_csv(path+\"corr_std_r_xy.csv\", index=False)\n",
    "\n",
    "        path = \"./analysis_data/corr/smooth/\"\n",
    "        text_file = open(path+\"specs.txt\", \"w\")\n",
    "        n = text_file.write(f'Window size: {windLenght}, polyorder: {polyOrder}')\n",
    "        text_file.close()\n",
    "\n",
    "        pd.DataFrame(corr_b_smooth[:,0]).to_csv(path+\"corr_b_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_b_smooth[:,1]).to_csv(path+\"corr_b_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_b_smooth[:,2]).to_csv(path+\"corr_b_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b_smooth[:,0]).to_csv(path+\"corr_std_b_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b_smooth[:,1]).to_csv(path+\"corr_std_b_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b_smooth[:,2]).to_csv(path+\"corr_std_b_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_r_smooth[:,0]).to_csv(path+\"corr_r_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_r_smooth[:,1]).to_csv(path+\"corr_r_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_r_smooth[:,2]).to_csv(path+\"corr_r_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r_smooth[:,0]).to_csv(path+\"corr_std_r_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r_smooth[:,1]).to_csv(path+\"corr_std_r_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r_smooth[:,2]).to_csv(path+\"corr_std_r_xy.csv\", index=False)\n",
    "else:\n",
    "    maxLagtime = 300\n",
    "    type_list = [\"x\", \"y\", \"xy\"]\n",
    "    path = \"./analysis_data/corr/raw/\"\n",
    "    corr_b = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_b_std = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r_std = np.zeros((nSteps, 3, maxLagtime))\n",
    "\n",
    "    for i in range(3):\n",
    "        corr_b[:, i] = pd.read_csv(path+f\"corr_b_{type_list[i]}.csv\").values\n",
    "        corr_b_std[:, i] = pd.read_csv(path+f\"corr_std_b_{type_list[i]}.csv\").values\n",
    "        corr_r[:, i] = pd.read_csv(path+f\"corr_r_{type_list[i]}.csv\").values\n",
    "        corr_r_std[:, i] = pd.read_csv(path+f\"corr_std_r_{type_list[i]}.csv\").values\n",
    "\n",
    "    path = \"./analysis_data/corr/smooth/\"\n",
    "    corr_b_smooth = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_b_std_smooth = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r_smooth = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r_std_smooth = np.zeros((nSteps, 3, maxLagtime))\n",
    "    for i in range(3):\n",
    "        corr_b_smooth[:, i] = pd.read_csv(path+f\"corr_b_{type_list[i]}.csv\").values\n",
    "        corr_b_std_smooth[:, i] = pd.read_csv(path+f\"corr_std_b_{type_list[i]}.csv\").values\n",
    "        corr_r_smooth[:, i] = pd.read_csv(path+f\"corr_r_{type_list[i]}.csv\").values\n",
    "        corr_r_std_smooth[:, i] = pd.read_csv(path+f\"corr_std_r_{type_list[i]}.csv\").values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"Raw\"\n",
    "\n",
    "if type == \"Raw\":\n",
    "    corr_b_plot = corr_b\n",
    "    corr_r_plot = corr_r\n",
    "\n",
    "elif type == \"Smooth\":\n",
    "    corr_b_plot = corr_b_smooth\n",
    "    corr_r_plot = corr_r_smooth\n",
    "\n",
    "else:\n",
    "    print(\"Wrong type\")\n",
    "\n",
    "coord_list = [\"x\", \"y\", \"xy\"]\n",
    "\n",
    "fig = plt.figure(figsize = (8, 5))\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(step):\n",
    "    title.set_text(f\"Velocity autocorrelation - {type} Trajectories - window [{startFrames[step]/10} - {endFrames[step]/10}] s\")\n",
    "    for i in range(3):\n",
    "        graphs[i].set_ydata(corr_b_plot[step, i])  \n",
    "        graphs1[i].set_ydata(corr_b_plot[step, i])\n",
    "    return graphs, graphs1\n",
    "\n",
    "ax = fig.add_subplot(211)\n",
    "title = ax.set_title(f\"Velocity autocorrelation - {type} Trajectories - window [{startFrames[0]/10} - {endFrames[0]/10}] s\")\n",
    "graphs = []\n",
    "for i in range(3):\n",
    "    graphs.append(ax.plot(np.arange(0, maxLagtime, 1)/10, corr_b_plot[0, i], label = f\"{coord_list[i]}\")[0])\n",
    "ax.set(ylabel = r'vacf [$(px/s)^2$]', xlabel = 'lag time $t$ [s]', xlim = (-1, 10), ylim = (-0.5, 1))\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "ax1 = fig.add_subplot(212)\n",
    "graphs1 = []\n",
    "for i in range(3):\n",
    "    graphs1.append(ax1.plot(np.arange(0, maxLagtime, 1)/10, corr_r_smooth[0, i], label = f\"{type_list[i]}\")[0])\n",
    "ax1.set(ylabel = r'vacf [$(px/s)^2$]', xlabel = 'lag time $t$ [s]', xlim = (-1, 10), ylim = (-0.5, 1))\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, nSteps, interval = 5, blit=False)\n",
    "if 1:\n",
    "    ani.save(f'./results/corr/corr_{type.lower()}.mp4', fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "if 0:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# difference from raw trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_b, corr_std_b = get_corr(get_velocities(blueTrajs), maxLagtime)\n",
    "corr_r, corr_std_r = get_corr(get_velocities(redTraj), maxLagtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windList = np.linspace(3, 13, 10, dtype=int)\n",
    "\n",
    "corr_b_smooth = np.zeros((len(windList), 3, maxLagtime))\n",
    "corr_r_smooth = np.zeros((len(windList), 3, maxLagtime))\n",
    "corr_std_b_smooth = np.zeros((len(windList), 3, maxLagtime))\n",
    "corr_std_r_smooth = np.zeros((len(windList), 3, maxLagtime))\n",
    "                            \n",
    "for k in tqdm(range(10)):\n",
    "    smoothTrajs = get_smooth_trajs(rawTrajs, nDrops, windList[k], 2)\n",
    "    blueTrajs_smooth, redTraj_smooth = get_trajs(nDrops, red_particle_idx, smoothTrajs)\n",
    "    v_b_smooth = get_velocities(blueTrajs_smooth)\n",
    "\n",
    "    corr_b_smooth[k], corr_std_b_smooth[k] = get_corr(get_velocities(blueTrajs), maxLagtime)\n",
    "    corr_r_smooth[k], corr_std_r_smooth[k] = get_corr(get_velocities(redTraj), maxLagtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "for i in range(0, 10):\n",
    "    ax.plot(x, corr[0] - corr_smooth[i, 0], '-b', alpha = 1/(i+1))\n",
    "ax.set_xlim(-1, 4)\n",
    "#ax.legend()\n",
    "for i in range(0, 10):\n",
    "    ax1.plot(x, corr[1] - corr_smooth[i, 1], 'b', alpha = 1/(i+1))\n",
    "#ax1.legend()\n",
    "ax1.set_xlim(-1, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(x, A)\n",
    "ax[0].fill_between(x, A - A_std, A + A_std, alpha=0.2)\n",
    "ax[0].set(xlabel = \"lagtime [s]\", xlim=(-1, 20), title = \"x\")\n",
    "\n",
    "ax[1].plot(x, B, label=\"y\")\n",
    "ax[1].fill_between(x, B - B_std, B + B_std, alpha=0.2)\n",
    "ax[1].set(xlabel=\"lagtime [s]\" , ylabel = \"correlation\", xlim=(-1, 20), title = \"y\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(x, A_smooth)\n",
    "ax[0].fill_between(x, A_smooth - A_std_smooth, A_smooth + A_std_smooth, alpha=0.2)\n",
    "ax[0].set(xlabel = \"lagtime [s]\", xlim=(-1, 20), title = \"x\")\n",
    "\n",
    "ax[1].plot(x, B_smooth, label=\"y\")\n",
    "ax[1].fill_between(x, B_smooth - B_std_smooth, B_smooth + B_std_smooth, alpha=0.2)\n",
    "ax[1].set(xlabel=\"lagtime [s]\" , ylabel = \"correlation\", xlim=(-1, 20), title = \"y\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
