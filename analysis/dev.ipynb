{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import KDTree, cKDTree\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import joblib\n",
    "import time\n",
    "from numba_progress import ProgressBar\n",
    "from tqdm import tqdm\n",
    "import trackpy as tp\n",
    "from numba import njit, prange\n",
    "\n",
    "from yupi import Trajectory\n",
    "import yupi.graphics as yg\n",
    "import yupi.stats as ys\n",
    "\n",
    "from utility import get_imsd, get_imsd_windowed, get_emsd, get_emsd_windowed, fit_hist, MB_2D,\\\n",
    "                    normal_distr, get_trajs, speed_windowed, theta_windowed, get_smooth_trajs, get_velocities\n",
    "\n",
    "show_verb = False\n",
    "save_verb = True\n",
    "anim_show_verb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDrops:50\n",
      "nFrames:32000 --> 3200.00 s\n",
      "window of 320.0 s, stride of 10.0 s\n",
      "number of steps: 288\n"
     ]
    }
   ],
   "source": [
    "rawTrajs = pd.read_parquet(\"../tracking/results/parquet/pre_merge_tracking.parquet\")\n",
    "red_particle_idx = 17\n",
    "rawTrajs.loc[rawTrajs.particle != red_particle_idx, [\"color\"]] = \"#00007F\"\n",
    "rawTrajs.loc[rawTrajs.particle == red_particle_idx, [\"color\"]] = \"#FF0000\"\n",
    "colors = rawTrajs.loc[rawTrajs.frame == 0, 'color'].values\n",
    "nDrops = len(rawTrajs.loc[rawTrajs.frame==0])\n",
    "nFrames = max(rawTrajs.frame) + 1\n",
    "print(f\"nDrops:{nDrops}\")\n",
    "print(f\"nFrames:{nFrames} --> {nFrames/10:.2f} s\")\n",
    "\n",
    "\n",
    "# WINDOWED ANALYSIS PARAMETERS\n",
    "window = 3200 # 320 s\n",
    "stride = 100 # 10 s\n",
    "print(f\"window of {window/10} s, stride of {stride/10} s\")\n",
    "startFrames = np.arange(0, nFrames-window, stride, dtype=int)\n",
    "endFrames = startFrames + window\n",
    "nSteps = len(startFrames)\n",
    "print(f\"number of steps: {nSteps}\")\n",
    "\n",
    "\n",
    "# step 10 with a 10 fps video --> 1 s\n",
    "units = \"px/s\"\n",
    "default_kwargs_blue = {\"color\": \"#00FFFF\", \"ec\": (0, 0, 0, 0.6), \"density\": True}\n",
    "default_kwargs_red = {\"color\": \"#EE4B2B\", \"ec\": (0, 0, 0, 0.6), \"density\": True}\n",
    "    \n",
    "maxLagtime = 1000\n",
    "#x = np.arange(0.1, 100.1, 0.1) # without initial point\n",
    "x = np.arange(0, 100, 0.1) # with initial point\n",
    "\n",
    "blueTrajs, redTraj = get_trajs(nDrops, red_particle_idx, rawTrajs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEAN SQUARED ANGULAR DIFFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msad(maxLagtime, r):\n",
    "    current_msd = np.empty(maxLagtime)\n",
    "    for lag_ in prange(1, maxLagtime + 1):\n",
    "        x_ = np.sum(r[lag_:] * r[:-lag_], axis=1) / (np.linalg.norm(r[lag_:], axis=1)*np.linalg.norm(r[:-lag_], axis=1))\n",
    "        temp = np.arccos( np.clip(x_, -1, 1) )\n",
    "        current_msd[lag_ - 1] = np.mean(temp)\n",
    "    return current_msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared angular displacement \n",
    "blueTrajs, redTraj = get_trajs(nDrops, red_particle_idx, rawTrajs)\n",
    "maxLagtime = 1000\n",
    "msad = np.empty((len(blueTrajs), maxLagtime))\n",
    "for i in tqdm(range(len(blueTrajs))):\n",
    "    r = np.array(blueTrajs[i].r)\n",
    "    current_msd = get_msad(maxLagtime, r)\n",
    "    msad[i] = current_msd\n",
    "msad_b = np.mean(msad, axis=0)\n",
    "msad_b_std = np.std(msad, axis=0)\n",
    "\n",
    "msad_r = get_msad(maxLagtime, np.array(redTraj[0].r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(1, maxLagtime+1, 1)/10, msad_b, 'b', label=\"blue\")\n",
    "ax.plot(np.arange(1, maxLagtime+1, 1)/10, msad_r, 'r', label=\"red\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set(xlabel=\"lag [s]\", ylabel=\"MSAD \", xscale=\"log\", yscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VELOCITY CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def get_corr(velocities, maxLagtime_):\n",
    "    xx = np.zeros((velocities.shape[0], maxLagtime_))\n",
    "    yy = np.zeros((velocities.shape[0], maxLagtime_))\n",
    "    xy = np.zeros((velocities.shape[0], maxLagtime_))\n",
    "    for i in prange(velocities.shape[0]):\n",
    "        v = velocities[i]\n",
    "        xx[i, 0] = np.corrcoef(v[0], v[0])[0, 1]\n",
    "        yy[i, 0] = np.corrcoef(v[1], v[1])[0, 1]\n",
    "        xy[i, 0] = np.corrcoef(v[0], v[1])[0, 1]\n",
    "        \n",
    "        for lag_ in prange(1, maxLagtime_):\n",
    "            xx[i, lag_] = np.corrcoef(v[0, :-lag_], v[0, lag_:])[0, 1]\n",
    "            yy[i, lag_] = np.corrcoef(v[1, :-lag_], v[1, lag_:])[0, 1]\n",
    "            xy[i, lag_] = np.corrcoef(v[0, :-lag_], v[1, lag_:])[0, 1]\n",
    "    return xx, yy, xy\n",
    "\n",
    "def corr_windowed(nSteps, maxLagtime, startFrames, endFrames, trajectories, red_particle_idx, nDrops):\n",
    "    corr_b = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_std_b = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_std_r = np.zeros((nSteps, 3, maxLagtime))\n",
    "\n",
    "    for k in tqdm(range(nSteps)):\n",
    "        trajs = trajectories.loc[trajectories.frame.between(startFrames[k], endFrames[k])]\n",
    "        blueTrajs, redTraj = get_trajs(nDrops, red_particle_idx, trajs)\n",
    "\n",
    "        res = np.array(get_corr(get_velocities(blueTrajs), maxLagtime))\n",
    "        corr_b[k], corr_std_b[k] = res.mean(axis=1), res.std(axis=1)\n",
    "        \n",
    "        res = np.array(get_corr(get_velocities(redTraj), maxLagtime))\n",
    "        corr_r[k], corr_std_r[k] = res.mean(axis=1), res.std(axis=1)\n",
    "\n",
    "    return corr_b, corr_std_b, corr_r, corr_std_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    maxLagtime = 300\n",
    "    corr_b, corr_std_b, corr_r, corr_std_r = corr_windowed(nSteps, maxLagtime, startFrames, endFrames, rawTrajs, red_particle_idx, nDrops)\n",
    "\n",
    "    windLenght = 10\n",
    "    polyOrder = 2\n",
    "    smoothTrajs = get_smooth_trajs(rawTrajs, nDrops, windLenght, polyOrder)\n",
    "    corr_b_smooth, corr_std_b_smooth, corr_r_smooth, corr_std_r_smooth = corr_windowed(nSteps, maxLagtime, startFrames, endFrames, smoothTrajs, red_particle_idx, nDrops)\n",
    "    if 1:\n",
    "        path = \"./analysis_data/corr/raw/\"\n",
    "        pd.DataFrame(corr_b[:,0]).to_csv(path+\"corr_b_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_b[:,1]).to_csv(path+\"corr_b_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_b[:,2]).to_csv(path+\"corr_b_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b[:,0]).to_csv(path+\"corr_std_b_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b[:,1]).to_csv(path+\"corr_std_b_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b[:,2]).to_csv(path+\"corr_std_b_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_r[:,0]).to_csv(path+\"corr_r_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_r[:,1]).to_csv(path+\"corr_r_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_r[:,2]).to_csv(path+\"corr_r_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r[:,0]).to_csv(path+\"corr_std_r_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r[:,1]).to_csv(path+\"corr_std_r_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r[:,2]).to_csv(path+\"corr_std_r_xy.csv\", index=False)\n",
    "\n",
    "        path = \"./analysis_data/corr/smooth/\"\n",
    "        text_file = open(path+\"specs.txt\", \"w\")\n",
    "        n = text_file.write(f'Window size: {windLenght}, polyorder: {polyOrder}')\n",
    "        text_file.close()\n",
    "\n",
    "        pd.DataFrame(corr_b_smooth[:,0]).to_csv(path+\"corr_b_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_b_smooth[:,1]).to_csv(path+\"corr_b_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_b_smooth[:,2]).to_csv(path+\"corr_b_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b_smooth[:,0]).to_csv(path+\"corr_std_b_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b_smooth[:,1]).to_csv(path+\"corr_std_b_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_b_smooth[:,2]).to_csv(path+\"corr_std_b_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_r_smooth[:,0]).to_csv(path+\"corr_r_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_r_smooth[:,1]).to_csv(path+\"corr_r_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_r_smooth[:,2]).to_csv(path+\"corr_r_xy.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r_smooth[:,0]).to_csv(path+\"corr_std_r_x.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r_smooth[:,1]).to_csv(path+\"corr_std_r_y.csv\", index=False)\n",
    "        pd.DataFrame(corr_std_r_smooth[:,2]).to_csv(path+\"corr_std_r_xy.csv\", index=False)\n",
    "else:\n",
    "    type_list = [\"x\", \"y\", \"xy\"]\n",
    "    path = \"./analysis_data/corr/raw/\"\n",
    "    corr_b = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_b_std = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r_std = np.zeros((nSteps, 3, maxLagtime))\n",
    "\n",
    "    for i in range(3):\n",
    "        corr_b[:, i] = pd.read_csv(path+f\"corr_b_{type_list[i]}.csv\").values\n",
    "        corr_b_std[:, i] = pd.read_csv(path+f\"corr_std_b_{type_list[i]}.csv\").values\n",
    "        corr_r[:, i] = pd.read_csv(path+f\"corr_r_{type_list[i]}.csv\").values\n",
    "        corr_r_std[:, i] = pd.read_csv(path+f\"corr_std_r_{type_list[i]}.csv\").values\n",
    "\n",
    "    path = \"./analysis_data/corr/smooth/\"\n",
    "    corr_b_smooth = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_b_std_smooth = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r_smooth = np.zeros((nSteps, 3, maxLagtime))\n",
    "    corr_r_std_smooth = np.zeros((nSteps, 3, maxLagtime))\n",
    "    for i in range(3):\n",
    "        corr_b_smooth[:, i] = pd.read_csv(path+f\"corr_b_{type_list[i]}.csv\").values\n",
    "        corr_b_std_smooth[:, i] = pd.read_csv(path+f\"corr_std_b_{type_list[i]}.csv\").values\n",
    "        corr_r_smooth[:, i] = pd.read_csv(path+f\"corr_r_{type_list[i]}.csv\").values\n",
    "        corr_r_std_smooth[:, i] = pd.read_csv(path+f\"corr_std_r_{type_list[i]}.csv\").values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = [\"x\", \"y\", \"xy\"]\n",
    "for i in range(3):\n",
    "    fig = plt.figure(figsize = (8, 5))\n",
    "    anim_running = True\n",
    "\n",
    "    def onClick(event):\n",
    "        global anim_running\n",
    "        if anim_running:\n",
    "            ani.event_source.stop()\n",
    "            anim_running = False\n",
    "        else:\n",
    "            ani.event_source.start()\n",
    "            anim_running = True\n",
    "\n",
    "    def update_graph(step):\n",
    "        title.set_text(f\"Velocity autocorrelation {type_list[i]} - Raw Trajectories - window [{startFrames[step]/10} - {endFrames[step]/10}] s\")\n",
    "        line.set_ydata(corr_b[step, i])    \n",
    "        line1.set_ydata(corr_r[step, i])\n",
    "        line2.set_ydata(corr_b_smooth[step, i])\n",
    "        line3.set_ydata(corr_r_smooth[step, i])\n",
    "        return line, line1, line2, line3,\n",
    "\n",
    "    ax = fig.add_subplot(211)\n",
    "    title = ax.set_title(f\"Velocity autocorrelation - Raw Trajectories - window [{startFrames[0]/10} - {endFrames[0]/10}] s\")\n",
    "    line, = ax.plot(np.arange(0, maxLagtime, 1)/10, corr_b[0, i], 'b', label = \"blue\")\n",
    "    line1, = ax.plot(np.arange(0, maxLagtime, 1)/10, corr_r[0, i], 'r', label = \"red\")\n",
    "    ax.set(ylabel = r'vacf [$(px/s)^2$]', xlabel = 'lag time $t$ [s]', xlim = (-1, 10), ylim = (-0.5, 1))\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "\n",
    "    ax1 = fig.add_subplot(212)\n",
    "    ax1.set_title(f\"Smooth Trajectories\")\n",
    "    line2, = ax1.plot(np.arange(0, maxLagtime, 1)/10, corr_b_smooth[0, i], 'b', label = \"blue\")\n",
    "    line3, = ax1.plot(np.arange(0, maxLagtime, 1)/10, corr_r_smooth[0, i], 'r', label = \"red\")\n",
    "    ax1.set(ylabel = r'vacf [$(px/s)^2$]', xlabel = 'lag time $t$ [s]', xlim = (-1, 10), ylim = (-0.5, 1))\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "    ani = matplotlib.animation.FuncAnimation(fig, update_graph, nSteps, interval = 5, blit=False)\n",
    "    if save_verb: ani.save(f'./results/corr/corr_{type_list[i]}.mp4', fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "    if show_verb:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# difference from raw trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_b, corr_std_b = get_corr(get_velocities(blueTrajs), maxLagtime)\n",
    "corr_r, corr_std_r = get_corr(get_velocities(redTraj), maxLagtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windList = np.linspace(3, 13, 10, dtype=int)\n",
    "\n",
    "corr_b_smooth = np.zeros((len(windList), 3, maxLagtime))\n",
    "corr_r_smooth = np.zeros((len(windList), 3, maxLagtime))\n",
    "corr_std_b_smooth = np.zeros((len(windList), 3, maxLagtime))\n",
    "corr_std_r_smooth = np.zeros((len(windList), 3, maxLagtime))\n",
    "                            \n",
    "for k in tqdm(range(10)):\n",
    "    smoothTrajs = get_smooth_trajs(rawTrajs, nDrops, windList[k], 2)\n",
    "    blueTrajs_smooth, redTraj_smooth = get_trajs(nDrops, red_particle_idx, smoothTrajs)\n",
    "    v_b_smooth = get_velocities(blueTrajs_smooth)\n",
    "\n",
    "    corr_b_smooth[k], corr_std_b_smooth[k] = get_corr(get_velocities(blueTrajs), maxLagtime)\n",
    "    corr_r_smooth[k], corr_std_r_smooth[k] = get_corr(get_velocities(redTraj), maxLagtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "for i in range(0, 10):\n",
    "    ax.plot(x, corr[0] - corr_smooth[i, 0], '-b', alpha = 1/(i+1))\n",
    "ax.set_xlim(-1, 4)\n",
    "#ax.legend()\n",
    "for i in range(0, 10):\n",
    "    ax1.plot(x, corr[1] - corr_smooth[i, 1], 'b', alpha = 1/(i+1))\n",
    "#ax1.legend()\n",
    "ax1.set_xlim(-1, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(x, A)\n",
    "ax[0].fill_between(x, A - A_std, A + A_std, alpha=0.2)\n",
    "ax[0].set(xlabel = \"lagtime [s]\", xlim=(-1, 20), title = \"x\")\n",
    "\n",
    "ax[1].plot(x, B, label=\"y\")\n",
    "ax[1].fill_between(x, B - B_std, B + B_std, alpha=0.2)\n",
    "ax[1].set(xlabel=\"lagtime [s]\" , ylabel = \"correlation\", xlim=(-1, 20), title = \"y\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(x, A_smooth)\n",
    "ax[0].fill_between(x, A_smooth - A_std_smooth, A_smooth + A_std_smooth, alpha=0.2)\n",
    "ax[0].set(xlabel = \"lagtime [s]\", xlim=(-1, 20), title = \"x\")\n",
    "\n",
    "ax[1].plot(x, B_smooth, label=\"y\")\n",
    "ax[1].fill_between(x, B_smooth - B_std_smooth, B_smooth + B_std_smooth, alpha=0.2)\n",
    "ax[1].set(xlabel=\"lagtime [s]\" , ylabel = \"correlation\", xlim=(-1, 20), title = \"y\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
