{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('image', cmap='gray')\n",
    "mpl.rcParams[\"image.interpolation\"] = 'none'\n",
    "%matplotlib inline\n",
    "import matplotlib.animation\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "from csbdeep.utils import Path, normalize\n",
    "import skimage\n",
    "from tifffile import imsave, imread\n",
    "from glob import glob\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD TRAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(cap, frame, x1, y1, x2, y2, w, h, preprocess):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "    ret, image = cap.read()\n",
    "    if preprocess:\n",
    "        npImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        alpha = Image.new('L', (w, h), 0)\n",
    "        draw = ImageDraw.Draw(alpha)\n",
    "        draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "        npAlpha = np.array(alpha)\n",
    "        npImage = npImage*npAlpha\n",
    "        ind = np.where(npImage == 0)\n",
    "        npImage[ind] = npImage[200, 200]\n",
    "        npImage = npImage[y1:y2, x1:x2]\n",
    "        return npImage\n",
    "    elif not preprocess:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        raise ValueError(\"preprocess must be a boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>r</th>\n",
       "      <th>frame</th>\n",
       "      <th>particle</th>\n",
       "      <th>flag</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>417.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>20.315157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#8B0E71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>505.5</td>\n",
       "      <td>529.5</td>\n",
       "      <td>20.472479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#53BF7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>555.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>20.537350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>#3706D8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>759.0</td>\n",
       "      <td>538.5</td>\n",
       "      <td>20.583065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>#5C524E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172.5</td>\n",
       "      <td>559.5</td>\n",
       "      <td>20.962828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#440066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x      y          r  frame  particle  flag    color\n",
       "0  417.0  174.0  20.315157    0.0         0     0  #8B0E71\n",
       "1  505.5  529.5  20.472479    0.0         1     0  #53BF7C\n",
       "2  555.0  528.0  20.537350    0.0         2     0  #3706D8\n",
       "3  759.0  538.5  20.583065    0.0         3     0  #5C524E\n",
       "4  172.5  559.5  20.962828    0.0         4     0  #440066"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trajectories = pd.read_parquet('./49b_1r/old/tracking_data/hough/tracking_hough_trackpy_linking.parquet')\n",
    "# rename column to be consistent with the other datasets\n",
    "trajectories.rename(columns={'d':'r'}, inplace=True)\n",
    "# remove rows with NaN values in the radius column\n",
    "trajectories.dropna(subset=['r'], inplace=True)\n",
    "display(trajectories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('/Users/matteoscandola/MasterThesis/tracking/data/49b1r.mp4')\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, first_frame = video.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [09:51<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# sample x frames from the hough-method tracking dataset\n",
    "n_samples = 1000\n",
    "np.random.seed(42)\n",
    "sample_frames = np.sort(np.random.choice(trajectories.frame.unique().astype(int), size=n_samples, replace=False))\n",
    "\n",
    "for frame in tqdm(sample_frames):\n",
    "    frame_img = get_frame(video, frame, 55, 55, 880, 880, 920, 960, True)\n",
    "    imsave(f\"/Users/matteoscandola/MasterThesis/tracking/train_49b-1r/image/49b1r_frame{frame}.tif\", frame_img)\n",
    "    df = trajectories.loc[(trajectories.frame == frame), [\"x\", \"y\", \"r\"]]\n",
    "    image = np.zeros((880 - 55, 880 - 55), dtype=np.uint8)\n",
    "    count = 0\n",
    "    for _, droplet in df.iterrows():\n",
    "        x, y, radius = droplet['x'], droplet['y'], droplet['r']\n",
    "        cv2.circle(image, (int(x)- 55, int(y) - 55), int(radius), int(count), thickness=-1)\n",
    "        count += 1\n",
    "    imsave(f\"/Users/matteoscandola/MasterThesis/tracking/train_49b-1r/mask/49b1r_frame{frame}.tif\", image)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNormalizing image channels \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mjointly\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m axis_norm \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39m2\u001b[39m \u001b[39min\u001b[39;00m axis_norm \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mindependently\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mflush()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m X \u001b[39m=\u001b[39m [normalize(x,\u001b[39m1\u001b[39m,\u001b[39m99.8\u001b[39m,axis\u001b[39m=\u001b[39maxis_norm) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tqdm(X)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m Y \u001b[39m=\u001b[39m [fill_label_holes(y) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m tqdm(Y)]\n",
      "\u001b[1;32m/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNormalizing image channels \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mjointly\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m axis_norm \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39m2\u001b[39m \u001b[39min\u001b[39;00m axis_norm \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mindependently\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mflush()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m X \u001b[39m=\u001b[39m [normalize(x,\u001b[39m1\u001b[39;49m,\u001b[39m99.8\u001b[39;49m,axis\u001b[39m=\u001b[39;49maxis_norm) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tqdm(X)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/train_stardist_test.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m Y \u001b[39m=\u001b[39m [fill_label_holes(y) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m tqdm(Y)]\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pyenv/lib/python3.9/site-packages/csbdeep/utils/utils.py:54\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(x, pmin, pmax, axis, clip, eps, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize\u001b[39m(x, pmin\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, pmax\u001b[39m=\u001b[39m\u001b[39m99.8\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, clip\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, eps\u001b[39m=\u001b[39m\u001b[39m1e-20\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32):\n\u001b[1;32m     52\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Percentile-based image normalization.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     mi \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mpercentile(x,pmin,axis\u001b[39m=\u001b[39;49maxis,keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     55\u001b[0m     ma \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpercentile(x,pmax,axis\u001b[39m=\u001b[39maxis,keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m normalize_mi_ma(x, mi, ma, clip\u001b[39m=\u001b[39mclip, eps\u001b[39m=\u001b[39meps, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpercentile\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pyenv/lib/python3.9/site-packages/numpy/lib/function_base.py:4166\u001b[0m, in \u001b[0;36mpercentile\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[1;32m   4165\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPercentiles must be in the range [0, 100]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4166\u001b[0m \u001b[39mreturn\u001b[39;00m _quantile_unchecked(\n\u001b[1;32m   4167\u001b[0m     a, q, axis, out, overwrite_input, method, keepdims)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pyenv/lib/python3.9/site-packages/numpy/lib/function_base.py:4424\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[1;32m   4416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_quantile_unchecked\u001b[39m(a,\n\u001b[1;32m   4417\u001b[0m                         q,\n\u001b[1;32m   4418\u001b[0m                         axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4421\u001b[0m                         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4422\u001b[0m                         keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   4423\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4424\u001b[0m     r, k \u001b[39m=\u001b[39m _ureduce(a,\n\u001b[1;32m   4425\u001b[0m                     func\u001b[39m=\u001b[39;49m_quantile_ureduce_func,\n\u001b[1;32m   4426\u001b[0m                     q\u001b[39m=\u001b[39;49mq,\n\u001b[1;32m   4427\u001b[0m                     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   4428\u001b[0m                     out\u001b[39m=\u001b[39;49mout,\n\u001b[1;32m   4429\u001b[0m                     overwrite_input\u001b[39m=\u001b[39;49moverwrite_input,\n\u001b[1;32m   4430\u001b[0m                     method\u001b[39m=\u001b[39;49mmethod)\n\u001b[1;32m   4431\u001b[0m     \u001b[39mif\u001b[39;00m keepdims:\n\u001b[1;32m   4432\u001b[0m         \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mreshape(q\u001b[39m.\u001b[39mshape \u001b[39m+\u001b[39m k)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pyenv/lib/python3.9/site-packages/numpy/lib/function_base.py:3725\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3722\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3723\u001b[0m     keepdim \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m a\u001b[39m.\u001b[39mndim\n\u001b[0;32m-> 3725\u001b[0m r \u001b[39m=\u001b[39m func(a, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3726\u001b[0m \u001b[39mreturn\u001b[39;00m r, keepdim\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pyenv/lib/python3.9/site-packages/numpy/lib/function_base.py:4593\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[0;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[1;32m   4591\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4592\u001b[0m         arr \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m-> 4593\u001b[0m result \u001b[39m=\u001b[39m _quantile(arr,\n\u001b[1;32m   4594\u001b[0m                    quantiles\u001b[39m=\u001b[39;49mq,\n\u001b[1;32m   4595\u001b[0m                    axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   4596\u001b[0m                    method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   4597\u001b[0m                    out\u001b[39m=\u001b[39;49mout)\n\u001b[1;32m   4598\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pyenv/lib/python3.9/site-packages/numpy/lib/function_base.py:4691\u001b[0m, in \u001b[0;36m_quantile\u001b[0;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[1;32m   4687\u001b[0m previous_indexes, next_indexes \u001b[39m=\u001b[39m _get_indexes(arr,\n\u001b[1;32m   4688\u001b[0m                                               virtual_indexes,\n\u001b[1;32m   4689\u001b[0m                                               values_count)\n\u001b[1;32m   4690\u001b[0m \u001b[39m# --- Sorting\u001b[39;00m\n\u001b[0;32m-> 4691\u001b[0m arr\u001b[39m.\u001b[39;49mpartition(\n\u001b[1;32m   4692\u001b[0m     np\u001b[39m.\u001b[39;49munique(np\u001b[39m.\u001b[39;49mconcatenate(([\u001b[39m0\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m   4693\u001b[0m                               previous_indexes\u001b[39m.\u001b[39;49mravel(),\n\u001b[1;32m   4694\u001b[0m                               next_indexes\u001b[39m.\u001b[39;49mravel(),\n\u001b[1;32m   4695\u001b[0m                               ))),\n\u001b[1;32m   4696\u001b[0m     axis\u001b[39m=\u001b[39;49mDATA_AXIS)\n\u001b[1;32m   4697\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(arr\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minexact):\n\u001b[1;32m   4698\u001b[0m     slices_having_nans \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(\n\u001b[1;32m   4699\u001b[0m         take(arr, indices\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis\u001b[39m=\u001b[39mDATA_AXIS)\n\u001b[1;32m   4700\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X = sorted(glob(\"./train_49b-1r/image/*.tif\"))\n",
    "Y = sorted(glob(\"./train_49b-1r/mask/*.tif\"))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))\n",
    "\n",
    "X = list(map(imread,X))\n",
    "Y = list(map(imread,Y))\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_label(img, lbl, img_title=\"image\", lbl_title=\"label\", **kwargs):\n",
    "    fig, (ai,al) = plt.subplots(1,2, figsize=(12,5), gridspec_kw=dict(width_ratios=(1.25,1)))\n",
    "    im = ai.imshow(img, cmap='gray', clim=(0,1))\n",
    "    ai.set_title(img_title)    \n",
    "    fig.colorbar(im, ax=ai)\n",
    "    al.imshow(lbl, cmap=lbl_cmap)\n",
    "    al.set_title(lbl_title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = min(9, len(X)-1)\n",
    "img, lbl = X[i], Y[i]\n",
    "assert img.ndim in (2,3)\n",
    "img = img if (img.ndim==2 or img.shape[-1]==3) else img[...,0]\n",
    "plot_img_label(img,lbl)\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gputools_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 32\n",
    "\n",
    "# Use OpenCL-based computations for data generator during training (requires 'gputools')\n",
    "use_gpu = False and gputools_available()\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = (2,2)\n",
    "\n",
    "conf = Config2D (\n",
    "    n_rays       = n_rays,\n",
    "    grid         = grid,\n",
    "    use_gpu      = use_gpu,\n",
    "    n_channel_in = n_channel,\n",
    ")\n",
    "print(conf)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from csbdeep.utils.tf import limit_gpu_memory\n",
    "    # adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "    limit_gpu_memory(0.8)\n",
    "    # alternatively, try this:\n",
    "    # limit_gpu_memory(None, allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist2D(conf, name='stardist', basedir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_size = calculate_extents(list(Y), np.median)\n",
    "fov = np.array(model._axes_tile_overlap('YX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fliprot(img, mask): \n",
    "    assert img.ndim >= mask.ndim\n",
    "    axes = tuple(range(mask.ndim))\n",
    "    perm = tuple(np.random.permutation(axes))\n",
    "    img = img.transpose(perm + tuple(range(mask.ndim, img.ndim))) \n",
    "    mask = mask.transpose(perm) \n",
    "    for ax in axes: \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=ax)\n",
    "            mask = np.flip(mask, axis=ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def augmenter(x, y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    x, y = random_fliprot(x, y)\n",
    "    x = random_intensity_change(x)\n",
    "    # add some gaussian noise\n",
    "    sig = 0.02*np.random.uniform(0,1)\n",
    "    x = x + sig*np.random.normal(0,1,x.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some augmented examples\n",
    "img, lbl = X[0],Y[0]\n",
    "plot_img_label(img, lbl)\n",
    "for _ in range(3):\n",
    "    img_aug, lbl_aug = augmenter(img,lbl)\n",
    "    plot_img_label(img_aug, lbl_aug, img_title=\"image augmented\", lbl_title=\"label augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_demo = False\n",
    "\n",
    "if quick_demo:\n",
    "    print (\n",
    "        \"NOTE: This is only for a quick demonstration!\\n\"\n",
    "        \"      Please set the variable 'quick_demo = False' for proper (long) training.\",\n",
    "        file=sys.stderr, flush=True\n",
    "    )\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter,\n",
    "                epochs=2, steps_per_epoch=10)\n",
    "\n",
    "    print(\"====> Stopping training and loading previously trained demo model from disk.\", file=sys.stderr, flush=True)\n",
    "    model = StarDist2D.from_pretrained('2D_demo')\n",
    "else:\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter)\n",
    "None;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
