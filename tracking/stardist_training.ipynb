{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('image', cmap='gray')\n",
    "mpl.rcParams[\"image.interpolation\"] = 'none'\n",
    "%matplotlib ipympl\n",
    "import matplotlib.animation\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "from csbdeep.utils import Path, normalize\n",
    "import skimage\n",
    "from tifffile import imsave, imread\n",
    "from glob import glob\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_label(img, lbl, img_title=\"image\", lbl_title=\"label\", **kwargs):\n",
    "    fig, (ai,al) = plt.subplots(1,2, figsize=(12,5), gridspec_kw=dict(width_ratios=(1.25,1)))\n",
    "    im = ai.imshow(img, cmap='gray', clim=(0,1))\n",
    "    ai.set_title(img_title)    \n",
    "    fig.colorbar(im, ax=ai)\n",
    "    al.imshow(lbl, cmap=lbl_cmap)\n",
    "    al.set_title(lbl_title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def random_fliprot(img, mask): \n",
    "    assert img.ndim >= mask.ndim\n",
    "    axes = tuple(range(mask.ndim))\n",
    "    perm = tuple(np.random.permutation(axes))\n",
    "    img = img.transpose(perm + tuple(range(mask.ndim, img.ndim))) \n",
    "    mask = mask.transpose(perm) \n",
    "    for ax in axes: \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=ax)\n",
    "            mask = np.flip(mask, axis=ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def augmenter(x, y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    x, y = random_fliprot(x, y)\n",
    "    x = random_intensity_change(x)\n",
    "    # add some gaussian noise\n",
    "    sig = 0.02*np.random.uniform(0,1)\n",
    "    x = x + sig*np.random.normal(0,1,x.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob(\"./train_49b-1r/image/*.tif\"))\n",
    "Y = sorted(glob(\"./train_49b-1r/mask/*.tif\"))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))\n",
    "\n",
    "X = list(map(imread,X))\n",
    "Y = list(map(imread,Y))\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]\n",
    "\n",
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = min(9, len(X)-1)\n",
    "img, lbl = X[i], Y[i]\n",
    "assert img.ndim in (2,3)\n",
    "img = img if (img.ndim==2 or img.shape[-1]==3) else img[...,0]\n",
    "plot_img_label(img,lbl)\n",
    "None;\n",
    "\n",
    "\n",
    "# plot some augmented examples\n",
    "img, lbl = X[0],Y[0]\n",
    "plot_img_label(img, lbl)\n",
    "for _ in range(3):\n",
    "    img_aug, lbl_aug = augmenter(img,lbl)\n",
    "    plot_img_label(img_aug, lbl_aug, img_title=\"image augmented\", lbl_title=\"label augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 32\n",
    "\n",
    "# Use OpenCL-based computations for data generator during training (requires 'gputools')\n",
    "use_gpu = False and gputools_available()\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = (2,2)\n",
    "\n",
    "conf = Config2D (\n",
    "    n_rays       = n_rays,\n",
    "    grid         = grid,\n",
    "    use_gpu      = use_gpu,\n",
    "    n_channel_in = n_channel,\n",
    ")\n",
    "print(conf)\n",
    "vars(conf)\n",
    "\n",
    "if use_gpu:\n",
    "    from csbdeep.utils.tf import limit_gpu_memory\n",
    "    # adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "    limit_gpu_memory(0.8)\n",
    "    # alternatively, try this:\n",
    "    # limit_gpu_memory(None, allow_growth=True)\n",
    "\n",
    "timestamp = time.time()\n",
    "model = StarDist2D(conf, name=f'stardist_{timestamp}', basedir='models')\n",
    "\n",
    "median_size = calculate_extents(list(Y), np.median)\n",
    "fov = np.array(model._axes_tile_overlap('YX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter, epochs=150, steps_per_epoch=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
