{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist.models import Config2D, StarDist2D\n",
    "from csbdeep.utils import Path, normalize\n",
    "from tifffile import imread\n",
    "from glob import glob\n",
    "from tracking_utils import plot_img_label, random_fliprot, random_intensity_change, augmenter\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR) # this goes *before* tf import\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = imread('./simulation/synthetic_dataset/image/synthetic_0.tif')\n",
    "test_mask = imread('./simulation/synthetic_dataset/mask/synthetic_0.tif')\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(test_img, cmap='gray')\n",
    "ax[1].imshow(test_mask, cmap=lbl_cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob(\"./simulation/synthetic_dataset/image/*.tif\"))\n",
    "Y = sorted(glob(\"./simulation/synthetic_dataset/mask/*.tif\"))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))\n",
    "\n",
    "X = list(map(imread,X))\n",
    "Y = list(map(imread,Y))\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]\n",
    "\n",
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = 'pretrained_2D_versatile_fluo' # 'new'\n",
    "\n",
    "if training_model == 'new':\n",
    "    n_rays = 32\n",
    "    use_gpu = False and gputools_available()\n",
    "    grid = (2, 2)\n",
    "    conf = Config2D (\n",
    "        n_rays       = n_rays,\n",
    "        grid         = grid,\n",
    "        use_gpu      = use_gpu,\n",
    "        n_channel_in = n_channel,\n",
    "    )\n",
    "    print(conf)\n",
    "    vars(conf)\n",
    "    if use_gpu:\n",
    "        from csbdeep.utils.tf import limit_gpu_memory\n",
    "        limit_gpu_memory(0.8)\n",
    "    timestamp = time.time()\n",
    "    model = StarDist2D(conf, name=f'stardist_trained', basedir='models')\n",
    "    median_size = calculate_extents(list(Y), np.median)\n",
    "    fov = np.array(model._axes_tile_overlap('YX'))\n",
    "    print(f\"median object size:      {median_size}\")\n",
    "    print(f\"network field of view :  {fov}\")\n",
    "    if any(median_size > fov):\n",
    "        print(\"WARNING: median object size larger than field of view of the neural network.\")\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val, Y_val), augmenter=augmenter, epochs=150, steps_per_epoch=100)\n",
    "    model.optimize_thresholds(X_val, Y_val)\n",
    "\n",
    "elif training_model == 'pretrained_2D_versatile_fluo':\n",
    "    if 1:\n",
    "        model_pretrained = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "        shutil.copytree(model_pretrained.logdir, './models/modified_2D_versatile_fluo', dirs_exist_ok=True)\n",
    "        model = StarDist2D(None, './models/modified_2D_versatile_fluo')\n",
    "    else:\n",
    "        model = StarDist2D(None, name = 'modified_2D_versatile_fluo', \\\n",
    "                               basedir = 'models')\n",
    "\n",
    "    median_size = calculate_extents(list(Y), np.median)\n",
    "    fov = np.array(model._axes_tile_overlap('YX'))\n",
    "    print(f\"median object size:      {median_size}\")\n",
    "    print(f\"network field of view :  {fov}\")\n",
    "    if any(median_size > fov):\n",
    "        print(\"WARNING: median object size larger than field of view of the neural network.\")\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val, Y_val), augmenter=augmenter, epochs = 150, steps_per_epoch = 100)\n",
    "    model.optimize_thresholds(X_val, Y_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
