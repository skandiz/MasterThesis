{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tracking_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtifffile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imsave, imread\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrackpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtp\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtracking_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tracking_utils'"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('image', cmap='gray')\n",
    "import matplotlib.animation\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from stardist import _draw_polygons\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "import skimage\n",
    "from scipy.optimize import dual_annealing, minimize\n",
    "from tifffile import imsave, imread\n",
    "import trackpy as tp\n",
    "\n",
    "from tracking_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'stardist_trained'          # stardist model trained for 50 epochs on simulated synthetic dataset\n",
    "model_name = 'modified_2D_versatile_fluo' # stardist model trained for 150 epochs on simulated dataset starting from the pretrained 2D versatile fluo model\n",
    "model = StarDist2D(None, name = model_name, basedir = './models/')\n",
    "video_selection =  \"25b25r-1\"#\"49b1r\"\n",
    "\n",
    "if video_selection == \"25b25r-1\":\n",
    "    xmin, ymin, xmax, ymax = 95, 30, 535, 470 \n",
    "    merge_present = False   \n",
    "elif video_selection == \"25b25r-2\":\n",
    "    xmin, ymin, xmax, ymax = 82, 13, 410, 342 \n",
    "    merge_present = False   \n",
    "elif video_selection == \"49b1r\":\n",
    "    xmin, ymin, xmax, ymax = 20, 50, 900, 930\n",
    "    merge_present = True\n",
    "    merge_frame = 32269\n",
    "\n",
    "\n",
    "save_path       = f'./{video_selection}/{model_name}/'\n",
    "source_path     = f'./data/{video_selection}.mp4'\n",
    "system_name     = f'{video_selection} system'\n",
    "nDrops = 50\n",
    "\n",
    "video = cv2.VideoCapture(source_path)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video has {n_frames} frames with a resolution of {w}x{h} and a framerate of {fps} fps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax.imshow(get_frame(video, n_frames -1, xmin, ymin, xmax, ymax, w, h, True))\n",
    "ax1.imshow(get_frame(video, n_frames -1, xmin, ymin, xmax, ymax, w, h, False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_verb = False\n",
    "detect_verb = False\n",
    "link_verb = False\n",
    "interp_verb = False\n",
    "\n",
    "startFrame = 0\n",
    "endFrame = n_frames - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_verb: \n",
    "    n_samples = 1000\n",
    "    test_detection(n_samples, n_frames, nDrops, video_selection, model, model_name, video, xmin, ymin, xmax, ymax, w, h, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if detect_verb:\n",
    "    print(f'Processing from {int(startFrame/fps)} s to {int(endFrame/fps)} s')\n",
    "    sample_frames = np.arange(startFrame, endFrame, 1, dtype=int)\n",
    "    raw_detection_df = detect_features(sample_frames, False, video_selection, model, model_name, video, xmin, ymin, xmax, ymax, w, h, save_path)\n",
    "    \n",
    "    n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "    ax[0, 0].plot(raw_detection_df.frame.unique(), n_feature_per_frame, '.')\n",
    "    ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "    ax[0, 1].plot(raw_detection_df.r, '.')\n",
    "    ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "    ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "    ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "    ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "    ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path + f'raw_features_{model_name}_{startFrame}_{endFrame}.png', dpi = 500)\n",
    "    plt.close()\n",
    "else:\n",
    "    raw_detection_df = pd.read_parquet(save_path + f'raw_detection_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet')\n",
    "    sample_frames = raw_detection_df.frame.unique()\n",
    "\n",
    "    n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "    ax[0, 0].plot(raw_detection_df.frame.unique(), n_feature_per_frame, '.')\n",
    "    ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "    ax[0, 1].plot(raw_detection_df.r, '.')\n",
    "    ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "    ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "    ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "    ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "    ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path + f'raw_features_{model_name}_{startFrame}_{endFrame}.png', dpi = 500)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_present:\n",
    "    err_frames_pre_merge = np.where(raw_detection_df.loc[raw_detection_df.frame < merge_frame].groupby('frame').count().x.values != nDrops)[0]\n",
    "    err_frames_post_merge = merge_frame + np.where(raw_detection_df.loc[raw_detection_df.frame >= merge_frame].groupby('frame').count().x.values != nDrops-1)[0] \n",
    "    print(f'Number of errors: {len(err_frames_pre_merge)} / {len(sample_frames[:merge_frame])} --> {len(err_frames_pre_merge)/len(sample_frames[:merge_frame])*100:.2f}%')\n",
    "    print(f'Number of errors: {len(err_frames_post_merge)} / {len(sample_frames[merge_frame:])} --> {len(err_frames_post_merge)/len(sample_frames[merge_frame:])*100:.2f}%')\n",
    "    condition = np.ediff1d(err_frames_pre_merge)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs_pre_merge = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors pre merge: {max_n_of_consecutive_errs_pre_merge}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs_pre_merge = 0\n",
    "        print(f'Max number of consecutive errors pre merge: 0')\n",
    "    condition = np.ediff1d(err_frames_post_merge)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs_post_merge = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors pre merge: {max_n_of_consecutive_errs_post_merge}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs_post_merge = 0\n",
    "        print(f'Max number of consecutive errors pre merge: 0')\n",
    "else:\n",
    "    err_frames = np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0]\n",
    "    print(f'Number of errors: {len(err_frames)} / {len(sample_frames)} --> {len(err_frames)/len(sample_frames)*100:.2f}%')\n",
    "    condition = np.ediff1d(err_frames)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors: {max_n_of_consecutive_errs}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs = 0\n",
    "        print(f'Max number of consecutive errors: 0')\n",
    "\n",
    "if merge_present: \n",
    "    traj_test = raw_detection_df.loc[raw_detection_df.frame.isin(np.append(err_frames_pre_merge, err_frames_post_merge))]\n",
    "else: \n",
    "    traj_test = raw_detection_df.loc[raw_detection_df.frame.isin(err_frames)]\n",
    "fig, ax = fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "def update_graph(frame):\n",
    "    df = traj_test.loc[(traj_test.frame == frame), [\"x\", \"y\", \"r\"]]\n",
    "    for i in range(len(df)):\n",
    "        graph[i].center = (df.x.values[i], df.y.values[i])\n",
    "        graph[i].radius = df.r.values[i]\n",
    "    graph2.set_data(get_frame(video, frame, xmin, ymin, xmax, ymax, w, h, False))\n",
    "    title.set_text(f'{system_name} Tracking -- t = {round(frame/fps, 1)} s')\n",
    "    return graph\n",
    "\n",
    "title = ax.set_title(f'{system_name} Tracking -- t = {0} s')\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "df = traj_test.loc[(traj_test.frame == min(traj_test.frame.unique())), [\"x\", \"y\", \"r\"]]\n",
    "graph = []\n",
    "for i in range(len(df)):\n",
    "    graph.append(ax.add_artist(plt.Circle((df.x.values[i], df.y.values[i]), df.r.values[i], color = 'red',\\\n",
    "                                           fill = False, alpha = 0.5, linewidth=1)))\n",
    "graph2 = ax.imshow(get_frame(video, 0, xmin, ymin, xmax, ymax, w, h, False))\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, traj_test.frame.unique(), interval = 5, blit=False)\n",
    "writer = matplotlib.animation.FFMpegWriter(fps = 30, metadata = dict(artist='Matteo Scandola'), extra_args=['-vcodec', 'libx264'])\n",
    "ani.save(f'./{save_path}/tracking_video_errors.mp4', writer=writer, dpi = 200)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if link_verb:\n",
    "    if merge_present:\n",
    "        print('Linking trajectories...')\n",
    "        cutoff = 100\n",
    "\n",
    "        ## PRE MERGE\n",
    "        t = tp.link_df(raw_detection_df.loc[raw_detection_df.frame < merge_frame], cutoff,\\\n",
    "                                 memory = max_n_of_consecutive_errs_pre_merge, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "        t = t.sort_values(['frame', 'particle'])\n",
    "        trajectories_pre_merge = tp.filter_stubs(t, 25)\n",
    "        # CREATE COLOR COLUMN AND SAVE DF\n",
    "        n = max(trajectories_pre_merge.particle)\n",
    "        print(f'N of droplets pre merge: {n + 1}')\n",
    "        random.seed(5)\n",
    "        colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "        for i in range(max(trajectories_pre_merge.particle)+1-n):\n",
    "            colors.append('#00FFFF')\n",
    "        c = []\n",
    "        for p in t.particle:\n",
    "            c.append(colors[p])\n",
    "        trajectories_pre_merge['color'] = c\n",
    "        trajectories_pre_merge = trajectories_pre_merge.reset_index(drop=True)\n",
    "        trajectories_pre_merge.to_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_pre_merge.parquet', index = False)\n",
    "\n",
    "        ## POST MERGE\n",
    "        t = tp.link_df(raw_detection_df.loc[raw_detection_df.frame >= merge_frame], cutoff,\\\n",
    "                                  memory = max_n_of_consecutive_errs_post_merge, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "        t = t.sort_values(['frame', 'particle'])\n",
    "        trajectories_post_merge = tp.filter_stubs(t, 25)\n",
    "        # CREATE COLOR COLUMN AND SAVE DF\n",
    "        n = max(trajectories_post_merge.particle)\n",
    "        print(f'N of droplets post merge: {n + 1}')\n",
    "        random.seed(5)\n",
    "        colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "        for i in range(max(trajectories_post_merge.particle)+1-n):\n",
    "            colors.append('#00FFFF')\n",
    "        c = []\n",
    "        for p in t.particle:\n",
    "            c.append(colors[p])\n",
    "        trajectories_post_merge['color'] = c\n",
    "        trajectories_post_merge = trajectories_post_merge.reset_index(drop=True)\n",
    "        trajectories_post_merge.to_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_post_merge.parquet', index = False)\n",
    "    else:\n",
    "        print('Linking trajectories...')\n",
    "        cutoff = 100\n",
    "        t = tp.link_df(raw_detection_df, cutoff, memory = max_n_of_consecutive_errs, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "        #print(t)\n",
    "        t = t.sort_values(['frame', 'particle'])\n",
    "        trajectories = tp.filter_stubs(t, 25)\n",
    "        # CREATE COLOR COLUMN AND SAVE DF\n",
    "        n = max(trajectories.particle)\n",
    "        print(f'N of droplets: {n + 1}')\n",
    "        random.seed(5)\n",
    "        colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "        for i in range(max(trajectories.particle)+1-n):\n",
    "            colors.append('#00FFFF')\n",
    "        c = []\n",
    "        for p in t.particle:\n",
    "            c.append(colors[p])\n",
    "        trajectories['color'] = c\n",
    "        trajectories = trajectories.reset_index(drop=True)\n",
    "        trajectories.to_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet', index = False)\n",
    "else:\n",
    "    if merge_present:\n",
    "        print('Importing linked trajectories...')\n",
    "        trajectories_pre_merge = pd.read_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_pre_merge.parquet')\n",
    "        trajectories_post_merge = pd.read_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_post_merge.parquet')\n",
    "    else:\n",
    "        print('Importing linked trajectories...')\n",
    "        trajectories = pd.read_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interp_verb:\n",
    "    if merge_present:\n",
    "        print('Interpolating trajectories...')\n",
    "        tqdm.pandas()\n",
    "        interp_trajectories_pre_merge = trajectories_pre_merge.groupby('particle').progress_apply(interpolate_trajectory)\n",
    "        interp_trajectories_pre_merge = interp_trajectories_pre_merge.reset_index(drop=True)\n",
    "        interp_trajectories_pre_merge['particle'] = interp_trajectories_pre_merge['particle'].astype(int)\n",
    "        interp_trajectories_pre_merge = interp_trajectories_pre_merge.sort_values(['frame', 'particle'])\n",
    "        interp_trajectories_pre_merge.to_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_pre_merge.parquet', index=False)\n",
    "\n",
    "        interp_trajectories_post_merge = trajectories_post_merge.groupby('particle').apply(interpolate_trajectory)\n",
    "        interp_trajectories_post_merge = interp_trajectories_post_merge.reset_index(drop=True)\n",
    "        interp_trajectories_post_merge['particle'] = interp_trajectories_post_merge['particle'].astype(int)\n",
    "        interp_trajectories_post_merge = interp_trajectories_post_merge.sort_values(['frame', 'particle'])\n",
    "        interp_trajectories_post_merge.to_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_post_merge.parquet', index=False)\n",
    "    else:\n",
    "        print('Interpolating trajectories...')\n",
    "        tqdm.pandas()\n",
    "        interp_trajectories = trajectories.groupby('particle').progress_apply(interpolate_trajectory)\n",
    "        interp_trajectories = interp_trajectories.reset_index(drop=True)\n",
    "        interp_trajectories['particle'] = interp_trajectories['particle'].astype(int)\n",
    "        interp_trajectories = interp_trajectories.sort_values(['frame', 'particle'])\n",
    "        interp_trajectories.to_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet', index=False)\n",
    "else:\n",
    "    if merge_present:\n",
    "        print('Importing interpolated trajectories...')\n",
    "        interp_trajectories_pre_merge = pd.read_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_pre_merge.parquet')\n",
    "        interp_trajectories_post_merge = pd.read_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_post_merge.parquet')\n",
    "    else:\n",
    "        print('Importing interpolated trajectories...')\n",
    "        interp_trajectories = pd.read_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    if merge_present:\n",
    "        interp_trajectories_subsampled_pre_merge = interp_trajectories_pre_merge.loc[interp_trajectories_pre_merge.frame.isin(interp_trajectories_pre_merge.frame.unique()[::int(fps/10)]), [\"x\", \"y\", \"r\", \"frame\", \"particle\", \"color\"]]\n",
    "        interp_trajectories_subsampled_pre_merge['frame'] = np.array(interp_trajectories_subsampled_pre_merge.frame/int(fps/10)).astype(int)\n",
    "        smooth_trajs_pre_merge = get_smooth_trajs(interp_trajectories_subsampled_pre_merge, windLen = 10, orderofPoly = 4)\n",
    "        ts1 = smooth_trajs_pre_merge.copy()\n",
    "        ts1[\"color\"] = ts1[\"color\"].astype(\"category\")\n",
    "        ts1[\"particle\"] = pd.to_numeric(ts1[\"particle\"], downcast=\"integer\")\n",
    "        ts1[\"frame\"] = pd.to_numeric(ts1[\"frame\"], downcast=\"integer\")\n",
    "        ts1[\"x\"] = pd.to_numeric(ts1[\"x\"], downcast=\"float\")\n",
    "        ts1[\"y\"] = pd.to_numeric(ts1[\"y\"], downcast=\"float\")\n",
    "        ts1[\"r\"] = pd.to_numeric(ts1[\"r\"], downcast=\"float\")\n",
    "        ts1 = ts1.sort_values(['frame', 'particle'])\n",
    "        display(ts1.memory_usage(deep=True))\n",
    "        display(ts1.dtypes)\n",
    "        reduction = ts1.memory_usage(deep=True).sum() / smooth_trajs_pre_merge.memory_usage(deep=True).sum()\n",
    "        print(f\" Reduced to {reduction*100:0.4f} % of the original size\")\n",
    "        ts1.to_parquet(save_path + f'{video_selection}_subsampled{int(fps/10)}_smoothed_windlen10_orderofpoly4_pre_merge', index=False, engine='pyarrow', partition_cols=['particle'])\n",
    "\n",
    "        interp_trajectories_subsampled_post_merge = interp_trajectories_post_merge.loc[interp_trajectories_post_merge.frame.isin(interp_trajectories_post_merge.frame.unique()[::int(fps/10)]), [\"x\", \"y\", \"r\", \"frame\", \"particle\", \"color\"]]\n",
    "        interp_trajectories_subsampled_post_merge['frame'] = np.array(interp_trajectories_subsampled_post_merge.frame/int(fps/10)).astype(int)\n",
    "        smooth_trajs_post_merge = get_smooth_trajs(interp_trajectories_subsampled_post_merge, windLen = 10, orderofPoly = 4)\n",
    "        ts2 = smooth_trajs_post_merge.copy()\n",
    "        ts2[\"color\"] = ts2[\"color\"].astype(\"category\")\n",
    "        ts2[\"particle\"] = pd.to_numeric(ts2[\"particle\"], downcast=\"integer\")\n",
    "        ts2[\"frame\"] = pd.to_numeric(ts2[\"frame\"], downcast=\"integer\")\n",
    "        ts2[\"x\"] = pd.to_numeric(ts2[\"x\"], downcast=\"float\")\n",
    "        ts2[\"y\"] = pd.to_numeric(ts2[\"y\"], downcast=\"float\")\n",
    "        ts2[\"r\"] = pd.to_numeric(ts2[\"r\"], downcast=\"float\")\n",
    "        ts2 = ts2.sort_values(['frame', 'particle'])\n",
    "        display(ts2.memory_usage(deep=True))\n",
    "        display(ts2.dtypes)\n",
    "        reduction = ts2.memory_usage(deep=True).sum() / smooth_trajs_post_merge.memory_usage(deep=True).sum()\n",
    "        print(f\" Reduced to {reduction*100:0.4f} % of the original size\")\n",
    "        ts2.to_parquet(save_path + f'{video_selection}_subsampled{int(fps/10)}_smoothed_windlen10_orderofpoly4_post_merge', index=False, engine='pyarrow', partition_cols=['particle'])\n",
    "    else:\n",
    "        interp_trajectories_subsampled = interp_trajectories.loc[interp_trajectories.frame.isin(interp_trajectories.frame.unique()[::int(fps/10)]), [\"x\", \"y\", \"r\", \"frame\", \"particle\", \"color\"]]\n",
    "        interp_trajectories_subsampled['frame'] = np.array(interp_trajectories_subsampled.frame/int(fps/10)).astype(int)\n",
    "        smooth_trajs = get_smooth_trajs(interp_trajectories_subsampled, windLen = 10, orderofPoly = 4)\n",
    "        ts2 = smooth_trajs.copy()\n",
    "        ts2[\"color\"] = ts2[\"color\"].astype(\"category\")\n",
    "        ts2[\"particle\"] = pd.to_numeric(ts2[\"particle\"], downcast=\"integer\")\n",
    "        ts2[\"frame\"] = pd.to_numeric(ts2[\"frame\"], downcast=\"integer\")\n",
    "        ts2[\"x\"] = pd.to_numeric(ts2[\"x\"], downcast=\"float\")\n",
    "        ts2[\"y\"] = pd.to_numeric(ts2[\"y\"], downcast=\"float\")\n",
    "        ts2[\"r\"] = pd.to_numeric(ts2[\"r\"], downcast=\"float\")\n",
    "        ts2 = ts2.sort_values(['frame', 'particle'])\n",
    "        display(ts2.memory_usage(deep=True))\n",
    "        display(ts2.dtypes)\n",
    "        reduction = ts2.memory_usage(deep=True).sum() / smooth_trajs.memory_usage(deep=True).sum()\n",
    "        print(f\" Reduced to {reduction*100:0.4f} % of the original size\")\n",
    "        ts2.to_parquet(save_path + f'{video_selection}_subsampled{int(fps/10)}_smoothed_windlen10_orderofpoly4', index=False, engine='pyarrow', partition_cols=['particle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature_per_frame = interp_trajectories.groupby('frame').count().x.values\n",
    "fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "ax[0, 0].plot(interp_trajectories.frame.unique(), n_feature_per_frame, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(interp_trajectories.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].scatter(interp_trajectories.r, interp_trajectories.eccentricity, s=0.1)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "ax[1, 1].scatter(interp_trajectories.r, interp_trajectories.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f'interp_features_{model_name}_{startFrame}_{endFrame}.png', dpi = 500)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "def update_graph(frame):\n",
    "    df = interp_trajectories.loc[(interp_trajectories.frame == frame), [\"x\", \"y\", \"r\", 'color']]\n",
    "    for i in range(len(df)):\n",
    "        graph[i].center = (df.x.values[i], df.y.values[i])\n",
    "        graph[i].radius = df.r.values[i]\n",
    "    graph2.set_data(get_frame(video, frame, xmin, ymin, xmax, ymax, w, h, False))\n",
    "    title.set_text(f'{system_name} Tracking -- t = {round(frame/fps, 1)} s')\n",
    "    return graph\n",
    "\n",
    "title = ax.set_title(f'{system_name} Tracking -- t = {0} s')\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "df = interp_trajectories.loc[(interp_trajectories.frame == min(interp_trajectories.frame.unique())), [\"x\", \"y\", \"r\", 'color']]\n",
    "graph = []\n",
    "for i in range(len(df)):\n",
    "    graph.append(ax.add_artist(plt.Circle((df.x.values[i], df.y.values[i]), df.r.values[i], color = df.color.values[i],\\\n",
    "                                           fill = False)))\n",
    "graph2 = ax.imshow(get_frame(video, 0, xmin, ymin, xmax, ymax, w, h, False))\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, interp_trajectories.frame.unique(), interval = 5, blit=False)\n",
    "writer = matplotlib.animation.FFMpegWriter(fps = 30, metadata = dict(artist='Matteo Scandola'), extra_args=['-vcodec', 'libx264'])\n",
    "ani.save(f'./{save_path}/tracking_video2.mp4', writer=writer, dpi = 200)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frames = [12336,  12337,  12338,  12339,  12340,  12341, 12343]\n",
    "missing_droplet_id = 43\n",
    "df1 = trajectories.loc[(trajectories.frame < max(test_frames) + 15) & (trajectories.frame > min(test_frames) - 15) & (trajectories.particle == 43)]\n",
    "df2 = interp_trajectories.loc[(interp_trajectories.frame < max(test_frames) + 15) & (interp_trajectories.frame > min(test_frames) - 15) & (interp_trajectories.particle == 43)]\n",
    "df3 = smooth_trajs.loc[(smooth_trajs.frame < max(test_frames) + 15) & (smooth_trajs.frame > min(test_frames) - 15) & (smooth_trajs.particle == 43)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 5))\n",
    "ax[0,0].plot(df1.x, df1.y, 'o', label = 'Raw', zorder = 20)\n",
    "ax[0,0].plot(df2.x, df2.y, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax[0,0].set(xlabel = 'X [px]', ylabel = 'Y [px]', title = 'Position interpolation')\n",
    "ax[0,0].legend()\n",
    "ax[1,0].plot(df1.frame, df1.r, 'o', label = 'Raw', zorder = 20)\n",
    "ax[1,0].plot(df2.frame, df2.r, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax[1,0].set(xlabel = 'Frame', ylabel = 'Radius [px]', title = 'Radius interpolation')\n",
    "ax[1,0].legend()\n",
    "ax[0,1].plot(df1.frame, df1.prob, 'o', label = 'Raw', zorder = 20)\n",
    "ax[0,1].plot(df2.frame, df2.prob, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax[0,1].set(xlabel = 'Frame', ylabel = 'Probability', title = 'Probability interpolation')\n",
    "ax[0,1].legend()\n",
    "ax[1,1].plot(df1.frame, df1.area, 'o', label = 'Raw', zorder = 20)\n",
    "ax[1,1].plot(df2.frame, df2.area, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax[1,1].set(xlabel = 'Frame', ylabel = 'Area [px]', title = 'Area interpolation')\n",
    "ax[1,1].legend()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(save_path + f'interp_example_linear.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax.plot(df1.x, df1.y, 'o', label = 'Original', zorder = 20)\n",
    "ax.plot(df2.x, df2.y, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax1.plot(df3.x, df3.y, '--o', label = 'Smoothed', zorder = 10)\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = 'Raw trajectory')\n",
    "ax1.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = 'Smoothed trajectory')\n",
    "ax.legend()\n",
    "plt.savefig(save_path + f'interp_smoothing_example_linear.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NORMALIZATION_CONSTANT = 2.2522836210436354\n",
    "\n",
    "def _mollifier(t):\n",
    "    \"\"\"Standard mollifier corresponding to epsilon = 1.\"\"\"\n",
    "    return _NORMALIZATION_CONSTANT*np.exp(1.0/(t*t - 1.0)) if abs(t) < 1.0 else 0.0\n",
    "\n",
    "def _mollify(u, k):\n",
    "    \"\"\"Returns the discrete mollification of the given signal with window size `k`.\"\"\"\n",
    "    if not isinstance(k, int):\n",
    "        raise TypeError(f\"Window size must be an integer: {k=}\")\n",
    "    if k < 1:\n",
    "        raise ValueError(f\"Window size must be at least 1: {k=}\")\n",
    "    if len(u.shape) > 1:\n",
    "        raise ValueError(f\"Input signal must be one-dimensional: {u}\")\n",
    "    n = u.size\n",
    "    Mu = np.copy(u)\n",
    "    for j in range(k, n - k):\n",
    "        Mu[j] = sum(_mollifier(i/k)*u[j - i] for i in range(1 - k, k))/k\n",
    "    return Mu\n",
    "\n",
    "def mollify(u, k):\n",
    "    \"\"\"Mollification filter with corrected tails.\"\"\"\n",
    "    n = u.size\n",
    "    padded = np.zeros(n + 2*k)\n",
    "    padded[:k] = u[0]\n",
    "    padded[k:k + n] = u\n",
    "    padded[k + n:] = u[-1]\n",
    "    mollified = _mollify(padded, k)\n",
    "    return mollified[k:n + k]\n",
    "\n",
    "def get_mollified_trajs(trajs, order):\n",
    "    trajs_ret = trajs.copy()\n",
    "    trajs_ret['x'] = trajs_ret.groupby('particle')['x'].transform(lambda x: mollify(x, order))\n",
    "    trajs_ret['y'] = trajs_ret.groupby('particle')['y'].transform(lambda y: mollify(y, order))\n",
    "    return trajs_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = mollify(interp_trajectories.loc[interp_trajectories.particle == 43].x.values, 2)\n",
    "test_y = mollify(interp_trajectories.loc[interp_trajectories.particle == 43].y.values, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1, ax3) = plt.subplots(1, 3, figsize=(12, 4), sharex=True, sharey=True)\n",
    "ax.plot(df1.x, df1.y, 'o', label = 'Original', zorder = 20)\n",
    "ax.plot(df2.x, df2.y, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax1.plot(df3.x, df3.y, '--o', label = 'Smoothed', zorder = 10)\n",
    "ax3.plot(test_x[df1.frame.min():df1.frame.max()], test_y[df1.frame.min():df1.frame.max()], '--o', label = 'Mollified', zorder = 10)\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = 'Raw trajectory')\n",
    "ax1.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = 'Smoothed trajectory')\n",
    "ax.legend()\n",
    "#plt.savefig(save_path + f'interp_smoothing_example_linear.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST SMOOTHING ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_trajectories_initial_part = interp_trajectories.loc[interp_trajectories.frame < 10000]\n",
    "smooth_trajs = get_smooth_trajs(interp_trajectories_initial_part, windLen = 17, orderofPoly = 10)\n",
    "df1 = interp_trajectories_initial_part.loc[(interp_trajectories_initial_part.particle == 43)]\n",
    "df2 = smooth_trajs.loc[(smooth_trajs.particle == 43)]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.plot(df1.x, df1.y, label = 'Original', zorder = 20)\n",
    "ax.plot(df2.x, df2.y, label = 'Smoothed', zorder = 10)\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = 'Raw trajectory')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajs(nDrops, red_particle_idx, trajs, subsample_factor, fps):\n",
    "    blueTrajs = []\n",
    "    redTrajs = []\n",
    "    for i in range(0, nDrops):\n",
    "        if i in red_particle_idx:\n",
    "            p = trajs.loc[trajs.particle == i, ['x','y']][::subsample_factor]\n",
    "            redTrajs.append(Trajectory(p.x, p.y, dt = 1/fps*subsample_factor, traj_id=i, diff_est={'method':DiffMethod.LINEAR_DIFF, \n",
    "                                                                                  'window_type': WindowType.CENTRAL}))\n",
    "        else:\n",
    "            p = trajs.loc[trajs.particle == i, ['x','y']][::subsample_factor]\n",
    "            blueTrajs.append(Trajectory(p.x, p.y, dt = 1/fps*subsample_factor, traj_id=i))\n",
    "    return blueTrajs, redTrajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if video_selection == '25b25r':\n",
    "    red_particle_idx = np.sort(np.array([38, 42, 25, 4, 23, 13, 45, 33, 46, 29, 10, 3, 35, 18, 12, 0, 27, 19, 26, 47, 7, 48, 21, 20, 22], dtype=int))\n",
    "elif video_selection == '49b1r':\n",
    "    red_particle_idx = np.array([19]).astype(int)\n",
    "trajs_yupi_b, trajs_yupi_r = get_trajs(nDrops, red_particle_idx, interp_trajectories_initial_part, 1, fps)\n",
    "turning_angles_b = ys.turning_angles_ensemble(trajs_yupi_b, centered = True)\n",
    "turning_angles_r = ys.turning_angles_ensemble(trajs_yupi_r, centered = True)\n",
    "\n",
    "smooth_trajs_yupi_b, smooth_trajs_yupi_r = get_trajs(nDrops, red_particle_idx, smooth_trajs, 1, fps)\n",
    "smooth_turning_angles_b = ys.turning_angles_ensemble(smooth_trajs_yupi_b, centered = True)\n",
    "smooth_turning_angles_r = ys.turning_angles_ensemble(smooth_trajs_yupi_r, centered = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8), sharex=True, sharey=True)\n",
    "ax[0,0].hist(turning_angles_b, bins = 101, density = True, alpha = 0.5, label = 'Original', color = 'blue')\n",
    "ax[0,1].hist(smooth_turning_angles_b, bins = 101, density = True, alpha = 0.5, label = 'Smoothed', color = 'blue')\n",
    "ax[1,0].hist(turning_angles_r, bins = 101, density = True, alpha = 0.5, label = 'Original', color = 'red')\n",
    "ax[1,1].hist(smooth_turning_angles_r, bins = 101, density = True, alpha = 0.5, label = 'Smoothed', color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
