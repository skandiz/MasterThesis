{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('image', cmap='gray')\n",
    "import matplotlib.animation\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import random\n",
    "from stardist import _draw_polygons\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "import skimage\n",
    "from scipy.optimize import dual_annealing, minimize\n",
    "from tifffile import imsave, imread\n",
    "import trackpy as tp\n",
    "\n",
    "from tracking_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.886451, nms_thresh=0.3.\n",
      "Video has 80794 frames with a resolution of 920x960 and a framerate of 10 fps\n"
     ]
    }
   ],
   "source": [
    "model_name = 'modified_2D_versatile_fluo_synthetic_dataset_100_fps_r_decay_r_gaussian_only_optimization'\n",
    "\n",
    "resolution = 1000\n",
    "model = StarDist2D(None, name = model_name, basedir = './models/')\n",
    "video_selection =  \"49b1r\"\n",
    "\n",
    "if video_selection == \"25b25r-1\":\n",
    "    xmin, ymin, xmax, ymax = 95, 30, 535, 470 \n",
    "    merge_present = False   \n",
    "elif video_selection == \"25b25r-2\":\n",
    "    xmin, ymin, xmax, ymax = 82, 13, 410, 342 \n",
    "    merge_present = False   \n",
    "elif video_selection == \"49b1r\":\n",
    "    xmin, ymin, xmax, ymax = 20, 50, 900, 930\n",
    "    merge_present = True\n",
    "    merge_frame = 32269\n",
    "\n",
    "\n",
    "save_path       = f'./{video_selection}/{model_name}/'\n",
    "source_path     = f'./data/{video_selection}.mp4'\n",
    "system_name     = f'{video_selection} system'\n",
    "nDrops = 50\n",
    "\n",
    "video = cv2.VideoCapture(source_path)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video has {n_frames} frames with a resolution of {w}x{h} and a framerate of {fps} fps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_frame(video, 0, xmin, ymin, xmax, ymax, w, h, resolution, True)\n",
    "label, details = model.predict_instances(normalize(img), predict_kwargs = {'verbose' : False})\n",
    "coord, points, prob = details['coord'], details['points'], details['prob']\n",
    "\n",
    "img2 = get_frame(video, n_frames -1, xmin, ymin, xmax, ymax, w, h, resolution, True)\n",
    "label2, details2 = model.predict_instances(normalize(img2), predict_kwargs = {'verbose' : False})\n",
    "coord2, points2, prob2 = details2['coord'], details2['points'], details2['prob']\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5), sharex=True, sharey=True)\n",
    "ax[0].imshow(img, cmap = 'gray')\n",
    "_draw_polygons(coord, points, prob, show_dist=True)\n",
    "ax[1].imshow(img, cmap = 'gray')\n",
    "ax[1].set(title = f'{len(prob)} instances detected')\n",
    "plt.savefig(save_path + f'test_first_frame.pdf', format = 'pdf')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5), sharex=True, sharey=True)\n",
    "ax[0].imshow(img2, cmap = 'gray')\n",
    "ax[1].imshow(img2, cmap = 'gray')\n",
    "_draw_polygons(coord2, points2, prob2, show_dist=True)\n",
    "ax[1].set(title = f'{len(prob2)} instances detected')\n",
    "plt.savefig(save_path + f'test_last_frame.pdf', format = 'pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_verb = False\n",
    "detect_verb = False\n",
    "link_verb = False\n",
    "interp_verb = False\n",
    "\n",
    "startFrame = 0\n",
    "endFrame = n_frames\n",
    "frames = np.arange(startFrame, endFrame, 1, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_verb:\n",
    "    n_samples = 1000\n",
    "    test_detection_df = test_detection(n_samples, n_frames, nDrops, video_selection, merge_frame, model, model_name, video, xmin, ymin, xmax, ymax, w, h, resolution, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if detect_verb:\n",
    "    print(f'Processing from {int(startFrame/fps)} s to {int(endFrame/fps)} s')\n",
    "    \n",
    "    raw_detection_df = detect_instances(frames, False, video_selection, model, model_name, video, xmin, ymin, xmax, ymax, w, h, resolution, save_path)\n",
    "    \n",
    "    n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "    ax[0, 0].scatter(raw_detection_df.frame.unique(), n_feature_per_frame, s=0.1)\n",
    "    ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "    ax[0, 1].scatter(raw_detection_df.frame, raw_detection_df.r, s=0.1)\n",
    "    ax[0, 1].set(xlabel = 'Instance index', ylabel = 'Radius [px]', title = 'Radius of instances detected')\n",
    "    ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "    ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "    ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "    ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path + f'raw_instances_{model_name}_{frames[0]}_{frames[-1]}.png', dpi = 500)\n",
    "    plt.close()\n",
    "else:\n",
    "    raw_detection_df = pd.read_parquet(save_path + f'raw_detection_{video_selection}_{model_name}_{frames[0]}_{frames[-1]}.parquet')\n",
    "    frames = raw_detection_df.frame.unique()\n",
    "\n",
    "    n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "    ax[0, 0].scatter(raw_detection_df.frame.unique(), n_feature_per_frame, s=0.1)\n",
    "    ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "    ax[0, 1].scatter(raw_detection_df.frame, raw_detection_df.r, s=0.1)\n",
    "    ax[0, 1].set(xlabel = 'Instance index', ylabel = 'Radius [px]', title = 'Radius of instances detected')\n",
    "    ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "    ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "    ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "    ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path + f'raw_instances_{model_name}_{frames[0]}_{frames[-1]}.png', dpi = 500)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_present:\n",
    "    err_frames_pre_merge = np.where(raw_detection_df.loc[raw_detection_df.frame < merge_frame].groupby('frame').count().x.values != nDrops)[0]\n",
    "    err_frames_post_merge = merge_frame + np.where(raw_detection_df.loc[raw_detection_df.frame >= merge_frame].groupby('frame').count().x.values != nDrops-1)[0] \n",
    "    print(f'Number of errors: {len(err_frames_pre_merge)} / {len(frames[:merge_frame])} --> {len(err_frames_pre_merge)/len(frames[:merge_frame])*100:.2f}%')\n",
    "    print(f'Number of errors: {len(err_frames_post_merge)} / {len(frames[merge_frame:])} --> {len(err_frames_post_merge)/len(frames[merge_frame:])*100:.2f}%')\n",
    "    condition = np.ediff1d(err_frames_pre_merge)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs_pre_merge = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors pre merge: {max_n_of_consecutive_errs_pre_merge}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs_pre_merge = 0\n",
    "        print(f'Max number of consecutive errors pre merge: 0')\n",
    "    condition = np.ediff1d(err_frames_post_merge)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs_post_merge = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors post merge: {max_n_of_consecutive_errs_post_merge}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs_post_merge = 0\n",
    "        print(f'Max number of consecutive errors post merge: 0')\n",
    "else:\n",
    "    err_frames = np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0]\n",
    "    print(f'Number of errors: {len(err_frames)} / {len(frames)} --> {len(err_frames)/len(frames)*100:.2f}%')\n",
    "    condition = np.ediff1d(err_frames)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors: {max_n_of_consecutive_errs}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs = 0\n",
    "        print(f'Max number of consecutive errors: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if link_verb:\n",
    "    if merge_present:\n",
    "        print('Linking trajectories...')\n",
    "        cutoff = 200\n",
    "\n",
    "        ## PRE MERGE\n",
    "        t = tp.link_df(raw_detection_df.loc[raw_detection_df.frame < merge_frame], cutoff,\\\n",
    "                       memory = max_n_of_consecutive_errs_pre_merge, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "        t = t.sort_values(['frame', 'particle'])\n",
    "        trajectories_pre_merge = tp.filter_stubs(t, 2500)\n",
    "        # CREATE COLOR COLUMN AND SAVE DF\n",
    "        n = max(trajectories_pre_merge.particle)\n",
    "        print(f'N of droplets pre merge: {n + 1}')\n",
    "        random.seed(5)\n",
    "        colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "        for i in range(max(trajectories_pre_merge.particle)+1-n):\n",
    "            colors.append('#00FFFF')\n",
    "        c = []\n",
    "        for p in trajectories_pre_merge.particle:\n",
    "            c.append(colors[p])\n",
    "        trajectories_pre_merge['color'] = c\n",
    "        trajectories_pre_merge = trajectories_pre_merge.reset_index(drop=True)\n",
    "        trajectories_pre_merge.to_parquet(save_path + f'raw_tracking_{video_selection}_{model_name}_pre_merge.parquet', index = False)\n",
    "\n",
    "        ## POST MERGE\n",
    "        t = tp.link_df(raw_detection_df.loc[raw_detection_df.frame >= merge_frame], cutoff,\\\n",
    "                       memory = max_n_of_consecutive_errs_post_merge, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "        t = t.sort_values(['frame', 'particle'])\n",
    "        trajectories_post_merge = tp.filter_stubs(t, 2500)\n",
    "        # CREATE COLOR COLUMN AND SAVE DF\n",
    "        n = max(trajectories_post_merge.particle)\n",
    "        print(f'N of droplets post merge: {n + 1}')\n",
    "        random.seed(5)\n",
    "        colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "        for i in range(max(trajectories_post_merge.particle)+1-n):\n",
    "            colors.append('#00FFFF')\n",
    "        c = []\n",
    "        for p in trajectories_post_merge.particle:\n",
    "            c.append(colors[p])\n",
    "        trajectories_post_merge['color'] = c\n",
    "        trajectories_post_merge = trajectories_post_merge.reset_index(drop=True)\n",
    "        trajectories_post_merge.to_parquet(save_path + f'raw_tracking_{video_selection}_{model_name}_post_merge.parquet', index = False)\n",
    "    else:\n",
    "        print('Linking trajectories...')\n",
    "        cutoff = 200\n",
    "        t = tp.link_df(raw_detection_df, cutoff, memory = max_n_of_consecutive_errs + 10,\\\n",
    "                       link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "        t = t.sort_values(['frame', 'particle'])\n",
    "        trajectories = tp.filter_stubs(t, 2500)\n",
    "        # CREATE COLOR COLUMN AND SAVE DF\n",
    "        n = max(trajectories.particle)\n",
    "        print(f'N of droplets: {n + 1}')\n",
    "        random.seed(5)\n",
    "        colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "        for i in range(max(trajectories.particle)+1-n):\n",
    "            colors.append('#00FFFF')\n",
    "        c = []\n",
    "        for p in trajectories.particle:\n",
    "            c.append(colors[p])\n",
    "        trajectories['color'] = c\n",
    "        trajectories = trajectories.reset_index(drop=True)\n",
    "        trajectories.to_parquet(save_path + f'raw_tracking_{video_selection}_{model_name}_{frames[0]}_{frames[-1]}.parquet', index = False)\n",
    "else:\n",
    "    if merge_present:\n",
    "        print('Importing linked trajectories...')\n",
    "        trajectories_pre_merge = pd.read_parquet(save_path + f'raw_tracking_{video_selection}_{model_name}_pre_merge.parquet')\n",
    "        trajectories_post_merge = pd.read_parquet(save_path + f'raw_tracking_{video_selection}_{model_name}_post_merge.parquet')\n",
    "    else:\n",
    "        print('Importing linked trajectories...')\n",
    "        trajectories = pd.read_parquet(save_path + f'raw_tracking_{video_selection}_{model_name}_{frames[0]}_{frames[-1]}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_present:\n",
    "    trajectories = pd.concat((trajectories_pre_merge, trajectories_post_merge)).reset_index(drop=True)\n",
    "\n",
    "if merge_present:\n",
    "    err_frames_pre_merge = np.where(trajectories.loc[trajectories.frame < merge_frame].groupby('frame').count().x.values != nDrops)[0]\n",
    "    err_frames_post_merge = merge_frame + np.where(trajectories.loc[trajectories.frame >= merge_frame].groupby('frame').count().x.values != nDrops-1)[0] \n",
    "    print(f'Number of errors: {len(err_frames_pre_merge)} / {len(frames[:merge_frame])} --> {len(err_frames_pre_merge)/len(frames[:merge_frame])*100:.2f}%')\n",
    "    print(f'Number of errors: {len(err_frames_post_merge)} / {len(frames[merge_frame:])} --> {len(err_frames_post_merge)/len(frames[merge_frame:])*100:.2f}%')\n",
    "    condition = np.ediff1d(err_frames_pre_merge)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs_pre_merge = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors pre merge: {max_n_of_consecutive_errs_pre_merge}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs_pre_merge = 0\n",
    "        print(f'Max number of consecutive errors pre merge: 0')\n",
    "    condition = np.ediff1d(err_frames_post_merge)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs_post_merge = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors post merge: {max_n_of_consecutive_errs_post_merge}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs_post_merge = 0\n",
    "        print(f'Max number of consecutive errors post merge: 0')\n",
    "else:\n",
    "    err_frames = np.where(trajectories.groupby('frame').count().x.values != nDrops)[0]\n",
    "    print(f'Number of errors: {len(err_frames)} / {len(frames)} --> {len(err_frames)/len(frames)*100:.2f}%')\n",
    "    condition = np.ediff1d(err_frames)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors: {max_n_of_consecutive_errs}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs = 0\n",
    "        print(f'Max number of consecutive errors: 0')\n",
    "\n",
    "err_frame = trajectories.loc[trajectories.particle == max(trajectories.particle.unique())].frame.min()\n",
    "if err_frame != 0:\n",
    "    fig, (ax, ax1, ax2) = plt.subplots(1, 3, figsize=(12, 5), sharex=True, sharey=True)\n",
    "    ax.imshow(get_frame(video, err_frame - 2, xmin, ymin, xmax, ymax, w, h, resolution, True))\n",
    "    ax.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = f'Frame {err_frame - 2}')\n",
    "    for i in range(len(trajectories.loc[trajectories.frame == err_frame - 2])):\n",
    "        ax.add_artist(plt.Circle((trajectories.loc[trajectories.frame == err_frame - 2].x.values[i], trajectories.loc[trajectories.frame == err_frame - 2].y.values[i]),\\\n",
    "                                trajectories.loc[trajectories.frame == err_frame - 2].r.values[i], color = trajectories.loc[trajectories.frame == err_frame - 2].color.values[i],\\\n",
    "                                fill = True))\n",
    "    ax1.imshow(get_frame(video, err_frame - 1, xmin, ymin, xmax, ymax, w, h, resolution, True))\n",
    "    ax1.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = f'Frame {err_frame - 1}')\n",
    "    for i in range(len(trajectories.loc[trajectories.frame == err_frame - 1])):\n",
    "        ax1.add_artist(plt.Circle((trajectories.loc[trajectories.frame == err_frame - 1].x.values[i], trajectories.loc[trajectories.frame == err_frame - 1].y.values[i]),\\\n",
    "                                trajectories.loc[trajectories.frame == err_frame - 1].r.values[i], color = trajectories.loc[trajectories.frame == err_frame - 1].color.values[i],\\\n",
    "                                fill = True))\n",
    "    ax2.imshow(get_frame(video, err_frame, xmin, ymin, xmax, ymax, w, h, resolution, True))\n",
    "    ax2.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = f'Frame {err_frame}')\n",
    "    for i in range(len(trajectories.loc[trajectories.frame == err_frame])):\n",
    "        ax2.add_artist(plt.Circle((trajectories.loc[trajectories.frame == err_frame].x.values[i], trajectories.loc[trajectories.frame == err_frame].y.values[i]),\\\n",
    "                                trajectories.loc[trajectories.frame == err_frame].r.values[i], color = trajectories.loc[trajectories.frame == err_frame].color.values[i],\\\n",
    "                                fill = True))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_present:\n",
    "    trajectories = pd.concat((trajectories_pre_merge, trajectories_post_merge)).reset_index(drop=True)\n",
    "n_feature_per_frame = trajectories.groupby('frame').count().x.values\n",
    "fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "ax[0, 0].scatter(trajectories.frame.unique(), n_feature_per_frame, s=0.1)\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].scatter(trajectories.frame, trajectories.r, s=0.1)\n",
    "ax[0, 1].set(xlabel = 'Instance index', ylabel = 'Radius [px]', title = 'Radius of instances detected')\n",
    "ax[1, 0].scatter(trajectories.r, trajectories.eccentricity, s=0.1)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "ax[1, 1].scatter(trajectories.r, trajectories.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f'linked_instances_{model_name}_{frames[0]}_{frames[-1]}.png', dpi = 500)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing interpolated trajectories...\n"
     ]
    }
   ],
   "source": [
    "if interp_verb:\n",
    "    if merge_present:\n",
    "        print('Interpolating trajectories...')\n",
    "        interp_trajectories_pre_merge = trajectories_pre_merge.groupby('particle').progress_apply(interpolate_trajectory)\n",
    "        interp_trajectories_pre_merge = interp_trajectories_pre_merge.reset_index(drop=True)\n",
    "        interp_trajectories_pre_merge['particle'] = interp_trajectories_pre_merge['particle'].astype(int)\n",
    "        interp_trajectories_pre_merge = interp_trajectories_pre_merge.sort_values(['frame', 'particle'])\n",
    "        interp_trajectories_pre_merge.to_parquet(save_path + f'interpolated_tracking_{video_selection}_{model_name}_pre_merge.parquet', index=False)\n",
    "\n",
    "        interp_trajectories_post_merge = trajectories_post_merge.groupby('particle').progress_apply(interpolate_trajectory)\n",
    "        interp_trajectories_post_merge = interp_trajectories_post_merge.reset_index(drop=True)\n",
    "        interp_trajectories_post_merge['particle'] = interp_trajectories_post_merge['particle'].astype(int)\n",
    "        interp_trajectories_post_merge = interp_trajectories_post_merge.sort_values(['frame', 'particle'])\n",
    "        interp_trajectories_post_merge.to_parquet(save_path + f'interpolated_tracking_{video_selection}_{model_name}_post_merge.parquet', index=False)\n",
    "    else:\n",
    "        print('Interpolating trajectories...')\n",
    "        interp_trajectories = trajectories.groupby('particle').progress_apply(interpolate_trajectory)\n",
    "        interp_trajectories = interp_trajectories.reset_index(drop=True)\n",
    "        interp_trajectories['particle'] = interp_trajectories['particle'].astype(int)\n",
    "        interp_trajectories = interp_trajectories.sort_values(['frame', 'particle'])\n",
    "        interp_trajectories = interp_trajectories.reset_index(drop=True)\n",
    "        interp_trajectories.to_parquet(save_path + f'interpolated_tracking_{video_selection}_{model_name}_{startFrame}_{endFrame}.parquet', index=False)\n",
    "else:\n",
    "    if merge_present:\n",
    "        print('Importing interpolated trajectories...')\n",
    "        interp_trajectories_pre_merge = pd.read_parquet(save_path + f'interpolated_tracking_{video_selection}_{model_name}_pre_merge.parquet')\n",
    "        interp_trajectories_post_merge = pd.read_parquet(save_path + f'interpolated_tracking_{video_selection}_{model_name}_post_merge.parquet')\n",
    "    else:\n",
    "        print('Importing interpolated trajectories...')\n",
    "        interp_trajectories = pd.read_parquet(save_path + f'interpolated_tracking_{video_selection}_{model_name}_{startFrame}_{endFrame}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_present:\n",
    "    interp_trajectories = pd.concat((interp_trajectories_pre_merge, interp_trajectories_post_merge)).reset_index(drop=True)\n",
    "n_feature_per_frame = interp_trajectories.groupby('frame').count().x.values\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "ax[0, 0].scatter(interp_trajectories.frame.unique(), n_feature_per_frame, s=0.1)\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].scatter(interp_trajectories.frame, interp_trajectories.r,  s=0.1)\n",
    "ax[0, 1].set(xlabel = 'Frame', ylabel = 'Radius [px]', title = 'Radius of instances detected')\n",
    "ax[1, 0].scatter(interp_trajectories.r, interp_trajectories.eccentricity, s=0.1)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "ax[1, 1].scatter(interp_trajectories.r, interp_trajectories.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f'interp_instances_{model_name}_{startFrame}_{endFrame}.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index       12907592\n",
       "x            6453796\n",
       "y            6453796\n",
       "r            6453796\n",
       "frame        3226898\n",
       "particle     1613449\n",
       "color        1618753\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "x            float32\n",
       "y            float32\n",
       "r            float32\n",
       "frame          int16\n",
       "particle        int8\n",
       "color       category\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reduced to 21.4315 % of the original size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index       19021800\n",
       "x            9510900\n",
       "y            9510900\n",
       "r            9510900\n",
       "frame        9510900\n",
       "particle     2377725\n",
       "color        2381933\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "x            float32\n",
       "y            float32\n",
       "r            float32\n",
       "frame          int32\n",
       "particle        int8\n",
       "color       category\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reduced to 23.2159 % of the original size\n"
     ]
    }
   ],
   "source": [
    "if 0:\n",
    "    if merge_present:\n",
    "        interp_trajectories_subsampled_pre_merge = interp_trajectories_pre_merge.loc[interp_trajectories_pre_merge.frame.isin(interp_trajectories_pre_merge.frame.unique()[::int(fps/10)]), [\"x\", \"y\", \"r\", \"frame\", \"particle\", \"color\"]]\n",
    "        interp_trajectories_subsampled_pre_merge['frame'] = np.array(interp_trajectories_subsampled_pre_merge.frame/int(fps/10)).astype(int)\n",
    "        smooth_trajs_pre_merge = get_smooth_trajs(interp_trajectories_subsampled_pre_merge, windLen = 10, orderofPoly = 4)\n",
    "        ts1 = smooth_trajs_pre_merge.copy()\n",
    "        ts1[\"color\"] = ts1[\"color\"].astype(\"category\")\n",
    "        ts1[\"particle\"] = pd.to_numeric(ts1[\"particle\"], downcast=\"integer\")\n",
    "        ts1[\"frame\"] = pd.to_numeric(ts1[\"frame\"], downcast=\"integer\")\n",
    "        ts1[\"x\"] = pd.to_numeric(ts1[\"x\"], downcast=\"float\")\n",
    "        ts1[\"y\"] = pd.to_numeric(ts1[\"y\"], downcast=\"float\")\n",
    "        ts1[\"r\"] = pd.to_numeric(ts1[\"r\"], downcast=\"float\")\n",
    "        ts1 = ts1.sort_values(['frame', 'particle'])\n",
    "        display(ts1.memory_usage(deep=True))\n",
    "        display(ts1.dtypes)\n",
    "        reduction = ts1.memory_usage(deep=True).sum() / smooth_trajs_pre_merge.memory_usage(deep=True).sum()\n",
    "        print(f\" Reduced to {reduction*100:0.4f} % of the original size\")\n",
    "        ts1.to_parquet(save_path + f'{video_selection}_subsampled{int(fps/10)}_smoothed_windlen10_orderofpoly4_pre_merge', index=False, engine='pyarrow', partition_cols=['particle'])\n",
    "\n",
    "        interp_trajectories_subsampled_post_merge = interp_trajectories_post_merge.loc[interp_trajectories_post_merge.frame.isin(interp_trajectories_post_merge.frame.unique()[::int(fps/10)]), [\"x\", \"y\", \"r\", \"frame\", \"particle\", \"color\"]]\n",
    "        interp_trajectories_subsampled_post_merge['frame'] = np.array(interp_trajectories_subsampled_post_merge.frame/int(fps/10)).astype(int)\n",
    "        smooth_trajs_post_merge = get_smooth_trajs(interp_trajectories_subsampled_post_merge, windLen = 10, orderofPoly = 4)\n",
    "        ts2 = smooth_trajs_post_merge.copy()\n",
    "        ts2[\"color\"] = ts2[\"color\"].astype(\"category\")\n",
    "        ts2[\"particle\"] = pd.to_numeric(ts2[\"particle\"], downcast=\"integer\")\n",
    "        ts2[\"frame\"] = pd.to_numeric(ts2[\"frame\"], downcast=\"integer\")\n",
    "        ts2[\"x\"] = pd.to_numeric(ts2[\"x\"], downcast=\"float\")\n",
    "        ts2[\"y\"] = pd.to_numeric(ts2[\"y\"], downcast=\"float\")\n",
    "        ts2[\"r\"] = pd.to_numeric(ts2[\"r\"], downcast=\"float\")\n",
    "        ts2 = ts2.sort_values(['frame', 'particle'])\n",
    "        display(ts2.memory_usage(deep=True))\n",
    "        display(ts2.dtypes)\n",
    "        reduction = ts2.memory_usage(deep=True).sum() / smooth_trajs_post_merge.memory_usage(deep=True).sum()\n",
    "        print(f\" Reduced to {reduction*100:0.4f} % of the original size\")\n",
    "        ts2.to_parquet(save_path + f'{video_selection}_subsampled{int(fps/10)}_smoothed_windlen10_orderofpoly4_post_merge', index=False, engine='pyarrow', partition_cols=['particle'])\n",
    "    else:\n",
    "        interp_trajectories_subsampled = interp_trajectories.loc[interp_trajectories.frame.isin(interp_trajectories.frame.unique()[::int(fps/10)]), [\"x\", \"y\", \"r\", \"frame\", \"particle\", \"color\"]]\n",
    "        interp_trajectories_subsampled['frame'] = np.array(interp_trajectories_subsampled.frame/int(fps/10)).astype(int)\n",
    "        smooth_trajs = get_smooth_trajs(interp_trajectories_subsampled, windLen = 10, orderofPoly = 4)\n",
    "        ts2 = smooth_trajs.copy()\n",
    "        ts2[\"color\"] = ts2[\"color\"].astype(\"category\")\n",
    "        ts2[\"particle\"] = pd.to_numeric(ts2[\"particle\"], downcast=\"integer\")\n",
    "        ts2[\"frame\"] = pd.to_numeric(ts2[\"frame\"], downcast=\"integer\")\n",
    "        ts2[\"x\"] = pd.to_numeric(ts2[\"x\"], downcast=\"float\")\n",
    "        ts2[\"y\"] = pd.to_numeric(ts2[\"y\"], downcast=\"float\")\n",
    "        ts2[\"r\"] = pd.to_numeric(ts2[\"r\"], downcast=\"float\")\n",
    "        ts2 = ts2.sort_values(['frame', 'particle'])\n",
    "        display(ts2.memory_usage(deep=True))\n",
    "        display(ts2.dtypes)\n",
    "        reduction = ts2.memory_usage(deep=True).sum() / smooth_trajs.memory_usage(deep=True).sum()\n",
    "        print(f\" Reduced to {reduction*100:0.4f} % of the original size\")\n",
    "        ts2.to_parquet(save_path + f'{video_selection}_subsampled{int(fps/10)}_smoothed_windlen10_orderofpoly4', index=False, engine='pyarrow', partition_cols=['particle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    fig, ax = fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    def update_graph(frame):\n",
    "        df = interp_trajectories.loc[(interp_trajectories.frame == frame), [\"x\", \"y\", \"r\", 'color']]\n",
    "        for i in range(len(df)):\n",
    "            graph[i].center = (df.x.values[i], df.y.values[i])\n",
    "            graph[i].radius = df.r.values[i]\n",
    "        graph2.set_data(get_frame(video, frame, xmin, ymin, xmax, ymax, w, h, False))\n",
    "        title.set_text(f'{system_name} Tracking -- t = {round(frame/fps, 1)} s')\n",
    "        return graph\n",
    "\n",
    "    title = ax.set_title(f'{system_name} Tracking -- t = {0} s')\n",
    "    ax.set(xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "    df = interp_trajectories.loc[(interp_trajectories.frame == min(interp_trajectories.frame.unique())), [\"x\", \"y\", \"r\", 'color']]\n",
    "    graph = []\n",
    "    for i in range(len(df)):\n",
    "        graph.append(ax.add_artist(plt.Circle((df.x.values[i], df.y.values[i]), df.r.values[i], color = df.color.values[i],\\\n",
    "                                            fill = False)))\n",
    "    graph2 = ax.imshow(get_frame(video, 0, xmin, ymin, xmax, ymax, w, h, False))\n",
    "    ani = matplotlib.animation.FuncAnimation(fig, update_graph, interp_trajectories.frame.unique(), interval = 5, blit=False)\n",
    "    writer = matplotlib.animation.FFMpegWriter(fps = 30, metadata = dict(artist='Matteo Scandola'), extra_args=['-vcodec', 'libx264'])\n",
    "    ani.save(f'./{save_path}/tracking_video2.mp4', writer=writer, dpi = 200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'err_frames_pre_merge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mconcatenate((\u001b[43merr_frames_pre_merge\u001b[49m, err_frames_post_merge)))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mconcatenate((err_frames_pre_merge, err_frames_post_merge))\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m trajectories\u001b[38;5;241m.\u001b[39mloc[trajectories\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m73391\u001b[39m]\u001b[38;5;241m.\u001b[39mparticle\u001b[38;5;241m.\u001b[39munique() \n",
      "\u001b[0;31mNameError\u001b[0m: name 'err_frames_pre_merge' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.concatenate((err_frames_pre_merge, err_frames_post_merge)))\n",
    "print(np.concatenate((err_frames_pre_merge, err_frames_post_merge)).shape)\n",
    "\n",
    "trajectories.loc[trajectories.frame == 73391].particle.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if video_selection == \"49b1r\":\n",
    "    test_frames = [73391, 73392, 73393, 73394, 73395]\n",
    "    missing_droplet_id = 3\n",
    "\n",
    "smooth_trajs = get_smooth_trajs(interp_trajectories, windLen = 10, orderofPoly = 4)\n",
    "\n",
    "df1 = trajectories.loc[(trajectories.frame < max(test_frames) + 15) & (trajectories.frame > min(test_frames) - 15) & (trajectories.particle == 3)]\n",
    "df2 = interp_trajectories.loc[(interp_trajectories.frame < max(test_frames) + 15) & (interp_trajectories.frame > min(test_frames) - 15) & (interp_trajectories.particle == 3)]\n",
    "df3 = smooth_trajs.loc[(smooth_trajs.frame < max(test_frames) + 15) & (smooth_trajs.frame > min(test_frames) - 15) & (smooth_trajs.particle == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 5))\n",
    "ax[0,0].plot(df1.x, df1.y, 'o', label = 'Raw', zorder = 20)\n",
    "ax[0,0].plot(df2.x, df2.y, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax[0,0].set(xlabel = 'X [px]', ylabel = 'Y [px]', title = 'Position interpolation')\n",
    "ax[0,0].legend()\n",
    "ax[1,0].plot(df1.frame, df1.r, 'o', label = 'Raw', zorder = 20)\n",
    "ax[1,0].plot(df2.frame, df2.r, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax[1,0].set(xlabel = 'Frame', ylabel = 'Radius [px]', title = 'Radius interpolation')\n",
    "ax[1,0].legend()\n",
    "ax[0,1].plot(df1.frame, df1.prob, 'o', label = 'Raw', zorder = 20)\n",
    "ax[0,1].plot(df2.frame, df2.prob, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax[0,1].set(xlabel = 'Frame', ylabel = 'Probability', title = 'Probability interpolation')\n",
    "ax[0,1].legend()\n",
    "ax[1,1].plot(df1.frame, df1.area, 'o', label = 'Raw', zorder = 20)\n",
    "ax[1,1].plot(df2.frame, df2.area, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax[1,1].set(xlabel = 'Frame', ylabel = 'Area [px]', title = 'Area interpolation')\n",
    "ax[1,1].legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f'interp_example_linear.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax.plot(df1.x, df1.y, 'o', label = 'Original', zorder = 20)\n",
    "ax.plot(df2.x, df2.y, '--o', label = 'Interpolated', zorder = 10)\n",
    "ax1.plot(df3.x, df3.y, '--o', label = 'Smoothed', zorder = 10)\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = 'Raw trajectory')\n",
    "ax1.set(xlabel = 'X [px]', ylabel = 'Y [px]', title = 'Smoothed trajectory')\n",
    "ax.legend()\n",
    "plt.savefig(save_path + f'interp_smoothing_example_linear.png', dpi = 500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
