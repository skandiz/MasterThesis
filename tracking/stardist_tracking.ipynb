{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('image', cmap='gray')\n",
    "import matplotlib.animation\n",
    "\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from stardist import _draw_polygons\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "import skimage\n",
    "from scipy.optimize import dual_annealing, minimize\n",
    "from tifffile import imsave, imread\n",
    "from utils import filter_detection_data, get_frame, detect_features, interpolate_trajectory\n",
    "import trackpy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.989263, nms_thresh=0.3.\n",
      "Video has 80794 frames with a resolution of 920x960 and a framerate of 10 fps\n"
     ]
    }
   ],
   "source": [
    "#model_name = 'stardist_trained'          # stardist model trained for 50 epochs on simulated synthetic dataset\n",
    "model_name = 'modified_2D_versatile_fluo' # stardist model trained for 150 epochs on simulated dataset starting from the pretrained 2D versatile fluo model\n",
    "model = StarDist2D(None, name = model_name, basedir = './models/')\n",
    "\n",
    "video_selection = \"49b1r\"\n",
    "if video_selection == \"25b25r-1\":\n",
    "    xmin, ymin, xmax, ymax = 95, 30, 535, 470 \n",
    "    merge_present = False   \n",
    "elif video_selection == \"49b1r\":\n",
    "    xmin, ymin, xmax, ymax = 20, 50, 900, 930\n",
    "    merge_present = True\n",
    "    merge_frame = 32269\n",
    "\n",
    "save_path       = f'./{video_selection}/{model_name}/'\n",
    "source_path     = f'./data/{video_selection}.mp4'\n",
    "system_name     = f'{video_selection} system'\n",
    "nDrops = 50\n",
    "\n",
    "video = cv2.VideoCapture(source_path)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video has {n_frames} frames with a resolution of {w}x{h} and a framerate of {fps} fps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_verb = False\n",
    "detect_verb = False\n",
    "link_verb = True\n",
    "interp_verb = True\n",
    "\n",
    "startFrame = 0\n",
    "endFrame = n_frames - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_verb: \n",
    "    n_samples = 100\n",
    "    test_detection(n_samples, n_frames, nDrops, video_selection, model, model_name, video, xmin, ymin, xmax, ymax, w, h, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if detect_verb:\n",
    "    print(f'Processing from {int(startFrame/fps)} s to {int(endFrame/fps)} s')\n",
    "    sample_frames = np.arange(startFrame, endFrame, 1, dtype=int)\n",
    "    raw_detection_df = detect_features(sample_frames, False, video_selection, model, model_name, video, xmin, ymin, xmax, ymax, w, h, save_path)\n",
    "    \n",
    "    n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "    ax[0, 0].plot(raw_detection_df.frame.unique(), n_feature_per_frame, '.')\n",
    "    ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "    ax[0, 1].plot(raw_detection_df.r, '.')\n",
    "    ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "    ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "    ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "    ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "    ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path + f'raw_features_{model_name}_{startFrame}_{endFrame}.png', dpi = 500)\n",
    "    plt.close()\n",
    "else:\n",
    "    raw_detection_df = pd.read_parquet(save_path + f'raw_detection_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet')\n",
    "    sample_frames = raw_detection_df.frame.unique()\n",
    "\n",
    "    n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "    ax[0, 0].plot(raw_detection_df.frame.unique(), n_feature_per_frame, '.')\n",
    "    ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "    ax[0, 1].plot(raw_detection_df.r, '.')\n",
    "    ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "    ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "    ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "    ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "    ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path + f'raw_features_{model_name}_{startFrame}_{endFrame}.png', dpi = 500)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 27 / 32269 --> 0.08%\n",
      "Number of errors: 157 / 48525 --> 0.32%\n",
      "Max number of consecutive errors pre merge: 0\n",
      "Max number of consecutive errors pre merge: 6\n"
     ]
    }
   ],
   "source": [
    "if merge_present:\n",
    "    err_frames_pre_merge = np.where(raw_detection_df.loc[raw_detection_df.frame < merge_frame].groupby('frame').count().x.values != nDrops)[0]\n",
    "    err_frames_post_merge = merge_frame + np.where(raw_detection_df.loc[raw_detection_df.frame >= merge_frame].groupby('frame').count().x.values != nDrops-1)[0] \n",
    "    print(f'Number of errors: {len(err_frames_pre_merge)} / {len(sample_frames[:merge_frame])} --> {len(err_frames_pre_merge)/len(sample_frames[:merge_frame])*100:.2f}%')\n",
    "    print(f'Number of errors: {len(err_frames_post_merge)} / {len(sample_frames[merge_frame:])} --> {len(err_frames_post_merge)/len(sample_frames[merge_frame:])*100:.2f}%')\n",
    "    condition = np.ediff1d(err_frames_pre_merge)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs_pre_merge = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors pre merge: {max_n_of_consecutive_errs_pre_merge}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs_pre_merge = 0\n",
    "        print(f'Max number of consecutive errors pre merge: 0')\n",
    "    condition = np.ediff1d(err_frames_post_merge)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs_post_merge = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors pre merge: {max_n_of_consecutive_errs_post_merge}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs_post_merge = 0\n",
    "        print(f'Max number of consecutive errors pre merge: 0')\n",
    "else:\n",
    "    err_frames = np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0]\n",
    "    print(f'Number of errors: {len(err_frames)} / {len(sample_frames)} --> {len(err_frames)/len(sample_frames)*100:.2f}%')\n",
    "    condition = np.ediff1d(err_frames)\n",
    "    condition[condition == 1] = True\n",
    "    condition[condition != 1] = False\n",
    "    if 1 in condition:\n",
    "        max_n_of_consecutive_errs = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "        print(f'Max number of consecutive errors: {max_n_of_consecutive_errs}')\n",
    "    else:\n",
    "        max_n_of_consecutive_errs = 0\n",
    "        print(f'Max number of consecutive errors: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge_present: \n",
    "    traj_test = raw_detection_df.loc[raw_detection_df.frame.isin(np.append(err_frames_pre_merge, err_frames_post_merge))]\n",
    "else: \n",
    "    traj_test = raw_detection_df.loc[raw_detection_df.frame.isin(err_frames)]\n",
    "fig, ax = fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "def update_graph(frame):\n",
    "    df = traj_test.loc[(traj_test.frame == frame), [\"x\", \"y\", \"r\"]]\n",
    "    for i in range(len(df)):\n",
    "        graph[i].center = (df.x.values[i], df.y.values[i])\n",
    "        graph[i].radius = df.r.values[i]\n",
    "    graph2.set_data(get_frame(video, frame, xmin, ymin, xmax, ymax, w, h, False))\n",
    "    title.set_text(f'{system_name} Tracking -- t = {round(frame/fps, 1)} s')\n",
    "    return graph\n",
    "\n",
    "title = ax.set_title(f'{system_name} Tracking -- t = {0} s')\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "df = traj_test.loc[(traj_test.frame == min(traj_test.frame.unique())), [\"x\", \"y\", \"r\"]]\n",
    "graph = []\n",
    "for i in range(len(df)):\n",
    "    graph.append(ax.add_artist(plt.Circle((df.x.values[i], df.y.values[i]), df.r.values[i], color = 'red',\\\n",
    "                                           fill = False, alpha = 0.5, linewidth=1)))\n",
    "graph2 = ax.imshow(get_frame(video, 0, xmin, ymin, xmax, ymax, w, h, False))\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, traj_test.frame.unique(), interval = 5, blit=False)\n",
    "writer = matplotlib.animation.FFMpegWriter(fps = 30, metadata = dict(artist='Matteo Scandola'), extra_args=['-vcodec', 'libx264'])\n",
    "ani.save(f'./{save_path}/tracking_video_errors.mp4', writer=writer, dpi = 200)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 32268: 50 trajectories present.\n"
     ]
    }
   ],
   "source": [
    "if link_verb:\n",
    "    if merge_present:\n",
    "        print('Linking trajectories...')\n",
    "        cutoff = 100\n",
    "\n",
    "        ## PRE MERGE\n",
    "        t = tp.link_df(raw_detection_df.loc[raw_detection_df.frame < merge_frame], cutoff,\\\n",
    "                                 memory = max_n_of_consecutive_errs_pre_merge, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "        t = t.sort_values(['frame', 'particle'])\n",
    "        trajectories_pre_merge = tp.filter_stubs(t, 25)\n",
    "        # CREATE COLOR COLUMN AND SAVE DF\n",
    "        n = max(trajectories_pre_merge.particle)\n",
    "        print(f'N of droplets pre merge: {n + 1}')\n",
    "        random.seed(5)\n",
    "        colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "        for i in range(max(trajectories_pre_merge.particle)+1-n):\n",
    "            colors.append('#00FFFF')\n",
    "        c = []\n",
    "        for p in t.particle:\n",
    "            c.append(colors[p])\n",
    "        trajectories_pre_merge['color'] = c\n",
    "        trajectories_pre_merge = trajectories_pre_merge.reset_index(drop=True)\n",
    "        trajectories_pre_merge.to_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_pre_merge.parquet', index = False)\n",
    "\n",
    "        ## POST MERGE\n",
    "        t = tp.link_df(raw_detection_df.loc[raw_detection_df.frame >= merge_frame], cutoff,\\\n",
    "                                  memory = max_n_of_consecutive_errs_post_merge, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "        t = t.sort_values(['frame', 'particle'])\n",
    "        trajectories_post_merge = tp.filter_stubs(t, 25)\n",
    "        # CREATE COLOR COLUMN AND SAVE DF\n",
    "        n = max(trajectories_post_merge.particle)\n",
    "        print(f'N of droplets post merge: {n + 1}')\n",
    "        random.seed(5)\n",
    "        colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "        for i in range(max(trajectories_post_merge.particle)+1-n):\n",
    "            colors.append('#00FFFF')\n",
    "        c = []\n",
    "        for p in t.particle:\n",
    "            c.append(colors[p])\n",
    "        trajectories_post_merge['color'] = c\n",
    "        trajectories_post_merge = trajectories_post_merge.reset_index(drop=True)\n",
    "        trajectories_post_merge.to_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_post_merge.parquet', index = False)\n",
    "    else:\n",
    "        print('Linking trajectories...')\n",
    "        cutoff = 100\n",
    "        t = tp.link_df(raw_detection_df, cutoff, memory = max_n_of_consecutive_errs, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "        #print(t)\n",
    "        t = t.sort_values(['frame', 'particle'])\n",
    "        trajectories = tp.filter_stubs(t, 25)\n",
    "        # CREATE COLOR COLUMN AND SAVE DF\n",
    "        n = max(trajectories.particle)\n",
    "        print(f'N of droplets: {n + 1}')\n",
    "        random.seed(5)\n",
    "        colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "        for i in range(max(trajectories.particle)+1-n):\n",
    "            colors.append('#00FFFF')\n",
    "        c = []\n",
    "        for p in t.particle:\n",
    "            c.append(colors[p])\n",
    "        trajectories['color'] = c\n",
    "        trajectories = trajectories.reset_index(drop=True)\n",
    "        trajectories.to_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet', index = False)\n",
    "else:\n",
    "    print('Importing linked trajectories...')\n",
    "    trajectories = pd.read_parquet(save_path + f'raw_tracking_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interp_verb:\n",
    "    if merge_present:\n",
    "        print('Interpolating trajectories...')\n",
    "        interp_trajectories_pre_merge = trajectories_pre_merge.groupby('particle').apply(interpolate_trajectory)\n",
    "        interp_trajectories_pre_merge = interp_trajectories_pre_merge.reset_index(drop=True)\n",
    "        interp_trajectories_pre_merge['particle'] = interp_trajectories_pre_merge['particle'].astype(int)\n",
    "        interp_trajectories_pre_merge = interp_trajectories_pre_merge.sort_values(['frame', 'particle'])\n",
    "        interp_trajectories_pre_merge.to_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_pre_merge.parquet', index=False)\n",
    "\n",
    "        interp_trajectories_post_merge = trajectories_post_merge.groupby('particle').apply(interpolate_trajectory)\n",
    "        interp_trajectories_post_merge = interp_trajectories_post_merge.reset_index(drop=True)\n",
    "        interp_trajectories_post_merge['particle'] = interp_trajectories_post_merge['particle'].astype(int)\n",
    "        interp_trajectories_post_merge = interp_trajectories_post_merge.sort_values(['frame', 'particle'])\n",
    "        interp_trajectories_post_merge.to_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_post_merge.parquet', index=False)\n",
    "    else:\n",
    "        print('Interpolating trajectories...')\n",
    "        interp_trajectories = trajectories.groupby('particle').apply(interpolate_trajectory)\n",
    "        interp_trajectories = interp_trajectories.reset_index(drop=True)\n",
    "        interp_trajectories['particle'] = interp_trajectories['particle'].astype(int)\n",
    "        interp_trajectories = interp_trajectories.sort_values(['frame', 'particle'])\n",
    "        interp_trajectories.to_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet', index=False)\n",
    "else:\n",
    "    if merge_present:\n",
    "        print('Importing interpolated trajectories...')\n",
    "        interp_trajectories_pre_merge = pd.read_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_pre_merge.parquet')\n",
    "        interp_trajectories_post_merge = pd.read_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_post_merge.parquet')\n",
    "    else:\n",
    "        print('Importing interpolated trajectories...')\n",
    "        interp_trajectories = pd.read_parquet(save_path + f'interpolated_tracking_{video_selection}_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature_per_frame = interp_trajectories.groupby('frame').count().x.values\n",
    "fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "ax[0, 0].plot(interp_trajectories.frame.unique(), n_feature_per_frame, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(interp_trajectories.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].scatter(interp_trajectories.r, interp_trajectories.eccentricity, s=0.1)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "ax[1, 1].scatter(interp_trajectories.r, interp_trajectories.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f'interp_features_{model_name}_{startFrame}_{endFrame}.png', dpi = 500)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "def update_graph(frame):\n",
    "    df = interp_trajectories.loc[(interp_trajectories.frame == frame), [\"x\", \"y\", \"r\", 'color']]\n",
    "    for i in range(len(df)):\n",
    "        graph[i].center = (df.x.values[i], df.y.values[i])\n",
    "        graph[i].radius = df.r.values[i]\n",
    "    graph2.set_data(get_frame(video, frame, xmin, ymin, xmax, ymax, w, h, False))\n",
    "    title.set_text(f'{system_name} Tracking -- t = {round(frame/fps, 1)} s')\n",
    "    return graph\n",
    "\n",
    "title = ax.set_title(f'{system_name} Tracking -- t = {0} s')\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "df = interp_trajectories.loc[(interp_trajectories.frame == min(interp_trajectories.frame.unique())), [\"x\", \"y\", \"r\", 'color']]\n",
    "graph = []\n",
    "for i in range(len(df)):\n",
    "    graph.append(ax.add_artist(plt.Circle((df.x.values[i], df.y.values[i]), df.r.values[i], color = df.color.values[i],\\\n",
    "                                           fill = False)))\n",
    "graph2 = ax.imshow(get_frame(video, 0, xmin, ymin, xmax, ymax, w, h, False))\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, interp_trajectories.frame.unique(), interval = 5, blit=False)\n",
    "writer = matplotlib.animation.FFMpegWriter(fps = 30, metadata = dict(artist='Matteo Scandola'), extra_args=['-vcodec', 'libx264'])\n",
    "ani.save(f'./{save_path}/tracking_video2.mp4', writer=writer, dpi = 200)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
