{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib ipympl\n",
    "\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tifffile import imsave\n",
    "from tqdm import tqdm\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from csbdeep.utils import Path, normalize\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCE IMAGES FROM VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_crop_and_resize(cap, frame, x1, y1, x2, y2, w, h):\n",
    "\tcap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "\tret, image = cap.read()\n",
    "\tnpImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\tnpImage = npImage[y1:y2, x1:x2]\n",
    "\treturn cv2.resize(npImage, (500, 500))\n",
    "\n",
    "def get_frame(cap, frame, x1, y1, x2, y2, w, h):\n",
    "\tcap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "\tret, image = cap.read()\n",
    "\tnpImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\talpha = Image.new('L', (w, h), 0)\n",
    "\tdraw = ImageDraw.Draw(alpha)\n",
    "\tdraw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\tnpAlpha = np.array(alpha)\n",
    "\tnpImage = npImage*npAlpha\n",
    "\tind = np.where(npImage == 0)\n",
    "\tnpImage[ind] = npImage[200, 200]\n",
    "\tnpImage = npImage[y1:y2, x1:x2]\n",
    "\treturn cv2.resize(npImage, (500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './training_dataset/'\n",
    "nDrops = 50\n",
    "\n",
    "source_path_25b25r = \"./data/25b25r-1.mp4\" \n",
    "xmin_25b25r, ymin_25b25r, xmax_25b25r, ymax_25b25r = 95, 30, 535, 470\n",
    "video_25b25r = cv2.VideoCapture(source_path_25b25r)\n",
    "video_25b25r.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w_25b25r = int(video_25b25r.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h_25b25r = int(video_25b25r.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_25b25r = int(video_25b25r.get(cv2.CAP_PROP_FPS))\n",
    "n_frames_25b25r = int(video_25b25r.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"25b25r video has {n_frames_25b25r} frames with a resolution of {w_25b25r}x{h_25b25r} and a framerate of {fps_25b25r} fps\")\n",
    "\n",
    "\n",
    "source_path_49b1r  = \"./data/49b1r.mp4\"\n",
    "xmin_49b1r,  ymin_49b1r,  xmax_49b1r,  ymax_49b1r  = 20, 50, 900, 930\n",
    "nDrops_post_merge_49b1r = 49\n",
    "video_49b1r = cv2.VideoCapture(source_path_49b1r)\n",
    "video_49b1r.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w_49b1r = int(video_49b1r.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h_49b1r = int(video_49b1r.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_49b1r = int(video_49b1r.get(cv2.CAP_PROP_FPS))\n",
    "n_frames_49b1r = int(video_49b1r.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"49b1r video has {n_frames_49b1r} frames with a resolution of {w_49b1r}x{h_49b1r} and a framerate of {fps_49b1r} fps\")\n",
    "print(f\"25b25r video can be cropped to : {ymax_25b25r - ymin_25b25r, xmax_25b25r - xmin_25b25r}\")\n",
    "print(f\"49b1r  video can be cropped to : {ymax_49b1r -  ymin_49b1r,  xmax_49b1r -  xmin_49b1r }\")\n",
    "\n",
    "start_49b1r = get_frame(video_49b1r, 0, xmin_49b1r, ymin_49b1r, xmax_49b1r, ymax_49b1r, w_49b1r, h_49b1r)\n",
    "end_49b1r = get_frame(video_49b1r, n_frames_49b1r-1, xmin_49b1r, ymin_49b1r, xmax_49b1r, ymax_49b1r, w_49b1r, h_49b1r)\n",
    "start_25b25r = get_frame(video_25b25r, 0, xmin_25b25r, ymin_25b25r, xmax_25b25r, ymax_25b25r, w_25b25r, h_25b25r)\n",
    "end_25b25r = get_frame(video_25b25r, n_frames_25b25r-1, xmin_25b25r, ymin_25b25r, xmax_25b25r, ymax_25b25r, w_25b25r, h_25b25r)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "ax[0,0].imshow(start_49b1r, cmap='gray', vmin=0, vmax=255)\n",
    "ax[0,0].set_title('Start 49b1r')\n",
    "ax[0,1].imshow(end_49b1r, cmap='gray', vmin=0, vmax=255)\n",
    "ax[0,1].set_title('End 49b1r')\n",
    "ax[1,0].imshow(start_25b25r, cmap='gray', vmin=0, vmax=255)\n",
    "ax[1,0].set_title('Start 25b25r')\n",
    "ax[1,1].imshow(end_25b25r, cmap='gray', vmin=0, vmax=255)\n",
    "ax[1,1].set_title('End 25b25r')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "n_samples_49b1r  = 100\n",
    "n_samples_25b25r = 100\n",
    "n_samples = n_samples_49b1r + n_samples_25b25r\n",
    "\n",
    "np.random.seed(0)\n",
    "sample_frames_49b1r  = np.sort(np.array(random.sample(range(30000 ), n_samples_49b1r )), axis=0)\n",
    "sample_frames_25b25r = np.sort(np.array(random.sample(range(n_frames_25b25r), n_samples_25b25r)), axis=0)\n",
    "\n",
    "for frame in tqdm(sample_frames_49b1r):\n",
    "    imsave(f\"{save_path}49b1r/image/49b1r_frame{frame}.tif\", get_frame(video_49b1r, frame, xmin_49b1r, ymin_49b1r, xmax_49b1r, ymax_49b1r, w_49b1r, h_49b1r))\n",
    "\n",
    "for frame in tqdm(sample_frames_25b25r):\n",
    "    imsave(f\"{save_path}25b25r/image/25b25r_frame{frame}.tif\", get_frame(video_25b25r, frame, xmin_25b25r, ymin_25b25r, xmax_25b25r, ymax_25b25r, w_25b25r, h_25b25r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYNTHETIC DATASET GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(cap, frame, x1, y1, x2, y2, w, h):\n",
    "\tcap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "\tret, image = cap.read()\n",
    "\tnpImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\talpha = Image.new('L', (w, h), 0)\n",
    "\tdraw = ImageDraw.Draw(alpha)\n",
    "\tdraw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\tnpAlpha = np.array(alpha)\n",
    "\tnpImage = npImage*npAlpha\n",
    "\tind = np.where(npImage == 0)\n",
    "\tnpImage[ind] = npImage[200, 200]\n",
    "\tnpImage = npImage[y1:y2, x1:x2]\n",
    "\tnpImage = cv2.resize(npImage, (500, 500))\n",
    "\treturn npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path_25b25r = \"./data/25b25r-1.mp4\" \n",
    "xmin_25b25r, ymin_25b25r, xmax_25b25r, ymax_25b25r = 95, 30, 535, 470\n",
    "video_25b25r = cv2.VideoCapture(source_path_25b25r)\n",
    "video_25b25r.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w_25b25r = int(video_25b25r.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h_25b25r = int(video_25b25r.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_25b25r = int(video_25b25r.get(cv2.CAP_PROP_FPS))\n",
    "n_frames_25b25r = int(video_25b25r.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\n",
    "source_path_49b1r  = \"./data/49b1r.mp4\"\n",
    "xmin_49b1r,  ymin_49b1r,  xmax_49b1r,  ymax_49b1r  = 20, 50, 900, 930\n",
    "video_49b1r = cv2.VideoCapture(source_path_49b1r)\n",
    "video_49b1r.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w_49b1r = int(video_49b1r.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h_49b1r = int(video_49b1r.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_49b1r = int(video_49b1r.get(cv2.CAP_PROP_FPS))\n",
    "n_frames_49b1r = int(video_49b1r.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "start_49b1r = get_frame(video_49b1r, 0, xmin_49b1r, ymin_49b1r, xmax_49b1r, ymax_49b1r, w_49b1r, h_49b1r)\n",
    "end_49b1r = get_frame(video_49b1r, n_frames_49b1r-1, xmin_49b1r, ymin_49b1r, xmax_49b1r, ymax_49b1r, w_49b1r, h_49b1r)\n",
    "start_25b25r = get_frame(video_25b25r, 0, xmin_25b25r, ymin_25b25r, xmax_25b25r, ymax_25b25r, w_25b25r, h_25b25r)\n",
    "end_25b25r = get_frame(video_25b25r, n_frames_25b25r-1, xmin_25b25r, ymin_25b25r, xmax_25b25r, ymax_25b25r, w_25b25r, h_25b25r)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "ax[0,0].imshow(start_49b1r, cmap='gray', vmin=0, vmax=255)\n",
    "ax[0,0].set_title('Start 49b1r')\n",
    "ax[0,1].imshow(end_49b1r, cmap='gray', vmin=0, vmax=255)\n",
    "ax[0,1].set_title('End 49b1r')\n",
    "ax[1,0].imshow(start_25b25r, cmap='gray', vmin=0, vmax=255)\n",
    "ax[1,0].set_title('Start 25b25r')\n",
    "ax[1,1].imshow(end_25b25r, cmap='gray', vmin=0, vmax=255)\n",
    "ax[1,1].set_title('End 25b25r')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circle_with_index(mask, center, radius, index):\n",
    "    cv2.circle(mask, center, radius, (index), -1)\n",
    "\n",
    "def overlap_between_circles(existing_circles, center, radius, min_distance):\n",
    "    for existing_center in existing_circles:\n",
    "        distance = np.linalg.norm(np.array(existing_center[0]) - np.array(center))\n",
    "        if distance < radius + existing_center[1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def create_gaussian(center, img_width, img_height, sigma, ampl):\n",
    "    center_x, center_y = center\n",
    "    x = np.linspace(0, img_width-1, img_width)\n",
    "    y = np.linspace(0, img_height-1, img_height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    gaussian = np.exp(-((X-center_x)**2 + (Y-center_y)**2) / (2.0 * sigma**2))\n",
    "    return np.round(ampl*(gaussian / np.max(gaussian))).astype(np.uint8)\n",
    "\n",
    "def generate_synthetic_image():\n",
    "    num_circles = 50 \n",
    "\n",
    "    # Create a black background image\n",
    "    height, width = 500, 500\n",
    "    image = np.random.randint(65, 75, (height, width), dtype=np.uint8) #np.ones((height, width), dtype=np.uint8)*70\n",
    "    outer_radius = 200\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    list_of_centers = []\n",
    "    list_of_distances = []\n",
    "    circles_array = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Draw circles on the background image and mask\n",
    "    for i in range(num_circles):\n",
    "        while True:\n",
    "            # Generate random circle properties\n",
    "            theta = random.uniform(0, 2 * np.pi)\n",
    "            r = random.randint(0, outer_radius)\n",
    "            center = (int(width/2 + r * np.cos(theta)), int(height/2 + r * np.sin(theta)))\n",
    "\n",
    "            feature_radius = 10# random.randint(9, 10)\n",
    "\n",
    "            if not overlap_between_circles(list_of_centers, center, feature_radius, feature_radius):\n",
    "                list_of_centers.append([center, feature_radius])\n",
    "                break\n",
    "        color = 110 #(random.randint(0, 255))\n",
    "        index = i + 1  # Assign unique index (starting from 1)\n",
    "        # Draw the circle on the image \n",
    "        # lineType = 4 for 4-connected line, 8 for 8-connected line, LINE_AA for antialiased line\n",
    "        cv2.circle(image, center, feature_radius, color, -1, lineType=4) \n",
    "\n",
    "        # draw circles as gaussian distribution\n",
    "        circles_array += create_gaussian(center, width, height, feature_radius/2, 10)\n",
    "\n",
    "        # Draw the circle with its index on the mask\n",
    "        draw_circle_with_index(mask, center, feature_radius, index)\n",
    "\n",
    "    # Draw the outer circle mimicking the petri dish\n",
    "    image = image + circles_array\n",
    "    cv2.circle(image, (int(height/2), int(width/2)), int(width/2), 150) \n",
    "    cv2.circle(image, (int(height/2), int(width/2)), int(width/2)-4, 150) \n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                    [-1, 5,-1],\n",
    "                    [0, -1, 0]])\n",
    "    #image = cv2.filter2D(image, ddepth=-1, kernel=kernel)\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 4)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img, test_mask = generate_synthetic_image()\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10, 5), sharex=True, sharey=True)\n",
    "axs[0,0].imshow(test_img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0,1].imshow(start_49b1r, cmap='gray', vmin=0, vmax=255)\n",
    "axs[0,2].imshow(start_25b25r, cmap='gray', vmin=0, vmax=255)\n",
    "axs[1,0].imshow(test_mask, cmap=lbl_cmap)\n",
    "axs[1,1].imshow(end_49b1r, cmap='gray', vmin=0, vmax=255)\n",
    "axs[1,2].imshow(end_25b25r, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "axs[0,0].set(xticks=[], yticks=[], title='Synthetic')\n",
    "axs[0,1].set(xticks=[], yticks=[], title='49b1r')\n",
    "axs[0,2].set(xticks=[], yticks=[], title='25b25r')\n",
    "axs[1,0].set(xticks=[], yticks=[], title='Synthetic mask')\n",
    "axs[1,1].set(xticks=[], yticks=[], title='49b1r')\n",
    "axs[1,2].set(xticks=[], yticks=[], title='25b25r')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    img, mask = generate_synthetic_image()\n",
    "    imsave(f'./synthetic_dataset/image/synthetic_image_{i}.tif', img)\n",
    "    imsave(f'./synthetic_dataset/mask/synthetic_mask_{i}.tif', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(img_aug, cmap='gray', vmin=0, vmax=255)\n",
    "ax[0].set_title('Augmented Image')\n",
    "ax[1].imshow(lbl_aug, cmap='gray')\n",
    "ax[1].set_title('Augmented Mask')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOUGH-CIRCLE DATASET GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FROM DATA OF 49b-1r HOUGH CIRCLE METHOD DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(cap, frame, x1, y1, x2, y2, w, h, preprocess):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "    ret, image = cap.read()\n",
    "    if preprocess:\n",
    "        npImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        alpha = Image.new('L', (w, h), 0)\n",
    "        draw = ImageDraw.Draw(alpha)\n",
    "        draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "        npAlpha = np.array(alpha)\n",
    "        npImage = npImage*npAlpha\n",
    "        ind = np.where(npImage == 0)\n",
    "        npImage[ind] = npImage[200, 200]\n",
    "        npImage = npImage[y1:y2, x1:x2]\n",
    "        return npImage\n",
    "    elif not preprocess:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        raise ValueError(\"preprocess must be a boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = pd.read_parquet('./49b_1r/old/tracking_data/hough/tracking_hough_trackpy_linking.parquet')\n",
    "# rename column to be consistent with the other datasets\n",
    "trajectories.rename(columns={'d':'r'}, inplace=True)\n",
    "# remove rows with NaN values in the radius column\n",
    "trajectories.dropna(subset=['r'], inplace=True)\n",
    "display(trajectories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('/Users/matteoscandola/MasterThesis/tracking/data/49b1r.mp4')\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, first_frame = video.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample x frames from the hough-method tracking dataset\n",
    "n_samples = 1000\n",
    "np.random.seed(42)\n",
    "sample_frames = np.sort(np.random.choice(trajectories.frame.unique().astype(int), size=n_samples, replace=False))\n",
    "\n",
    "for frame in tqdm(sample_frames):\n",
    "    frame_img = get_frame(video, frame, 55, 55, 880, 880, 920, 960, True)\n",
    "    imsave(f\"/Users/matteoscandola/MasterThesis/tracking/train_49b-1r/image/49b1r_frame{frame}.tif\", frame_img)\n",
    "    df = trajectories.loc[(trajectories.frame == frame), [\"x\", \"y\", \"r\"]]\n",
    "    image = np.zeros((880 - 55, 880 - 55), dtype=np.uint8)\n",
    "    count = 0\n",
    "    for _, droplet in df.iterrows():\n",
    "        x, y, radius = droplet['x'], droplet['y'], droplet['r']\n",
    "        cv2.circle(image, (int(x)- 55, int(y) - 55), int(radius), int(count), thickness=-1)\n",
    "        count += 1\n",
    "    imsave(f\"/Users/matteoscandola/MasterThesis/tracking/train_49b-1r/mask/49b1r_frame{frame}.tif\", image)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATING NEW HOUGH CIRCLE DETECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_hough(cap, frame, x1, y1, x2, y2, w, h):\n",
    "\tcap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "\tret, image = cap.read()\n",
    "\tnpImage = np.array(image)\n",
    "\talpha = Image.new('L', (w, h), 0)\n",
    "\tdraw = ImageDraw.Draw(alpha)\n",
    "\tdraw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\tnpAlpha = np.array(alpha)\n",
    "\tnpImage = cv2.cvtColor(npImage, cv2.COLOR_BGR2GRAY)*npAlpha \n",
    "\tind = np.where(npImage == 0)\n",
    "\tnpImage[ind] = npImage[200, 200]\n",
    "\tnpImage = npImage[y1:y2, x1:x2]\n",
    "\treturn npImage \n",
    "\t\n",
    "def hough_loc_frame(correct_n, frame, img, parameters):\n",
    "\tfound_circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, **parameters)\n",
    "\tif found_circles is not None:\n",
    "\t\treturn np.hstack((found_circles[0], (np.ones((found_circles.shape[1], 1), dtype=int)*frame),\\\n",
    "\t\t\t\t\t\t\tnp.ones((found_circles.shape[1], 1), dtype=int)*found_circles.shape[1]))\n",
    "\telse:\n",
    "\t\treturn np.hstack((np.ones((1, 3))*-1, np.array([[frame, 0]])))\n",
    "\t\t\n",
    "def hough_feature_location(sample_frames, correct_n, params):\n",
    "\ttemp = []\n",
    "\tfor frame in tqdm(sample_frames):\n",
    "\t\timg = get_frame_hough(video, frame, xmin, ymin, xmax, ymax, w, h)\n",
    "\t\ttemp.append(hough_loc_frame(correct_n, frame, img, params))\n",
    "\t\n",
    "\ttemp_df = pd.DataFrame(np.concatenate([arr for arr in temp]), columns = [\"x\", \"y\", \"d\", \"frame\", \"nDroplets\"])\n",
    "\ttemp_df[\"frame\"] = temp_df[\"frame\"].astype(int)\n",
    "\ttemp_df[\"nDroplets\"] = temp_df[\"nDroplets\"].astype(int)\n",
    "\terr_frames = temp_df.loc[temp_df.nDroplets != correct_n].frame.unique().astype(int)\n",
    "\tloss = err_frames.shape[0]/sample_frames.shape[0]\n",
    "\treturn temp_df, err_frames, loss\n",
    "\n",
    "def optimize_params(x, *args):\n",
    "\tframes, correct_n = args\n",
    "\tparams = {\"dp\":x[0], \"minDist\":int(x[1]), \"param1\":x[2], \"param2\":x[3], \"minRadius\":int(x[4]), \"maxRadius\":int(x[5])}\n",
    "\terrs = 0\n",
    "\tfor i in tqdm(frames):\n",
    "\t\timg = get_frame_hough(video, i, xmin, ymin, xmax, ymax, w, h)\n",
    "\t\tfound_circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, **params)\n",
    "\t\tif (found_circles is not None) and (found_circles.shape[1] == correct_n):\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\terrs += 1\n",
    "\t\t\t\n",
    "\tloss = errs/frames.shape[0]\n",
    "\ta = [loss, x[0], int(x[1]), x[2], x[3], int(x[4]), int(x[5])]\n",
    "\tprint(a)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "random.seed(0)\n",
    "sample_frames = np.sort(np.array(random.sample(range(n_frames), n_samples)), axis=0)\n",
    "\n",
    "test_params = {\"dp\":1.5, \"minDist\":10, \"param1\":20, \"param2\":0.7, \"minRadius\":5, \"maxRadius\":30}\n",
    "\n",
    "temp_df, err_frames, loss = hough_feature_location(sample_frames, nDrops, test_params)\n",
    "print(loss, err_frames)\n",
    "temp_df_test = temp_df.loc[temp_df.frame == err_frames[1]]\n",
    "test_img = get_frame_hough(video, err_frames[1], xmin, ymin, xmax, ymax, w, h)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.imshow(test_img, cmap=\"gray\")\n",
    "for i in range(temp_df_test.nDroplets.iloc[0]):\n",
    "    circle = plt.Circle((temp_df_test.x.iloc[i], temp_df_test.y.iloc[i]), temp_df_test.d.iloc[i], color='r', fill=True, alpha=0.5)\n",
    "    ax.add_artist(circle)\n",
    "ax.set(xticks=[], yticks=[], title=f\"Frame {err_frames[1]} -- {temp_df_test.nDroplets.iloc[0]} droplets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramters of HoughCircles --> dp, minDist, param1, param2, minRadius, maxRadius\n",
    "init_guess =  [2, 5, 20, 0.7, 7, 12] # initial guess for the parameters\n",
    "params_bounds = [(1, 3), (1, 10), (1, 100), (0.3, 1), (5, 10), (10, 15)] # bounds for the parameters\n",
    "\n",
    "opt_result = dual_annealing(optimize_params, x0 = init_guess, args = (sample_frames, nDrops), bounds = params_bounds, maxiter = 2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
