{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e32dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib ipympl\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.rcParams['font.size'] = 8\n",
    "mpl.rc('image', cmap='gray')\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "import matplotlib.animation\n",
    "writervideo = matplotlib.animation.FFMpegWriter(fps=30)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, json\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "tp.quiet()\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "from scipy.optimize import dual_annealing, minimize\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "import random\n",
    "\n",
    "run_analysis_verb = False\n",
    "show_verb = True\n",
    "save_verb = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "807ab6cd",
   "metadata": {},
   "source": [
    "# TRACKPY TRACKING \n",
    "Since in movie.mp4 at frame merge_frame = 32269 two droplets merge together, the tracking procedure is divided into two parts: \\\n",
    "    - Pre merge [0:merge_frame] --> 50 features to locate \\\n",
    "    - Post merge [merge_frame:] --> 49 features to locate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE PROCESSING\n",
    "@pims.pipeline\n",
    "def trackpy_preprocessing(image, x1, y1, x2, y2):    \n",
    "    npImage = np.array(image)\n",
    "    # Create same size alpha layer with circle\n",
    "    #alpha = Image.new('L', (920, 960), 0)\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\n",
    "    # Convert alpha Image to numpy arrayf\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = npImage[:, :, 1] * npAlpha\n",
    "    \n",
    "    ind = np.where(npImage == 0)\n",
    "    # npImage[200, 200] color of the border to swap with the black\n",
    "    npImage[ind] = npImage[200, 200]\n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import video with pre processing applied\n",
    "data = trackpy_preprocessing(pims.open('./data/movie.mp4'), 55, 55, 880, 880)\n",
    "data_ref = pims.open('./data/movie.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 0\n",
    "fig, (ax, ax1) = plt.subplots(1, 2)\n",
    "ax.imshow(data_ref[frame])\n",
    "ax.set(title = f'Original - frame {frame}', xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "ax1.imshow(data[frame])\n",
    "ax1.set(title = f'Processed - frame {frame}', xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "plt.tight_layout()\n",
    "if save_verb: plt.savefig('./results/pre_processing_example.png', bbox_inches='tight')\n",
    "if show_verb: \n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c383209e",
   "metadata": {},
   "source": [
    "## PRE MERGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0181830",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_analysis_verb = False\n",
    "if run_analysis_verb:\n",
    "    ###############################################################################################\n",
    "    #                                           PARAMETERS                                        #\n",
    "    ###############################################################################################\n",
    "    dropSize = 31  \n",
    "    minMass = 2000\n",
    "    sep = 16\n",
    "    nDrops = 50\n",
    "    trackpy_params = {\"dropSize\": dropSize, \"minMass\": minMass, \"sep\": sep, \"nDrops\": nDrops}\n",
    "    # save parameters used for the trial tracking:\n",
    "    with open('./results/tracking_data/trackpy_trial_params.txt', 'w') as fp:\n",
    "        json.dump(trackpy_params, fp)\n",
    "\n",
    "    ###############################################################################################\n",
    "    #                                     FEATURES LOCATION                                       #\n",
    "    ###############################################################################################\n",
    "    nFrames = 100 # up to merge_frame\n",
    "    startFrame = 0\n",
    "    endFrame = startFrame + nFrames\n",
    "    f = tp.batch(data[startFrame:endFrame], dropSize, minmass = minMass, separation = sep, topn = nDrops, engine = 'numba')    \n",
    "    display(f)\n",
    "\n",
    "    ###############################################################################################\n",
    "    #                                      FEATURES LINKING                                       #\n",
    "    ###############################################################################################\n",
    "    t = tp.link_df(f, 150, memory = 2, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "    display(t)\n",
    "\n",
    "    # CREATE COLOR COLUMN AND SAVE DF\n",
    "    n = max(t.particle)\n",
    "    print(n)\n",
    "    random.seed(5)\n",
    "    colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "    for i in range(max(t.particle)+1-n):\n",
    "        colors.append(\"#00FFFF\")\n",
    "    c = []\n",
    "    for p in t.particle:\n",
    "        c.append(colors[p])\n",
    "    t[\"color\"] = c\n",
    "    trajectory = t.copy()\n",
    "    trajectory.to_parquet('./results/tracking_data/trackpy_trial.parquet')\n",
    "    display(trajectory)\n",
    "else:\n",
    "    try:\n",
    "        trajectory = pd.read_parquet('./results/tracking_data/trackpy_pre_merge_sorted_and_colored.parquet')\n",
    "        display(trajectory)\n",
    "    except:\n",
    "        print(\"ERROR: no trajectory data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# need to work on this\n",
    "\n",
    "# ANOMALIES DETECTION\n",
    "num = np.zeros(1000)\n",
    "for i in range(1000):\n",
    "    num[i] = len(f.loc[f['frame'] == i + startFrame])\n",
    "\n",
    "idx = np.where(num != nDrops)[0]\n",
    "print(idx)\n",
    "if len(idx) != 0:\n",
    "    delta = np.zeros(len(idx)-1)\n",
    "    for i in range(len(idx)-1):\n",
    "        delta[i] = idx[i+1]-idx[i]\n",
    "    print(delta)\n",
    "\n",
    "t = tp.link_df(f, 50, memory = 2, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "t = tp.filter_stubs(t, 50)\n",
    "\n",
    "# ANOMALIES DETECTION\n",
    "n = max(t.particle)\n",
    "print(n)\n",
    "random.seed(5)\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "for i in range(max(t.particle)+1-n):\n",
    "    colors.append(\"#00FFFF\")\n",
    "c = []\n",
    "for p in t.particle:\n",
    "    c.append(colors[p])\n",
    "t[\"color\"] = c\n",
    "\n",
    "display(t)\n",
    "df = t.loc[(t.frame == startFrame+100) , [\"x\", \"y\", \"color\"]]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(df.x, df.y, facecolors = 'none', edgecolors = df.color, s = 50)\n",
    "ax.imshow(data_preload[100])\n",
    "plt.show()\n",
    "df = t.loc[t['frame'] == f1, [\"x\", \"y\", \"color\", \"particle\"]]\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2)\n",
    "ax.scatter(df.x, df.y, s=50, ec = \"w\", facecolor = df.color)\n",
    "ax.imshow(data[f1])\n",
    "df1 = t.loc[t['frame'] == f2, [\"x\", \"y\", \"color\"]]\n",
    "ax1.scatter(df1.x, df1.y, s=50, ec = \"w\", facecolor = df1.color)\n",
    "ax1.imshow(data[f2])\n",
    "plt.show()\n",
    "lost_particles = []\n",
    "for i in range(nFrames-1):\n",
    "    a = t.loc[t.frame == i].sort_values('particle').particle.values\n",
    "    b = t.loc[t.frame == i+1].sort_values('particle').particle.values\n",
    "    ind = np.where(np.in1d(a, b)==False)[0]\n",
    "    if ind.size > 0:\n",
    "        lost_particles.append([i, a[ind]])\n",
    "print(\"Total problems:\", len(lost_particles))\n",
    "print(ind)\n",
    "\n",
    "if len(lost_particles) > 0: \n",
    "    print(f\"First failure occurred at frame {lost_particles[0][0]}\")\n",
    "    f1 = lost_particles[0][0]\n",
    "    f2 = lost_particles[0][0]+1\n",
    "    print(t.loc[t.frame == f1].sort_values('particle').particle.values)\n",
    "    print(t.loc[t.frame == f2].sort_values('particle').particle.values)\n",
    "\n",
    "if len(lost_particles)>0: \n",
    "    fig, (ax, ax1) = plt.subplots(1, 2)\n",
    "    df = t.loc[t['frame'] == f1, [\"x\", \"y\", \"color\", \"particle\"]]\n",
    "    ax.scatter(df.x, df.y, s=50, ec = \"w\", facecolor = df.color)\n",
    "    #ax.scatter(df.loc[df.particle==43].x, df.loc[df.particle==43].y, s=100)\n",
    "    #ax.scatter(df.loc[df.particle==82].x, df.loc[df.particle==82].y, s=100)\n",
    "    ax.imshow(data[f1])\n",
    "\n",
    "    df1 = t.loc[t['frame'] == f2, [\"x\", \"y\", \"color\"]]\n",
    "    ax1.scatter(df1.x, df1.y, s=50, ec = \"w\", facecolor = df1.color)\n",
    "    ax1.imshow(data[f2])\n",
    "\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bd424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# animated plot of the tracking results\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(frame):\n",
    "    df = trajectory.loc[(trajectory.frame == frame) , [\"x\",\"y\",\"color\",\"size\"]]\n",
    "    for i in range(50):\n",
    "        graph[i].center = (df.x.values[i], df.y.values[i])\n",
    "        graph[i].radius = 2*df[\"size\"].values[i]\n",
    "    graph2.set_data(data[frame])\n",
    "    title.set_text('Tracking raw - frame = {}'.format(frame))\n",
    "    return graph\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "title = ax.set_title('Tracking raw - frame = 0')\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "df = trajectory.loc[(trajectory.frame == 0), [\"x\",\"y\",\"color\",\"size\"]]\n",
    "\n",
    "graph = []\n",
    "for i in range(50):\n",
    "    graph.append(ax.add_artist(plt.Circle((df.x.values[i], df.y.values[i]), 2*df[\"size\"].values[i], color = df.color.values[i],\\\n",
    "                                           fill = False, linewidth=1)))\n",
    "graph2 = ax.imshow(data[0])\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, range(0, max(trajectory.frame), 1), interval = 5, blit=False)\n",
    "if 0: \n",
    "    writer = matplotlib.animation.FFMpegWriter(fps = 30, metadata = dict(artist='Matteo Scandola'), extra_args=['-vcodec', 'libx264'])\n",
    "    ani.save('./results/tracking_raw_trial.mp4', writer=writer, dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec4587f9",
   "metadata": {},
   "source": [
    "## POST MERGE  - to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the tracking\n",
    "dropSize = 31  \n",
    "minMass = 2000\n",
    "sep = 16\n",
    "nDrops = 49\n",
    "\n",
    "# FEATURES LOCATION\n",
    "nFrames = 100 # total number of frames of video --> len(data)\n",
    "startFrame = merge_frame + 100 \n",
    "endFrame = startFrame + nFrames\n",
    "\n",
    "preload = True\n",
    "if preload:\n",
    "    data_preload = list(data[startFrame:endFrame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tp.batch(data_preload, dropSize, minmass = minMass, separation = sep, topn = nDrops, engine = 'numba')    \n",
    "f.frame = f.frame + startFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75fc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "629fb8d1",
   "metadata": {},
   "source": [
    "# HOUGH TRACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9af4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pims.pipeline\n",
    "def hough_preprocessing(image, x1, y1, x2, y2):    \n",
    "    #image = cv2.GaussianBlur(image, ksize = [7,7], sigmaX = 1.5, sigmaY = 1.5)\n",
    "    npImage = np.array(image)\n",
    "    # Create same size alpha layer with circle\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\n",
    "    # Convert alpha Image to numpy array\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = npImage[:, :, 1] * npAlpha\n",
    "    \n",
    "    ind = np.where(npImage == 0)\n",
    "    # npImage[200, 200] color of the border to swap with the black\n",
    "    npImage[ind] = npImage[200, 200]\n",
    "    npImage = cv2.medianBlur(npImage, 5)\n",
    "    return npImage\n",
    "\n",
    "@joblib.delayed\n",
    "def loc_frame(correct_n, frame, img, parameters):\n",
    "\ttemp = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, **parameters)\n",
    "\tif (temp is not None) and (temp.shape[1] == correct_n):\n",
    "\t\treturn np.hstack((temp[0], (np.ones((correct_n, 1), dtype=int)*frame), np.ones((correct_n, 1), dtype=int)*correct_n))\n",
    "\telif (temp is not None) and (temp.shape[1] != correct_n):\n",
    "\t\treturn np.hstack((np.zeros((correct_n, 3)), (np.ones((correct_n, 1), dtype=int)*frame), np.ones((correct_n, 1), dtype=int)*temp.shape[1]))\n",
    "\telse:\n",
    "\t\treturn np.hstack((np.zeros((correct_n, 3)), (np.ones((correct_n, 1), dtype=int)*frame), np.zeros((correct_n, 1), dtype=int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_feature_location(data_preload, frames, correct_n, params):\n",
    "    parallel = joblib.Parallel(n_jobs = -2)\n",
    "    temp = parallel(\n",
    "        loc_frame(correct_n, frame, data_preload[frame-frames[0]], params)\n",
    "        for frame in frames #tqdm(frames)\n",
    "    )\n",
    "    temp = pd.DataFrame(np.array(temp).reshape(len(frames)*correct_n, 5), columns = [\"x\", \"y\", \"d\", \"frame\", \"nDroplets\"])\n",
    "    err_frames = frames[0] + np.where(temp.groupby(\"frame\").mean().nDroplets!=correct_n)[0]\n",
    "    loss = err_frames.shape[0]/frames.shape[0]\n",
    "    return temp, err_frames, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491045fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_params(x, *args):\n",
    "    data_preload, frames, correct_n, writer = args\n",
    "    params = {\"dp\":x[0], \"minDist\":x[1], \"param1\":x[2], \"param2\":x[3], \"minRadius\":int(x[4]), \"maxRadius\":int(x[5])}\n",
    "    _, _, loss = hough_feature_location(data_preload, frames, correct_n, params)\n",
    "    # write to csv loss and parameters\n",
    "    writer.writerow([loss] + list(params.values()))\n",
    "    return loss\n",
    "\n",
    "def plot_optimization_results(opt_result_df, slot2):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(np.arange(0, len(opt_result_df.loss), 1), opt_result_df.loss, 'b-')\n",
    "    ax.set_ylabel(\"loss\", color = 'b') \n",
    "    ax1 = ax.twinx() \n",
    "    ax1.plot(np.arange(0, len(opt_result_df[slot2]), 1), opt_result_df[slot2], 'r.')\n",
    "    ax1.set_ylabel(slot2, color='r')\n",
    "    ax.grid()\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9985feb9",
   "metadata": {},
   "source": [
    "## PRE MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "preload_load_data = False # takes 20 min\n",
    "merge_frame = 32269\n",
    "data = hough_preprocessing(pims.open('./data/movie.mp4'), 40, 55, 895, 910)\n",
    "if preload_load_data: data_preload = list(data[:merge_frame])\n",
    "\n",
    "startFrame = 0\n",
    "endFrame = merge_frame\n",
    "frames = np.arange(startFrame, endFrame, 100)\n",
    "correct_n = 50\n",
    "default_parameters = {\"dp\": 1.5, \"minDist\": 15, \"param1\": 100, \"param2\": 0.8, \"minRadius\": 15, \"maxRadius\": 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7addc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_verb = False\n",
    "run_optimization_verb = False\n",
    "if optimization_verb:\n",
    "    if run_optimization_verb:\n",
    "        with open(\"./results/tracking_data/hough/pre_merge_optimization.csv\", 'w') as f1:\n",
    "            writer = csv.writer(f1, delimiter='\\t',lineterminator='\\n',)\n",
    "            writer.writerow([\"loss\", \"dp\", \"minDist\", \"param1\", \"param2\", \"minRadius\", \"maxRadius\"])\n",
    "            opt_result = dual_annealing(optimize_params, x0 = [1.5, 15, 100, 0.9, 15, 25], \\\n",
    "                                        args = (data_preload, frames, correct_n, writer),\\\n",
    "                                        bounds = [(1, 3), (5, 20), (50, 200), (0.3, 1), (5, 20), (10, 30)],\\\n",
    "                                        maxiter = 2000)\n",
    "    else:\n",
    "        try:\n",
    "            opt_result_df = pd.read_csv(\"./results/tracking_data/hough/pre_merge_optimization.csv\", sep=\"\\t\").sort_values(\"loss\", ascending=False)\n",
    "        except:\n",
    "            raise Exception(\"No optimization results found\")\n",
    "\n",
    "        optimized_parameters = opt_result_df.iloc[-1]\n",
    "        optimized_parameters = {\"dp\": optimized_parameters.dp, \"minDist\": optimized_parameters.minDist,\\\n",
    "                                \"param1\": optimized_parameters.param1, \"param2\": optimized_parameters.param2,\\\n",
    "                                \"minRadius\": int(optimized_parameters.minRadius), \"maxRadius\": int(optimized_parameters.maxRadius)}\n",
    "        parameters = optimized_parameters\n",
    "        print(parameters)\n",
    "else:\n",
    "    parameters = default_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4291bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_analysis_verb:\n",
    "    # save to txt parameters:\n",
    "    with open('./results/tracking_data/hough/hough_pre_merge.txt', 'w') as f:\n",
    "        f.write(json.dumps(parameters))\n",
    "    pre_merge_df, err_frames, error = hough_feature_location(data_preload, frames, correct_n, parameters)\n",
    "    pre_merge_df.to_parquet(\"./results/tracking_data/hough_pre_merge.parquet\")\n",
    "else:\n",
    "    try:\n",
    "        parameters = json.load(open('./results/tracking_data/hough/hough_pre_merge.txt'))\n",
    "        post_merge_df = pd.read_parquet(\"./results/tracking_data/hough/hough_pre_merge.parquet\")\n",
    "        print(parameters)\n",
    "        display(post_merge_df)\n",
    "    except:\n",
    "        raise Exception(\"No pre merge data found, run analysis first\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f476656",
   "metadata": {},
   "source": [
    "## POST MERGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "preload_load_data = False # takes 20 min\n",
    "merge_frame = 32269\n",
    "data = hough_preprocessing(pims.open('./data/movie.mp4'), 40, 55, 895, 910)\n",
    "if preload_load_data: data_preload = list(data[merge_frame:])\n",
    "\n",
    "startFrame = merge_frame\n",
    "endFrame = len(data) \n",
    "frames = np.arange(startFrame, endFrame, 1)\n",
    "opt_test_frames = np.arange(startFrame, endFrame, 500)\n",
    "correct_n = 49\n",
    "default_parameters = {\"dp\": 1.5, \"minDist\": 10, \"param1\": 100, \"param2\": 0.8, \"minRadius\": 10, \"maxRadius\": 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69448516",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_verb = True\n",
    "run_optimization_verb = False\n",
    "if optimization_verb:\n",
    "    if run_optimization_verb:\n",
    "        with open(\"./results/tracking_data/hough/post_merge_optimization.csv\", 'w') as f1:\n",
    "            writer = csv.writer(f1, delimiter='\\t',lineterminator='\\n',)\n",
    "            writer.writerow([\"loss\", \"dp\", \"minDist\", \"param1\", \"param2\", \"minRadius\", \"maxRadius\"])\n",
    "            opt_result = dual_annealing(optimize_params, x0 = [1.5, 15, 100, 0.9, 15, 25], \\\n",
    "                                        args = (data_preload, opt_test_frames, correct_n, writer),\\\n",
    "                                        bounds = [(1, 3), (5, 20), (50, 200), (0.3, 1), (5, 20), (10, 30)],\\\n",
    "                                        maxiter = 2000)\n",
    "    else:\n",
    "        opt_result_df = pd.read_csv(\"./results/tracking_data/hough/post_merge_optimization.csv\", sep=\"\\t\").sort_values(\"loss\", ascending=False)\n",
    "        # plot example of optimization result, in this case minRadius, can be any parameter\n",
    "        plot_optimization_results(opt_result_df, \"minRadius\")\n",
    "        \n",
    "        optimized_parameters = opt_result_df.iloc[-1]\n",
    "        optimized_parameters = {\"dp\": optimized_parameters.dp, \"minDist\": optimized_parameters.minDist,\\\n",
    "                                \"param1\": optimized_parameters.param1, \"param2\": optimized_parameters.param2,\\\n",
    "                                \"minRadius\": int(optimized_parameters.minRadius), \"maxRadius\": int(optimized_parameters.maxRadius)}\n",
    "        parameters = optimized_parameters\n",
    "        print(parameters)\n",
    "else:\n",
    "    parameters = default_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_analysis_verb:\n",
    "    # save to txt parameters:\n",
    "    with open('./results/tracking_data/hough/hough_post_merge.txt', 'w') as f:\n",
    "        f.write(json.dumps(parameters))\n",
    "    post_merge_df, err_frames, error = hough_feature_location(data_preload, frames, correct_n, parameters)\n",
    "    post_merge_df.to_parquet(\"./results/tracking_data/hough/hough_post_merge.parquet\")\n",
    "else:\n",
    "    try:\n",
    "        parameters = json.load(open('./results/tracking_data/hough/hough_post_merge.txt'))\n",
    "        post_merge_df = pd.read_parquet(\"./results/tracking_data/hough/hough_post_merge.parquet\")\n",
    "        print(parameters)\n",
    "        display(post_merge_df)\n",
    "    except:\n",
    "        raise Exception(\"No post merge data found, run analysis first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a frame with errors\n",
    "problem_frame = frames[np.where(post_merge_df.groupby(\"frame\").mean().nDroplets == 48)[0][-1]] #- merge_frame\n",
    "example = cv2.HoughCircles(data_preload[problem_frame], cv2.HOUGH_GRADIENT_ALT, **parameters)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax1 = fig.add_subplot(gs[0, 1]) \n",
    "ax1.plot(frames, test_result.groupby(\"frame\").mean().nDroplets, 'b-')\n",
    "ax1.set(title = \"Detected droplets\", ylabel = \"n\")\n",
    "ax1.grid()\n",
    "\n",
    "ax2 = fig.add_subplot(gs[1, 1]) \n",
    "ax2.plot(frames, test_result.d.values.reshape(len(frames), correct_n), 'b.', markersize=1)\n",
    "ax2.set(xlabel = \"Frame\", ylabel = \"d [px]\", title = \"Droplets diameter\")\n",
    "ax2.grid()\n",
    "\n",
    "ax3 = fig.add_subplot(gs[:, 0]) \n",
    "ax3.imshow(data_preload[problem_frame], cmap = \"gray\")\n",
    "ax3.set(title=f\"Detected droplets: {example.shape[1]} - Frame: {problem_frame + merge_frame}\", xlabel = \"X [px]\", ylabel = \"Y [px]\")\n",
    "for i in range(example.shape[1]):\n",
    "    ax3.add_patch(plt.Circle((example[0][i][0], example[0][i][1]), example[0][i][2], color = \"r\", fill = False))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab9eef",
   "metadata": {},
   "source": [
    "# DIMENSION OF DROPLETS ANALYSIS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a9eba65",
   "metadata": {},
   "source": [
    "## TRACKPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900fab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTrajs = pd.read_parquet(\"./results/tracking_data/trackpy_full.parquet\")\n",
    "mean_dim = rawTrajs.groupby(\"frame\").mean()\n",
    "merge_frame = 32269\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(mean_dim.index/10, 2*mean_dim[\"size\"])\n",
    "ax.vlines(merge_frame/10, 2*mean_dim[\"size\"].values.min(), 2*mean_dim[\"size\"].max(), color=\"r\")\n",
    "ax.set(xlabel = \"Time [s]\", ylabel = \"d [px]\", title = \"Mean particle diameter\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "if save_verb: plt.savefig(\"./results/dimension_analysis/mean_diameter_trackpy.png\", bbox_inches='tight')\n",
    "if show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10616cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windowed ?\n",
    "nFrames = len(mean_dim)\n",
    "print(nFrames)\n",
    "# WINDOWED ANALYSIS PARAMETERS\n",
    "window = 3200 # 320 s\n",
    "stride = 100 # 10 s\n",
    "print(f\"window of {window/10} s, stride of {stride/10} s\")\n",
    "startFrames = np.arange(0, nFrames-window, stride, dtype=int)\n",
    "endFrames = startFrames + window\n",
    "nSteps = len(startFrames)\n",
    "print(f\"number of steps: {nSteps}\")\n",
    "\n",
    "# mean and std droplet diameter per frame\n",
    "mean_d_wind = np.zeros(nSteps)\n",
    "std_d_wind = np.zeros(nSteps)\n",
    "for i, start in enumerate(startFrames):\n",
    "    mean_d_wind[i] = np.mean(2*mean_dim[\"size\"][start:start+window])\n",
    "    std_d_wind[i] = np.std(2*mean_dim[\"size\"][start:start+window])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59812ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (10, 5))\n",
    "ax.plot(startFrames/10, mean_d_wind)\n",
    "ax.vlines(merge_frame/10, mean_d_wind.min(), mean_d_wind.max(), color=\"r\")\n",
    "ax.fill_between(startFrames/10, mean_d_wind - std_d_wind, mean_d_wind + std_d_wind, alpha=0.5)\n",
    "ax.set(xlabel = \"Window Time [s]\", ylabel = \"d [px]\", title = \"Droplet diameter over window time\")\n",
    "ax.grid(True, linestyle='-', color = '0.75')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81e78c36",
   "metadata": {},
   "source": [
    "## confront trackpy and hough circle results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd690023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48ad65ac",
   "metadata": {},
   "source": [
    "# LINK HOUGH RESULT TO TRACKPY RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5fcc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deprecated pixel format used, make sure you did set range correctly\n"
     ]
    }
   ],
   "source": [
    "data = hough_preprocessing(pims.open('./data/movie.mp4'), 40, 55, 895, 910)\n",
    "nFrames = len(data)\n",
    "merge_frame = 32269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fad1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trackpy_df = pd.read_parquet(\"./results/tracking_data/pre_merge_tracking_sorted_and_colored.parquet\")\n",
    "colors = trackpy_df.loc[trackpy_df.frame == 0].color.values\n",
    "\n",
    "hough_df = pd.read_parquet(\"./results/tracking_data/hough/hough_pre_merge.parquet\").replace(0, np.nan)\n",
    "hough_df.loc[:49, [\"frame\"]] = 0\n",
    "hough_df = hough_df.loc[hough_df.frame.between(0, max(trackpy_df.frame)), :]\n",
    "hough_df[\"particle\"] = np.zeros(len(hough_df), dtype=int)\n",
    "pre_merge_err_frames = np.where(hough_df.groupby(\"frame\").mean().x.isna())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d92d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate at each frame droplet ID from trackpy to the one from hough circles by minimizing distance matrix\n",
    "for frame in tqdm(range(max(trackpy_df.frame))):\n",
    "    # neglect frames with error in hough circle detection\n",
    "    if frame in pre_merge_err_frames:\n",
    "        continue\n",
    "    hoguh_frame = hough_df.loc[hough_df.frame == frame]\n",
    "    trackpy_frame = trackpy_df.loc[trackpy_df.frame == frame]\n",
    "    dist = distance_matrix(hoguh_frame[[\"x\", \"y\"]].values, trackpy_frame[[\"x\", \"y\"]].values)\n",
    "    row_ind, col_ind = linear_sum_assignment(dist)\n",
    "    hough_df.loc[hough_df.frame == frame, [\"particle\"]] = trackpy_frame.loc[:, [\"particle\"]].values[col_ind,:]\n",
    "\n",
    "c = []\n",
    "for p in hough_df.particle:\n",
    "    c.append(colors[p])\n",
    "hough_df[\"color\"] = c\n",
    "hough_df.sort_values(by=[\"frame\", \"particle\"], inplace=True)\n",
    "if 0: hough_df.to_parquet(\"./results/parquet/tracking_hough_trackpy_linking.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32aaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 100\n",
    "hough_temp = hough_df.loc[(hough_df.frame == frame)] #  & (hough_df.particle == 10)\n",
    "trackpy_temp = trackpy_df.loc[(trackpy_df.frame == frame) ] #  & (trackpy_df.particle == 10)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 4))\n",
    "ax.imshow(data[frame])\n",
    "#ax.scatter(trackpy_temp.x.values, trackpy_temp.y.values, color = trackpy_temp.color.values)\n",
    "ax.set(title = \"Trackpy result\")\n",
    "ax1.imshow(data[frame])\n",
    "#ax1.scatter(hough_temp.x.values, hough_temp.y.values, color = hough_temp.color.values)\n",
    "ax1.set(title = \"Hough result\")\n",
    "\n",
    "for i in range(50):\n",
    "    ax.add_artist(plt.Circle((trackpy_temp.x.values[i],\\\n",
    "                               trackpy_temp.y.values[i]), \\\n",
    "                               2*trackpy_temp[\"size\"].values[i],\\\n",
    "                               color = trackpy_temp.color.values[i], fill=False, linewidth=1))\n",
    "    \n",
    "    ax1.add_artist(plt.Circle((hough_temp.x.values[i], \\\n",
    "                              hough_temp.y.values[i]),\\\n",
    "                              hough_temp.d.values[i],\\\n",
    "                              color = hough_temp.color.values[i], fill=False, linewidth=1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc493f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5, 5))\n",
    "#fig.subplots_adjust(left=0, right=1, bottom=0, top=1, wspace=None, hspace=None)\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(frame):\n",
    "    df = hough_df.loc[(hough_df.frame == frame) , [\"x\",\"y\",\"color\",\"d\"]]\n",
    "    for i in range(50):\n",
    "        graph[i].center = (df.x.values[i], df.y.values[i])\n",
    "        graph[i].radius = df.d.values[i]\n",
    "    graph2.set_data(data[frame])\n",
    "    title.set_text('Hough features location & Trackpy linking - frame = {}'.format(frame))\n",
    "    return graph\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "title = ax.set_title('Hough features location & Trackpy linking - frame = 0')\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "df = hough_df.loc[(hough_df.frame == 0), [\"x\",\"y\",\"color\",\"d\"]]\n",
    "\n",
    "graph = []\n",
    "for i in range(50):\n",
    "    graph.append(ax.add_artist(plt.Circle((df.x.values[i], df.y.values[i]), df.d.values[i], color = df.color.values[i],\\\n",
    "                                           fill = False, linewidth=1)))\n",
    "graph2 = ax.imshow(data[0])\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, range(0, int(max(hough_df.frame)), 1), interval = 5, blit=False)\n",
    "if 0: \n",
    "    writer = matplotlib.animation.FFMpegWriter(fps = 30, metadata = dict(artist='Matteo Scandola'), extra_args=['-vcodec', 'libx264'])\n",
    "    ani.save('./results/tracking_hough_trackpy_linking.mp4', writer=writer, dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e379a5a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TRACKPY TRACKING ERROR ESTIMATION\n",
    "\n",
    "I note that between frames 18300 and 18900 a droplet 40 seems stable and isolated.\\\n",
    "Then applying a rectangular mask around it I compute the \"benchmark\" position of the droplet using Canny Edge Detection and Hough Transform.\\\n",
    "Finally I confront the tracking result with the benchmark and different window sizes of smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552bf09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply mask to perform edge detection only on the benchmark particle\n",
    "@pims.pipeline\n",
    "def crop(image, x1, y1, x2, y2):   \n",
    "    npImage = np.array(image)\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.rectangle([(x1, y1), (x2, y2)], fill = 255)\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = npImage[:, :, 1] * npAlpha\n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16f714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "startFrame = 18300\n",
    "endFrame = 18900\n",
    "framesArray = np.arange(startFrame, endFrame, 1) \n",
    "\n",
    "rawTrajs = pd.read_parquet(\"./results/tracking_data/trackpy_pre_merge.parquet\")\n",
    "benchmark_particle_id = 40\n",
    "print(\"Benchmark particle:\", benchmark_particle_id)\n",
    "rawTraj = rawTrajs.loc[(rawTrajs.frame.between(startFrame, endFrame-1)) & (rawTrajs.particle == benchmark_particle_id)]\n",
    "if 1: ref = list(pims.open('./data/movie.mp4')[startFrame:endFrame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b5325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply mask to perform edge detection only on the benchmark particle\n",
    "y1 = rawTraj.iloc[0].y - 50\n",
    "x1 = rawTraj.iloc[0].x - 50\n",
    "y2 = rawTraj.iloc[0].y + 110\n",
    "x2 = rawTraj.iloc[0].x + 120\n",
    "if 1: ref_masked = list(crop(pims.open('./data/movie.mp4'), x1, y1, x2, y2)[startFrame:endFrame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829c59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (8, 6))\n",
    "ax.imshow(ref[0])\n",
    "ax.scatter(rawTraj.iloc[0].x, rawTraj.iloc[0].y, s=150, facecolors='none', edgecolors='b')\n",
    "ax.set(title = \"Selection of benchmark particle\", xlabel = \"x [px]\", ylabel = \"y [px]\")\n",
    "ax1.imshow(ref_masked[0])\n",
    "ax1.scatter(rawTraj.iloc[0].x, rawTraj.iloc[0].y, s=150, facecolors='none', edgecolors='b')\n",
    "ax1.set(title = \"Masked video\", xlabel = \"x [px]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/error_estimation/masked_frame.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662cfae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed to check that only particle 40 is selected by the mask\n",
    "fig = plt.figure()\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(frame):\n",
    "    df = rawTraj.loc[rawTraj.frame == startFrame + frame, [\"x\",\"y\", \"color\"]]\n",
    "    graph.set_offsets(df)\n",
    "    graph2.set_data(ref_masked[frame])\n",
    "    title.set_text('frame = {}'.format(startFrame + frame))\n",
    "    return graph\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "title = ax.set_title(f'frame = {startFrame}')\n",
    "df = rawTraj.loc[rawTraj.frame == startFrame, [\"x\",\"y\", \"color\"]]\n",
    "\n",
    "graph = ax.scatter(df.x, df.y, facecolors = 'none', edgecolors= df.color, s = 150)\n",
    "\n",
    "graph2 = ax.imshow(ref_masked[0])\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, endFrame-startFrame, interval = 2, blit=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6de5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "circles = []\n",
    "problems = 0\n",
    "\n",
    "for i in tqdm(range(0, len(ref_masked))):\n",
    "    img = ref_masked[i]\n",
    "    \"\"\"\n",
    "                    -- this works fine !!!!! --\n",
    "    # Apply Canny Edge Detection to find edges in the image\n",
    "    edges = cv2.Canny(img, 30, 30)\n",
    "    # Apply the Hough Transform to find circles in the image \n",
    "    temp = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, minDist=20, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "    if temp is not None:\n",
    "        circles.append(temp[0][0])\n",
    "   \"\"\"\n",
    "    \n",
    "    # this gives better results\n",
    "    temp = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, 1.5, minDist=1, param1=300, param2=0.6, minRadius=10, maxRadius=21)\n",
    "    if temp is not None:\n",
    "        circles.append(temp[0][0])\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        problems += 1\n",
    "print(\"Number of problems:\", problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38934f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.zeros(len(circles))\n",
    "y = np.zeros(len(circles))\n",
    "d = np.zeros(len(circles))\n",
    "\n",
    "for i in range(len(circles)):\n",
    "    x[i] = circles[i][0]\n",
    "    y[i] = circles[i][1]\n",
    "    d[i] = circles[i][2]\n",
    "    \n",
    "benchmark_traj = pd.DataFrame({\"x\": x, \"y\": y, \"d\": d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e392c-a35f-43a1-a554-b008d0eb2116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "ax.plot(np.arange(startFrame, endFrame, 1), benchmark_traj.d, label = \"benchmark\")\n",
    "ax.plot(np.arange(startFrame, endFrame, 1), 2*rawTraj[\"size\"], label = \"traj\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510b867-8441-4268-b872-5bb80388144a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c1 = plt.Circle(( x[100] , y[100] ), d[100], fill = False, color = \"red\")\n",
    "c2 = plt.Circle((rawTraj.x.values[100], rawTraj.y.values[100]), 2*rawTraj[\"size\"].values[100], fill = False, color=\"blue\")\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 8))\n",
    "ax.imshow(ref_masked[100])\n",
    "ax.add_artist(c1)\n",
    "ax.scatter(x[100], y[100], color = \"red\")\n",
    "ax.set(xlim = (x1, x2), ylim = (y1, y2))\n",
    "ax1.imshow(ref_masked[100])\n",
    "ax1.add_artist(c2)\n",
    "ax1.scatter(rawTraj.x.values[100], rawTraj.y.values[100], color = \"blue\")\n",
    "ax1.set(xlim = (x1, x2), ylim = (y1, y2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa3cdb7-8e8d-4c8e-a327-7bb372e68ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## POSITION ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d14fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tracking_pos = np.sqrt(rawTraj.x**2 + rawTraj.y**2)\n",
    "\n",
    "benchmark_pos = np.sqrt(x**2 + y**2)\n",
    "mse_raw = ((benchmark_pos - tracking_pos)**2).mean()\n",
    "print(\"MSE with raw trajectory:\", mse_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1488998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "def get_smooth_trajs(trajs, nDrops, windLen, orderofPoly):\n",
    "    # Trajectory Smoothing: using a Savgol Filter in order to drop the noise due to the tracking procedure\n",
    "    ret = trajs.copy()\n",
    "    for i in range(nDrops):\n",
    "        ret.loc[ret.particle == i, \"x\"] = savgol_filter(trajs.loc[trajs.particle == i].x.values, windLen, orderofPoly)\n",
    "        ret.loc[ret.particle == i, \"y\"] = savgol_filter(trajs.loc[trajs.particle == i].y.values, windLen, orderofPoly)    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5201bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windLen = 30\n",
    "smoothTrajs = get_smooth_trajs(rawTrajs, 50, windLen, 2)\n",
    "smoothTraj = smoothTrajs.loc[(smoothTrajs.frame.between(startFrame, endFrame-1)) & (smoothTrajs.particle == benchmark_particle_id)]\n",
    "tracking_smooth_pos = np.sqrt(smoothTraj.x**2 + smoothTraj.y**2)\n",
    "mse = ((benchmark_pos - tracking_smooth_pos)**2).mean()\n",
    "print(f\"MSE smoothing window {windLen}:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93cfab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax.plot(framesArray, benchmark_pos, label = \"benchmark\")\n",
    "ax.plot(framesArray, tracking_pos, label = \"tracking\")\n",
    "ax.set_title(\"Confront with raw traj\")\n",
    "ax1.plot(framesArray, benchmark_pos, label = \"benchmark\")\n",
    "ax1.plot(framesArray, tracking_smooth_pos, label = \"tracking\")\n",
    "ax1.set_title(f\"Confront with smooth traj (window = {windLen})\")\n",
    "ax.legend()\n",
    "ax1.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/error_estimation/benchmark_confront_wind30.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f09cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MSE ANALYSIS OF THE SMOOTHING WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "windLenList = np.arange(3, 100, 1)\n",
    "mse = np.zeros(len(windLenList))\n",
    "\n",
    "for k in tqdm(range(len(windLenList))):\n",
    "    smoothTrajs = get_smooth_trajs(rawTrajs, 50, windLenList[k], 2)\n",
    "    smoothTraj = smoothTrajs.loc[(smoothTrajs.frame.between(startFrame, endFrame-1)) & (smoothTrajs.particle == benchmark_particle_id)]\n",
    "    tracking_smooth_pos = np.sqrt(smoothTraj.x**2 + smoothTraj.y**2)\n",
    "    mse[k] = ((benchmark_pos - tracking_smooth_pos)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "ax.hlines(mse_raw, windLenList[0], windLenList[-1], 'r', label = \"raw\")\n",
    "ax.plot(windLenList, mse, label = \"smooth\")\n",
    "ax.set_title(\"MSE vs smoothing window\")\n",
    "ax.set_xlabel(\"Smoothing window\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.legend(loc='center right')\n",
    "plt.savefig(\"./results/error_estimation/mse_vs_window.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300bd97a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MERGING ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "preMerge = data[32268]\n",
    "merge = data[32269]\n",
    "postMerge = data[32270]\n",
    "\n",
    "# feature location with minMass, have some problems but the spurious effect are solved\n",
    "f = tp.locate(preMerge, dropSize, minmass = minMass, separation = sep, topn = nDrops, engine = 'numba')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(f['mass'], bins = 20)\n",
    "ax1.set(xlabel='mass', ylabel='count')\n",
    "ax2.imshow(preMerge)\n",
    "ax2.plot(f.x, f.y, 'bo')\n",
    "plt.suptitle(f\"Number of features found: {len(f)}\")\n",
    "plt.show()\n",
    "\n",
    "f = tp.locate(merge, dropSize, minmass = minMass, separation = sep, topn = nDrops-1, engine = 'numba')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(f['mass'], bins = 20)\n",
    "ax1.set(xlabel='mass', ylabel='count')\n",
    "ax2.imshow(merge)\n",
    "ax2.plot(f.x, f.y, 'bo')\n",
    "plt.suptitle(f\"Number of features found: {len(f)}\")\n",
    "\n",
    "f = tp.locate(postMerge, dropSize, minmass = minMass, separation = sep, topn = nDrops-1, engine = 'numba')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(f['mass'], bins = 20)\n",
    "ax1.set(xlabel='mass', ylabel='count')\n",
    "ax2.imshow(postMerge)\n",
    "ax2.plot(f.x, f.y, 'bo')\n",
    "plt.suptitle(f\"Number of features found: {len(f)}\")\n",
    "\n",
    "plt.show()\n",
    "tp.subpx_bias(f)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cda584d4033b4fbc423661afef9f2afe920081905f188573e835f76abdc60dee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
