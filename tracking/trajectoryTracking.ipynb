{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e32dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib ipympl\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "mpl.rc('image', cmap='gray')\n",
    "import matplotlib.animation\n",
    "writervideo = matplotlib.animation.FFMpegWriter(fps=30)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "tp.quiet()\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "import random\n",
    "\n",
    "run_analysis_verb = False\n",
    "show_verb = True\n",
    "save_verb = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044e885",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pims.pipeline\n",
    "def crop(image, x1, y1, x2, y2):    \n",
    "    npImage = np.array(image)\n",
    "    # Create same size alpha layer with circle\n",
    "    #alpha = Image.new('L', (920, 960), 0)\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\n",
    "    # Convert alpha Image to numpy arrayf\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = npImage[:, :, 1] * npAlpha\n",
    "    \n",
    "    ind = np.where(npImage == 0)\n",
    "    # npImage[200, 200] color of the border to swap with the black\n",
    "    npImage[ind] = npImage[200, 200]\n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = crop(pims.open('./data/movie.mp4'), 55, 55, 880, 880)\n",
    "data_ref = pims.open('./data/movie.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(data[0])\n",
    "ax2.imshow(data_ref[0])\n",
    "plt.tight_layout()\n",
    "if save_verb: plt.savefig('./results/pre_processing.png', bbox_inches='tight')\n",
    "if 1: \n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7f592",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# TRACKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0181830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the tracking\n",
    "dropSize = 31  \n",
    "minMass = 2000\n",
    "sep = 16\n",
    "nDrops = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8faa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES LOCATION\n",
    "nFrames = 100 # total number of frames of video --> len(data)\n",
    "startFrame = 0\n",
    "endFrame = startFrame + nFrames\n",
    "\n",
    "f = tp.batch(data[startFrame:endFrame], dropSize, minmass = minMass, separation = sep, topn = nDrops, engine = 'numba')    \n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d5021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOMALIES DETECTION\n",
    "\n",
    "num = np.zeros(nFrames)\n",
    "for i in range(nFrames):\n",
    "    num[i] = len(f.loc[f['frame'] == i])\n",
    "\n",
    "idx = np.where(num != nDrops)[0]\n",
    "print(idx)\n",
    "\n",
    "if len(idx) != 0:\n",
    "    delta = np.zeros(len(idx)-1)\n",
    "    for i in range(len(idx)-1):\n",
    "        delta[i] = idx[i+1]-idx[i]\n",
    "    print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0452d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES LINKING\n",
    "\"\"\" f : DataFrame\n",
    "    The DataFrame must include any number of column(s) for position and a\n",
    "    column of frame numbers. By default, 'x' and 'y' are expected for\n",
    "    position, and 'frame' is expected for frame number. See below for\n",
    "    options to use custom column names.\n",
    "search_range : float or tuple\n",
    "    the maximum distance features can move between frames,\n",
    "    optionally per dimension\n",
    "pos_columns : list of str, optional\n",
    "    Default is ['y', 'x'], or ['z', 'y', 'x'] when 'z' is present in f\n",
    "t_column : str, optional\n",
    "    Default is 'frame'\n",
    "memory : integer, optional\n",
    "    the maximum number of frames during which a feature can vanish\n",
    "\"\"\"\n",
    "\n",
    "t = tp.link_df(f, 150, memory = 2, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "display(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = max(t.particle)\n",
    "print(n)\n",
    "random.seed(5)\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "for i in range(max(t.particle)+1-n):\n",
    "    colors.append(\"#00FFFF\")\n",
    "c = []\n",
    "for p in t.particle:\n",
    "    c.append(colors[p])\n",
    "t[\"color\"] = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a18d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_particles = []\n",
    "for i in range(nFrames-1):\n",
    "    a = t.loc[t.frame == i].sort_values('particle').particle.values\n",
    "    b = t.loc[t.frame == i+1].sort_values('particle').particle.values\n",
    "    ind = np.where(np.in1d(a, b)==False)[0]\n",
    "    if ind.size > 0:\n",
    "        lost_particles.append([i, a[ind]])\n",
    "\n",
    "print(\"Total problems:\", len(lost_particles))\n",
    "if len(lost_particles) > 0: \n",
    "    print(f\"First failure occurred at frame {lost_particles[0][0]}\")\n",
    "    f1 = lost_particles[0][0]\n",
    "    f2 = lost_particles[0][0]+1\n",
    "    print(t.loc[t.frame == f1].sort_values('particle').particle.values)\n",
    "    print(t.loc[t.frame == f2].sort_values('particle').particle.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86195d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(lost_particles)>0: \n",
    "    fig, (ax, ax1) = plt.subplots(1, 2)\n",
    "    df = t.loc[t['frame'] == f1, [\"x\", \"y\", \"color\", \"particle\"]]\n",
    "    ax.scatter(df.x, df.y, s=50, ec = \"w\", facecolor = df.color)\n",
    "    #ax.scatter(df.loc[df.particle==43].x, df.loc[df.particle==43].y, s=100)\n",
    "    #ax.scatter(df.loc[df.particle==82].x, df.loc[df.particle==82].y, s=100)\n",
    "    ax.imshow(data[f1])\n",
    "\n",
    "    df1 = t.loc[t['frame'] == f2, [\"x\", \"y\", \"color\"]]\n",
    "    ax1.scatter(df1.x, df1.y, s=50, ec = \"w\", facecolor = df1.color)\n",
    "    ax1.imshow(data[f2])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05cf221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tp.filter_stubs(t, nFrames/2)\n",
    "# Compare the number of particles in the unfiltered and filtered data.\n",
    "print('Before:', t['particle'].nunique())\n",
    "print('After:', t1['particle'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bd424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rawTrajs.loc[(rawTrajs.frame == 0) , [\"x\", \"y\", \"color\"]]\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(df.x, df.y, facecolors = 'none', edgecolors = df.color, s = 150)\n",
    "ax.imshow(data[0])\n",
    "if save_verb: plt.savefig(\"../results/location_example.png\",  bbox_inches='tight')\n",
    "if show_verb: \n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(frame):\n",
    "    df = rawTrajs.loc[(rawTrajs.frame == frame) & (rawTrajs.particle == red_particle_idx) , [\"x\",\"y\",\"color\"]]\n",
    "    graph.set_offsets(df)\n",
    "    graph.set_edgecolor(df.color)\n",
    "    graph2.set_data(data[frame])\n",
    "    title.set_text('frame = {}'.format(frame))\n",
    "    return graph\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "title = ax.set_title('frame = 0')\n",
    "df = rawTrajs.loc[(rawTrajs.frame == 0) & (rawTrajs.particle == red_particle_idx), [\"x\",\"y\",\"color\"]]\n",
    "\n",
    "graph = ax.scatter(df.x, df.y, facecolors = 'none', edgecolors = df.color, s = 150)\n",
    "\n",
    "graph2 = ax.imshow(data[0])\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, 100, interval = 5, blit=False)\n",
    "if 0: ani.save('../results/video/tracking.mp4', fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "if anim_show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec4587f9",
   "metadata": {},
   "source": [
    "# post merge tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the tracking\n",
    "dropSize = 31  \n",
    "minMass = 2000\n",
    "sep = 16\n",
    "nDrops = 49\n",
    "\n",
    "# FEATURES LOCATION\n",
    "nFrames = 100 # total number of frames of video --> len(data)\n",
    "startFrame = 32269 + 100\n",
    "endFrame = startFrame + nFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5224e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preload = list(data[startFrame:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tp.batch(data_preload[:1000], dropSize, minmass = minMass, separation = sep, topn = nDrops, engine = 'numba')    \n",
    "f.frame = f.frame + startFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.zeros(1000)\n",
    "for i in range(1000):\n",
    "    num[i] = len(f.loc[f['frame'] == i + startFrame])\n",
    "\n",
    "idx = np.where(num != nDrops)[0]\n",
    "print(idx)\n",
    "if len(idx) != 0:\n",
    "    delta = np.zeros(len(idx)-1)\n",
    "    for i in range(len(idx)-1):\n",
    "        delta[i] = idx[i+1]-idx[i]\n",
    "    print(delta)\n",
    "\n",
    "t = tp.link_df(f, 50, memory = 2, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "t = tp.filter_stubs(t, 50)\n",
    "# ANOMALIES DETECTION\n",
    "n = max(t.particle)\n",
    "print(n)\n",
    "random.seed(5)\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "for i in range(max(t.particle)+1-n):\n",
    "    colors.append(\"#00FFFF\")\n",
    "c = []\n",
    "for p in t.particle:\n",
    "    c.append(colors[p])\n",
    "t[\"color\"] = c\n",
    "\n",
    "display(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = t.loc[(t.frame == startFrame+100) , [\"x\", \"y\", \"color\"]]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(df.x, df.y, facecolors = 'none', edgecolors = df.color, s = 50)\n",
    "ax.imshow(data_preload[100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(frame):\n",
    "    df = t.loc[t.frame == frame, [\"x\", \"y\", \"color\"]]\n",
    "    graph.set_offsets(df)\n",
    "    graph.set_edgecolor(df.color)\n",
    "    graph2.set_data(data_preload[frame-startFrame])\n",
    "    title.set_text('frame = {}'.format(frame))\n",
    "    return graph\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "title = ax.set_title('frame = 0')\n",
    "df = t.loc[t.frame == startFrame, [\"x\", \"y\", \"color\"]]\n",
    "graph = ax.scatter(df.x, df.y, facecolors = 'none', edgecolors = df.color, s = 50)\n",
    "graph2 = ax.imshow(data_preload[0])\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, range(startFrame, startFrame + 1000), interval = 5, blit=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = t.loc[t['frame'] == f1, [\"x\", \"y\", \"color\", \"particle\"]]\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2)\n",
    "ax.scatter(df.x, df.y, s=50, ec = \"w\", facecolor = df.color)\n",
    "ax.imshow(data[f1])\n",
    "df1 = t.loc[t['frame'] == f2, [\"x\", \"y\", \"color\"]]\n",
    "ax1.scatter(df1.x, df1.y, s=50, ec = \"w\", facecolor = df1.color)\n",
    "ax1.imshow(data[f2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52822bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_particles = []\n",
    "for i in range(nFrames-1):\n",
    "    a = t.loc[t.frame == i].sort_values('particle').particle.values\n",
    "    b = t.loc[t.frame == i+1].sort_values('particle').particle.values\n",
    "    ind = np.where(np.in1d(a, b)==False)[0]\n",
    "    if ind.size > 0:\n",
    "        lost_particles.append([i, a[ind]])\n",
    "print(\"Total problems:\", len(lost_particles))\n",
    "print(ind)\n",
    "\n",
    "if len(lost_particles) > 0: \n",
    "    print(f\"First failure occurred at frame {lost_particles[0][0]}\")\n",
    "    f1 = lost_particles[0][0]\n",
    "    f2 = lost_particles[0][0]+1\n",
    "    print(t.loc[t.frame == f1].sort_values('particle').particle.values)\n",
    "    print(t.loc[t.frame == f2].sort_values('particle').particle.values)\n",
    "\n",
    "if len(lost_particles)>0: \n",
    "    fig, (ax, ax1) = plt.subplots(1, 2)\n",
    "    df = t.loc[t['frame'] == f1, [\"x\", \"y\", \"color\", \"particle\"]]\n",
    "    ax.scatter(df.x, df.y, s=50, ec = \"w\", facecolor = df.color)\n",
    "    #ax.scatter(df.loc[df.particle==43].x, df.loc[df.particle==43].y, s=100)\n",
    "    #ax.scatter(df.loc[df.particle==82].x, df.loc[df.particle==82].y, s=100)\n",
    "    ax.imshow(data[f1])\n",
    "\n",
    "    df1 = t.loc[t['frame'] == f2, [\"x\", \"y\", \"color\"]]\n",
    "    ax1.scatter(df1.x, df1.y, s=50, ec = \"w\", facecolor = df1.color)\n",
    "    ax1.imshow(data[f2])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab9eef",
   "metadata": {},
   "source": [
    "# DIMENSION OF DROPLETS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9eba65",
   "metadata": {},
   "source": [
    "## TRACKPY RESULTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900fab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTrajs = pd.read_parquet(\"./results/parquet/full_movie_tracking.parquet\")\n",
    "mean_dim = rawTrajs.groupby(\"frame\").mean()\n",
    "merge_frame = 32269\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(mean_dim.index/10, 2*mean_dim[\"size\"])\n",
    "ax.vlines(merge_frame/10, 2*mean_dim[\"size\"].values.min(), 2*mean_dim[\"size\"].max(), color=\"r\")\n",
    "ax.set(xlabel = \"Time [s]\", ylabel = \"d [px]\", title = \"Mean particle diameter\")\n",
    "ax.grid()\n",
    "if save_verb: plt.savefig(\"./results/dimension_analysis/mean_diameter_trackpy.png\", bbox_inches='tight')\n",
    "if show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522405e4",
   "metadata": {},
   "source": [
    "## HOUGH CIRCLE RESULTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5611af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pims.pipeline\n",
    "def crop2(image, x1, y1, x2, y2):    \n",
    "    #image = cv2.GaussianBlur(image, ksize = [7,7], sigmaX = 1.5, sigmaY = 1.5)\n",
    "    npImage = np.array(image)\n",
    "    # Create same size alpha layer with circle\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\n",
    "    # Convert alpha Image to numpy array\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = npImage[:, :, 1] * npAlpha\n",
    "    \n",
    "    ind = np.where(npImage == 0)\n",
    "    # npImage[200, 200] color of the border to swap with the black\n",
    "    npImage[ind] = npImage[200, 200]\n",
    "    npImage = cv2.medianBlur(npImage, 5)\n",
    "    return npImage\n",
    "\n",
    "@joblib.delayed\n",
    "def loc_frame(correct_n, frame, img, parameters):\n",
    "\ttemp = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, **parameters)\n",
    "\tif temp.shape[1] == correct_n:\n",
    "\t\treturn np.hstack((temp[0], (np.ones((correct_n, 1), dtype=int)*frame), np.ones((correct_n, 1), dtype=int)*temp.shape[1]))\n",
    "\telse: \n",
    "\t\treturn np.hstack((np.zeros((correct_n, 3)), (np.ones((correct_n, 1), dtype=int)*frame), np.ones((correct_n, 1), dtype=int)*temp.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429bb31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters of the HoughCircles function\n",
    "parameters_pre_merge = {\"dp\": 1.5, \"minDist\": 15, \"param1\": 100, \"param2\": 0.8, \"minRadius\": 15, \"maxRadius\": 25}\n",
    "parameters_post_merge = {\"dp\": 1.5, \"minDist\": 10, \"param1\": 100, \"param2\": 0.8, \"minRadius\": 10, \"maxRadius\": 30}\n",
    "# load data\n",
    "data = crop2(pims.open('./data/movie.mp4'), 40, 55, 895, 910)\n",
    "nFrames = len(data)\n",
    "merge_frame = 32269\n",
    "\n",
    "if 0:\n",
    "\t# pre merge detection\n",
    "\tparallel = joblib.Parallel(n_jobs = -1)\n",
    "\ttemp = parallel(\n",
    "\t\tloc_frame(50, frame, data[frame], parameters_pre_merge)\n",
    "\t\tfor frame in tqdm( range(merge_frame) )\n",
    "\t)\n",
    "\tpre_merge_droplets = np.array(temp).reshape(merge_frame*50, 5)\n",
    "\tpre_merge_droplets = pd.DataFrame(pre_merge_droplets, columns = [\"x\", \"y\", \"d\", \"frame\", \"nDroplets\"])\n",
    "\tpre_merge_droplets.to_parquet(\"pre_merge_droplets2.parquet\")\n",
    "\tpre_merge_droplets.replace(0, np.nan, inplace=True)\n",
    "\tpre_merge_droplets.loc[:50, \"frame\"] = 0\n",
    "\t\n",
    "\tparallel = joblib.Parallel(n_jobs = -1)\n",
    "\ttemp = parallel(\n",
    "\t\tloc_frame(49, frame, data[frame], parameters_post_merge)\n",
    "\t\tfor frame in tqdm( range(merge_frame, nFrames) )\n",
    "\t)\n",
    "\tpost_merge_droplets = np.array(temp).reshape((nFrames-merge_frame)*49, 5)\n",
    "\tpost_merge_droplets = pd.DataFrame(post_merge_droplets, columns = [\"x\", \"y\", \"d\", \"frame\", \"nDroplets\"])\n",
    "\tpost_merge_droplets.to_parquet(\"post_merge_droplets2.parquet\")\n",
    "\tpost_merge_droplets.replace(0, np.nan, inplace=True)\n",
    "\n",
    "else:\n",
    "\tpre_merge_droplets = pd.read_parquet(\"./pre_merge_droplets.parquet\").replace(0, np.nan)\n",
    "\tpre_merge_droplets.loc[:50, \"frame\"] = 0\n",
    "\tpost_merge_droplets = pd.read_parquet(\"./post_merge_droplets.parquet\").replace(0, np.nan)\n",
    "\t\n",
    "pre_merge_err_frames = np.where(pre_merge_droplets.groupby(\"frame\").mean().x.isna())[0]\n",
    "post_merge_err_frames = merge_frame + np.where(post_merge_droplets.groupby(\"frame\").mean().x.isna())[0]\n",
    "pre_merge_errors = int(len(pre_merge_err_frames))\n",
    "post_merge_errors = int(len(post_merge_err_frames))\n",
    "\n",
    "print(f\"Errors before merging: {pre_merge_errors} --> {np.round(100*pre_merge_errors/merge_frame, 2)} %\")\n",
    "print(f\"Errors after merging:  {post_merge_errors} --> {np.round(100*post_merge_errors/(nFrames-merge_frame), 2)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15a3db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = crop2(pims.open('./data/movie.mp4'), 40, 55, 895, 910)\n",
    "merge_frame = 32269\n",
    "if 1: data_preload = list(data[merge_frame:len(data)])\n",
    "\n",
    "# pre merge test\n",
    "if 0:\n",
    "\tparameters_pre_merge = {\"dp\": 1.5, \"minDist\": 15, \"param1\": 100, \"param2\": 0.9, \"minRadius\": 15, \"maxRadius\": 25}\n",
    "\tstartFrame = 0\n",
    "\tendFrame = 5000 #merge_frame\n",
    "\tframes = np.arange(startFrame, endFrame, 1)\n",
    "\tn = len(frames)\n",
    "\tparallel = joblib.Parallel(n_jobs = -2)\n",
    "\ttemp = parallel(\n",
    "\t    loc_frame(50, frame, data[frame], parameters_pre_merge)\n",
    "\t    for frame in tqdm( frames )\n",
    "\t)\n",
    "\ttemp = pd.DataFrame(np.array(temp).reshape(n*50, 5), columns = [\"x\", \"y\", \"d\", \"frame\", \"nDroplets\"])\n",
    "\ttemp = temp.replace(0, np.nan)\n",
    "\ttemp.loc[:50, \"frame\"] = 0\n",
    "\tprint(temp)\n",
    "\n",
    "\terr_frames = np.where(temp.groupby(\"frame\").mean().x.isna())[0]\n",
    "\tprint(f\"Errors before merging:  {len(err_frames)} --> {np.round(100*len(err_frames)/n, 2)} %\")\n",
    "\n",
    "\tfig, (ax, ax1) = plt.subplots(2, 1, figsize = (10, 4))\n",
    "\tax.plot(temp.groupby(\"frame\").mean().nDroplets, \"o\", ms = 1)\n",
    "\tax1.plot(temp.d, \"o\", ms = 1)\n",
    "\tax.set_xlabel(\"Frame\")\n",
    "\tax.set_ylabel(\"Number of droplets\")\n",
    "\tax.set_title(\"Number of droplets detected per frame\")\n",
    "\tplt.show()\n",
    "\n",
    "# Post merge test\n",
    "if 1:\n",
    "\tparameters_post_merge = {\"dp\": 1.5, \"minDist\": 14, \"param1\": 100, \"param2\": 0.8, \"minRadius\": 14, \"maxRadius\": 25}\n",
    "\tstartFrame = merge_frame\n",
    "\tendFrame =  len(data) #startFrame + 5000 #len(data)\n",
    "\tframes = np.arange(startFrame, endFrame, 1)\n",
    "\tn = len(frames)\n",
    "\n",
    "\tparallel = joblib.Parallel(n_jobs = -1)\n",
    "\ttemp2 = parallel(\n",
    "\t    loc_frame(49, frame, data_preload[frame-startFrame], parameters_post_merge)\n",
    "\t    for frame in tqdm( frames )\n",
    "\t) \n",
    "\ttemp2 = pd.DataFrame(np.array(temp2).reshape(n*49, 5), columns = [\"x\", \"y\", \"d\", \"frame\", \"nDroplets\"])\n",
    "\ttemp2 = temp2.replace(0, np.nan)\n",
    "\tprint(temp2)\n",
    "\n",
    "\terr_frames2 = np.where(temp2.groupby(\"frame\").mean().x.isna())[0]\n",
    "\tprint(f\"Errors after merging:  {len(err_frames2)} --> {np.round(100*len(err_frames2)/n, 2)} %\")\n",
    "\n",
    "\tfig, (ax, ax1) = plt.subplots(2, 1, figsize = (10, 4))\n",
    "\tax.plot(temp2.nDroplets)\n",
    "\tax1.plot(temp2.d)\n",
    "\tax.set_xlabel(\"Frame\")\n",
    "\tax.set_ylabel(\"Number of droplets\")\n",
    "\tax.set_title(\"Number of droplets detected per frame\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_frame = np.where(temp.groupby(\"frame\").mean().nDroplets == 47)[0][0] + merge_frame\n",
    "temp = cv2.HoughCircles(data[problem_frame], cv2.HOUGH_GRADIENT_ALT, **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ba4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(2, 1, figsize = (10, 10))\n",
    "ax.imshow(data[problem_frame], cmap = \"gray\")\n",
    "for i in range(temp.shape[1]):\n",
    "    ax.add_patch(plt.Circle((temp[0][i][0], temp[0][i][1]), temp[0][i][2], color = \"r\", fill = False))\n",
    "ax1.plot(temp[0][:, 2], \"o\", ms = 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d060d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(pre_merge_droplets.groupby(\"frame\").mean().nDroplets, label=\"Before merging\")\n",
    "ax.plot(post_merge_droplets.groupby(\"frame\").mean().nDroplets, label=\"After merging\")\n",
    "ax.set(xlabel=\"Frame\", ylabel=\"Mean number of droplets\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "if save_verb: plt.savefig(\"./results/dimension_analysis/mean_nDroplets.png\", bbox_inches='tight')\n",
    "if show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_merge_mean_dim = pre_merge_droplets.groupby(\"frame\").mean().d.values\n",
    "post_merge_mean_dim = post_merge_droplets.groupby(\"frame\").mean().d.values\n",
    "mean_dim_hough = np.append(pre_merge_mean_dim, post_merge_mean_dim)\n",
    "\n",
    "fig, (ax,ax1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [2, 1]})\n",
    "ax.plot(mean_dim_hough)\n",
    "ax.vlines(merge_frame, np.nanmin(mean_dim_hough), np.nanmax(mean_dim_hough), color=\"r\")\n",
    "ax.set(xlabel=\"Frame\", ylabel=\"Mean diameter\")\n",
    "ax.grid()\n",
    "ax1.hist(np.argwhere(np.isnan(mean_dim_hough)), bins = np.arange(0, len(data), 320), cumulative=True, histtype=\"step\")\n",
    "ax1.set(xlabel=\"Frame\", ylabel=\"Cumulative number of errors\")\n",
    "plt.tight_layout()\n",
    "if save_verb: plt.savefig(\"./results/dimension_analysis/mean_dim_hough.png\",  bbox_inches = 'tight')\n",
    "if show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n",
    "plt.show()\n",
    "\n",
    "# confront betwee trackpy and hough results\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(2*mean_dim, label=\"Trackpy\")\n",
    "ax.plot(mean_dim_hough, label=\"Hough\")\n",
    "ax.vlines(merge_frame, np.nanmin(mean_dim_hough), np.nanmax(mean_dim_hough), color=\"r\")\n",
    "ax.set(xlabel=\"Frame\", ylabel=\"Mean diameter\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "if save_verb: plt.savefig(\"./results/dimension_analysis/mean_dim_comparison.png\",  bbox_inches='tight')\n",
    "if show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96909310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match detected particles to rawTrajs particle index:\n",
    "ids = np.zeros((100, 50), dtype=int)\n",
    "err_count = 0\n",
    "for frame in tqdm(range(100)):\n",
    "    if frame in error_frames:\n",
    "        continue\n",
    "        #temp = err_circles[err_count]\n",
    "        #err_count += 1\n",
    "    else:\n",
    "        temp = detected_circles[frame]\n",
    "\n",
    "    dist_mat = distance_matrix(temp[:, :2], rawTrajs.loc[rawTrajs.frame==frame, [\"x\", \"y\"]])\n",
    "    ids[frame] = np.argmin(dist_mat, axis = 1)\n",
    "\n",
    "colors = np.array([\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(50)])\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(50):\n",
    "    ax.scatter(detected_circles[0, ids[0], 0], detected_circles[0, ids[0], 1], color = colors[i])\n",
    "ax.scatter(rawTrajs.loc[rawTrajs.frame==0, [\"x\"]], rawTrajs.loc[rawTrajs.frame==0, [\"y\"]], color = colors)\n",
    "ax.imshow(data_preload[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8fff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_error(img, parameters, plot):\n",
    "    temp = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, **parameters)[0]\n",
    "    print(f\"Found {temp.shape[0]} circles\")\n",
    "    # compute distance between detected circles\n",
    "    dist_list = []\n",
    "    for i in range(temp.shape[0]):\n",
    "        for j in range(i):\n",
    "            dist_list.append(np.linalg.norm(temp[i, :2] - temp[j, :2]))\n",
    "    # find the two circles that are the closest\n",
    "    problems_id = []\n",
    "    for i in range(temp.shape[0]):\n",
    "        for j in range(i):\n",
    "            if np.linalg.norm(temp[i, :2] - temp[j, :2]) == min(dist_list):\n",
    "                problems_id = [i, j]\n",
    "                #print(\"Circles ID:\", problems_id, \"found at distance:\", np.linalg.norm(temp[i, :2] - temp[j, :2]))\n",
    "\n",
    "    # prepare the circles for plotting, different color for the two problematic circles\n",
    "    circles_plot = []\n",
    "    for i in range(temp.shape[0]):\n",
    "        if (i == problems_id[0]) or (i == problems_id[1]):\n",
    "            circles_plot.append(plt.Circle((temp[i, 0], temp[i, 1]), temp[i, 2], color='r', fill=False))\n",
    "        else:\n",
    "            circles_plot.append(plt.Circle((temp[i, 0], temp[i, 1]), temp[i, 2], color='b', fill=False))\n",
    "    if plot:\n",
    "        # plot the image with the circles\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.imshow(img)\n",
    "        for i in range(temp.shape[0]):\n",
    "            ax.add_artist(circles_plot[i])\n",
    "        plt.show()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    data_preload_pre_merge = list(data[pre_merge_err_frames[0]:pre_merge_err_frames[10]])\n",
    "    data_preload_post_merge = list(data[post_merge_err_frames[0]:post_merge_err_frames[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59377e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pre merge -> 50 droplets\")\n",
    "for i in range(10):\n",
    "    analyze_error(data_preload_pre_merge[i], parameters, False)\n",
    "print(\"Post merge -> 49 droplets \")\n",
    "for i in range(10):\n",
    "    analyze_error(data_preload_post_merge[i], parameters, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e379a5a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# estimate error in the tracking\n",
    "\n",
    "I note that between frames 18300 and 18900 a droplet 40 seems stable and isolated.\\\n",
    "Then applying a rectangular mask around it I compute the \"benchmark\" position of the droplet using Canny Edge Detection and Hough Transform.\\\n",
    "Finally I confront the tracking result with the benchmark and different window sizes of smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552bf09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply mask to perform edge detection only on the benchmark particle\n",
    "@pims.pipeline\n",
    "def crop2(image, x1, y1, x2, y2):   \n",
    "    npImage = np.array(image)\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.rectangle([(x1, y1), (x2, y2)], fill = 255)\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = npImage[:, :, 1] * npAlpha\n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16f714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "startFrame = 18300\n",
    "endFrame = 18900\n",
    "framesArray = np.arange(startFrame, endFrame, 1) \n",
    "\n",
    "rawTrajs = pd.read_parquet(\"./results/parquet/pre_merge_tracking.parquet\")\n",
    "benchmark_particle_id = 40\n",
    "print(\"Benchmark particle:\", benchmark_particle_id)\n",
    "rawTraj = rawTrajs.loc[(rawTrajs.frame.between(startFrame, endFrame-1)) & (rawTrajs.particle == benchmark_particle_id)]\n",
    "if 1: ref = list(pims.open('./data/movie.mp4')[startFrame:endFrame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b5325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply mask to perform edge detection only on the benchmark particle\n",
    "y1 = rawTraj.iloc[0].y - 50\n",
    "x1 = rawTraj.iloc[0].x - 50\n",
    "y2 = rawTraj.iloc[0].y + 110\n",
    "x2 = rawTraj.iloc[0].x + 120\n",
    "if 1: ref_masked = list(crop2(pims.open('./data/movie.mp4'), x1, y1, x2, y2)[startFrame:endFrame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829c59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (8, 6))\n",
    "ax.imshow(ref[0])\n",
    "ax.scatter(rawTraj.iloc[0].x, rawTraj.iloc[0].y, s=150, facecolors='none', edgecolors='b')\n",
    "ax.set(title = \"Selection of benchmark particle\", xlabel = \"x [px]\", ylabel = \"y [px]\")\n",
    "ax1.imshow(ref_masked[0])\n",
    "ax1.scatter(rawTraj.iloc[0].x, rawTraj.iloc[0].y, s=150, facecolors='none', edgecolors='b')\n",
    "ax1.set(title = \"Masked video\", xlabel = \"x [px]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/error_estimation/masked_frame.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662cfae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed to check that only particle 40 is selected by the mask\n",
    "fig = plt.figure()\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(frame):\n",
    "    df = rawTraj.loc[rawTraj.frame == startFrame + frame, [\"x\",\"y\", \"color\"]]\n",
    "    graph.set_offsets(df)\n",
    "    graph2.set_data(ref_masked[frame])\n",
    "    title.set_text('frame = {}'.format(startFrame + frame))\n",
    "    return graph\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "title = ax.set_title(f'frame = {startFrame}')\n",
    "df = rawTraj.loc[rawTraj.frame == startFrame, [\"x\",\"y\", \"color\"]]\n",
    "\n",
    "graph = ax.scatter(df.x, df.y, facecolors = 'none', edgecolors= df.color, s = 150)\n",
    "\n",
    "graph2 = ax.imshow(ref_masked[0])\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, endFrame-startFrame, interval = 2, blit=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6de5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "circles = []\n",
    "problems = 0\n",
    "\n",
    "for i in tqdm(range(0, len(ref_masked))):\n",
    "    img = ref_masked[i]\n",
    "    \"\"\"\n",
    "                    -- this works fine !!!!! --\n",
    "    # Apply Canny Edge Detection to find edges in the image\n",
    "    edges = cv2.Canny(img, 30, 30)\n",
    "    # Apply the Hough Transform to find circles in the image \n",
    "    temp = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, minDist=20, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "    if temp is not None:\n",
    "        circles.append(temp[0][0])\n",
    "   \"\"\"\n",
    "    \n",
    "    # this gives better results\n",
    "    temp = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, 1.5, minDist=1, param1=300, param2=0.6, minRadius=10, maxRadius=21)\n",
    "    if temp is not None:\n",
    "        circles.append(temp[0][0])\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        problems += 1\n",
    "print(\"Number of problems:\", problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38934f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.zeros(len(circles))\n",
    "y = np.zeros(len(circles))\n",
    "d = np.zeros(len(circles))\n",
    "\n",
    "for i in range(len(circles)):\n",
    "    x[i] = circles[i][0]\n",
    "    y[i] = circles[i][1]\n",
    "    d[i] = circles[i][2]\n",
    "    \n",
    "benchmark_traj = pd.DataFrame({\"x\": x, \"y\": y, \"d\": d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e392c-a35f-43a1-a554-b008d0eb2116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "ax.plot(np.arange(startFrame, endFrame, 1), benchmark_traj.d, label = \"benchmark\")\n",
    "ax.plot(np.arange(startFrame, endFrame, 1), 2*rawTraj[\"size\"], label = \"traj\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510b867-8441-4268-b872-5bb80388144a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c1 = plt.Circle(( x[100] , y[100] ), d[100], fill = False, color = \"red\")\n",
    "c2 = plt.Circle((rawTraj.x.values[100], rawTraj.y.values[100]), 2*rawTraj[\"size\"].values[100], fill = False, color=\"blue\")\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 8))\n",
    "ax.imshow(ref_masked[100])\n",
    "ax.add_artist(c1)\n",
    "ax.scatter(x[100], y[100], color = \"red\")\n",
    "ax.set(xlim = (x1, x2), ylim = (y1, y2))\n",
    "ax1.imshow(ref_masked[100])\n",
    "ax1.add_artist(c2)\n",
    "ax1.scatter(rawTraj.x.values[100], rawTraj.y.values[100], color = \"blue\")\n",
    "ax1.set(xlim = (x1, x2), ylim = (y1, y2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa3cdb7-8e8d-4c8e-a327-7bb372e68ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## POSITION ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d14fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tracking_pos = np.sqrt(rawTraj.x**2 + rawTraj.y**2)\n",
    "\n",
    "benchmark_pos = np.sqrt(x**2 + y**2)\n",
    "mse_raw = ((benchmark_pos - tracking_pos)**2).mean()\n",
    "print(\"MSE with raw trajectory:\", mse_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1488998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "def get_smooth_trajs(trajs, nDrops, windLen, orderofPoly):\n",
    "    # Trajectory Smoothing: using a Savgol Filter in order to drop the noise due to the tracking procedure\n",
    "    ret = trajs.copy()\n",
    "    for i in range(nDrops):\n",
    "        ret.loc[ret.particle == i, \"x\"] = savgol_filter(trajs.loc[trajs.particle == i].x.values, windLen, orderofPoly)\n",
    "        ret.loc[ret.particle == i, \"y\"] = savgol_filter(trajs.loc[trajs.particle == i].y.values, windLen, orderofPoly)    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5201bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windLen = 30\n",
    "smoothTrajs = get_smooth_trajs(rawTrajs, 50, windLen, 2)\n",
    "smoothTraj = smoothTrajs.loc[(smoothTrajs.frame.between(startFrame, endFrame-1)) & (smoothTrajs.particle == benchmark_particle_id)]\n",
    "tracking_smooth_pos = np.sqrt(smoothTraj.x**2 + smoothTraj.y**2)\n",
    "mse = ((benchmark_pos - tracking_smooth_pos)**2).mean()\n",
    "print(f\"MSE smoothing window {windLen}:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93cfab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax.plot(framesArray, benchmark_pos, label = \"benchmark\")\n",
    "ax.plot(framesArray, tracking_pos, label = \"tracking\")\n",
    "ax.set_title(\"Confront with raw traj\")\n",
    "ax1.plot(framesArray, benchmark_pos, label = \"benchmark\")\n",
    "ax1.plot(framesArray, tracking_smooth_pos, label = \"tracking\")\n",
    "ax1.set_title(f\"Confront with smooth traj (window = {windLen})\")\n",
    "ax.legend()\n",
    "ax1.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/error_estimation/benchmark_confront_wind30.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f09cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MSE ANALYSIS OF THE SMOOTHING WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "windLenList = np.arange(3, 100, 1)\n",
    "mse = np.zeros(len(windLenList))\n",
    "\n",
    "for k in tqdm(range(len(windLenList))):\n",
    "    smoothTrajs = get_smooth_trajs(rawTrajs, 50, windLenList[k], 2)\n",
    "    smoothTraj = smoothTrajs.loc[(smoothTrajs.frame.between(startFrame, endFrame-1)) & (smoothTrajs.particle == benchmark_particle_id)]\n",
    "    tracking_smooth_pos = np.sqrt(smoothTraj.x**2 + smoothTraj.y**2)\n",
    "    mse[k] = ((benchmark_pos - tracking_smooth_pos)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "ax.hlines(mse_raw, windLenList[0], windLenList[-1], 'r', label = \"raw\")\n",
    "ax.plot(windLenList, mse, label = \"smooth\")\n",
    "ax.set_title(\"MSE vs smoothing window\")\n",
    "ax.set_xlabel(\"Smoothing window\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.legend(loc='center right')\n",
    "plt.savefig(\"./results/error_estimation/mse_vs_window.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d854aa7c-d1ab-4070-a068-2d51651dba04",
   "metadata": {},
   "source": [
    "# TRACKING WITHOUT TRACKPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132bcf2-4e5e-49d5-a81a-b3b472586706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.imshow(ref_masked[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8aa1e7-24be-472e-91ca-78efac89ce0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Initialize a list to store the circle data\n",
    "circles_list = []\n",
    "\n",
    "for i in tqdm(range(0, len(ref))):\n",
    "    img = ref_masked[i]\n",
    "    \n",
    "    # Detect the circles in the frame\n",
    "    circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, 1.5, minDist=1, param1=300, param2=0.6, minRadius=10, maxRadius=21)\n",
    "    \n",
    "    # If circles were detected, add them to the list\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        circles_list.append(circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95f892-6728-49d9-9672-92b5129b0879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "circles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d442b-9468-4b43-8b22-65e4dd0e9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a dictionary to store the circle data\n",
    "circles_dict = {}\n",
    "next_id = 0\n",
    "\n",
    "# Loop through the frames\n",
    "for frame_idx, circles in enumerate(circles_list):\n",
    "    # Initialize a cost matrix for the circles in this frame and the previous frame\n",
    "    num_circles = len(circles)\n",
    "    if frame_idx == 0:\n",
    "        prev_circles = []\n",
    "        cost_matrix = np.zeros((num_circles, 1))\n",
    "    else:\n",
    "        prev_circles = circles_list[frame_idx-1]\n",
    "        num_prev_circles = len(prev_circles)\n",
    "        cost_matrix = np.zeros((num_circles, num_prev_circles))\n",
    "        for i, (x1, y1, r1) in enumerate(circles):\n",
    "            for j, (x2, y2, r2) in enumerate(prev_circles):\n",
    "                dist = np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "                cost_matrix[i, j] = dist\n",
    "    \n",
    "    # Use the Hungarian algorithm to find the optimal assignment of circles\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Add the circles to the dictionary\n",
    "    for i, j in zip(row_ind, col_ind):\n",
    "        if frame_idx == 0:\n",
    "            circles_dict[next_id] = [(circles[i][0], circles[i][1], circles[i][2])]\n",
    "            next_id += 1\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300bd97a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MERGING ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "preMerge = data[32268]\n",
    "merge = data[32269]\n",
    "postMerge = data[32270]\n",
    "\n",
    "# feature location with minMass, have some problems but the spurious effect are solved\n",
    "f = tp.locate(preMerge, dropSize, minmass = minMass, separation = sep, topn = nDrops, engine = 'numba')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(f['mass'], bins = 20)\n",
    "ax1.set(xlabel='mass', ylabel='count')\n",
    "ax2.imshow(preMerge)\n",
    "ax2.plot(f.x, f.y, 'bo')\n",
    "plt.suptitle(f\"Number of features found: {len(f)}\")\n",
    "plt.show()\n",
    "\n",
    "f = tp.locate(merge, dropSize, minmass = minMass, separation = sep, topn = nDrops-1, engine = 'numba')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(f['mass'], bins = 20)\n",
    "ax1.set(xlabel='mass', ylabel='count')\n",
    "ax2.imshow(merge)\n",
    "ax2.plot(f.x, f.y, 'bo')\n",
    "plt.suptitle(f\"Number of features found: {len(f)}\")\n",
    "\n",
    "f = tp.locate(postMerge, dropSize, minmass = minMass, separation = sep, topn = nDrops-1, engine = 'numba')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(f['mass'], bins = 20)\n",
    "ax1.set(xlabel='mass', ylabel='count')\n",
    "ax2.imshow(postMerge)\n",
    "ax2.plot(f.x, f.y, 'bo')\n",
    "plt.suptitle(f\"Number of features found: {len(f)}\")\n",
    "\n",
    "plt.show()\n",
    "tp.subpx_bias(f)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cda584d4033b4fbc423661afef9f2afe920081905f188573e835f76abdc60dee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
