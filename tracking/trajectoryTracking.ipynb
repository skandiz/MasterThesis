{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e32dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "import matplotlib.animation\n",
    "writervideo = matplotlib.animation.FFMpegWriter(fps=30)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "tp.quiet()\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "\n",
    "import random\n",
    "\n",
    "run_analysis_verb = True\n",
    "show_verb = False\n",
    "save_verb = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8044e885",
   "metadata": {},
   "source": [
    "# PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pims.pipeline\n",
    "def crop(image, x1, y1, x2, y2):    \n",
    "    npImage = np.array(image)\n",
    "    # Create same size alpha layer with circle\n",
    "    #alpha = Image.new('L', (920, 960), 0)\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\n",
    "    # Convert alpha Image to numpy arrayf\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = npImage[:, :, 1] * npAlpha\n",
    "    \n",
    "    ind = np.where(npImage == 0)\n",
    "    # npImage[200, 200] color of the border to swap with the black\n",
    "    npImage[ind] = npImage[200, 200]\n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = crop(pims.open('./data/movie.mp4'), 55, 55, 880, 880)\n",
    "data_ref = pims.open('./data/movie.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5fac4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(data[0])\n",
    "ax2.imshow(data_ref[0])\n",
    "plt.tight_layout()\n",
    "if save_verb: plt.savefig('./results/pre_processing.png' bbox_inches='tight')\n",
    "if 1: \n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3b7f592",
   "metadata": {},
   "source": [
    "# TRACKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0181830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the tracking\n",
    "dropSize = 31  \n",
    "minMass = 2000\n",
    "sep = 16\n",
    "nDrops = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8faa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES LOCATION\n",
    "\n",
    "nFrames = 100 # total number of frames of video --> len(data)\n",
    "startFrame = 0\n",
    "endFrame = startFrame + nFrames\n",
    "\n",
    "f = tp.batch(data[startFrame:endFrame], dropSize, minmass = minMass, separation = sep, topn = nDrops, engine = 'numba')    \n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d5021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOMALIES DETECTION\n",
    "\n",
    "num = np.zeros(nFrames)\n",
    "for i in range(nFrames):\n",
    "    num[i] = len(f.loc[f['frame'] == i])\n",
    "\n",
    "idx = np.where(num != nDrops)[0]\n",
    "print(idx)\n",
    "\n",
    "if len(idx) != 0:\n",
    "    delta = np.zeros(len(idx)-1)\n",
    "    for i in range(len(idx)-1):\n",
    "        delta[i] = idx[i+1]-idx[i]\n",
    "    print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0452d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES LINKING\n",
    "\"\"\" f : DataFrame\n",
    "    The DataFrame must include any number of column(s) for position and a\n",
    "    column of frame numbers. By default, 'x' and 'y' are expected for\n",
    "    position, and 'frame' is expected for frame number. See below for\n",
    "    options to use custom column names.\n",
    "search_range : float or tuple\n",
    "    the maximum distance features can move between frames,\n",
    "    optionally per dimension\n",
    "pos_columns : list of str, optional\n",
    "    Default is ['y', 'x'], or ['z', 'y', 'x'] when 'z' is present in f\n",
    "t_column : str, optional\n",
    "    Default is 'frame'\n",
    "memory : integer, optional\n",
    "    the maximum number of frames during which a feature can vanish\n",
    "\"\"\"\n",
    "\n",
    "t = tp.link_df(f, 150, memory = 2, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "display(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = max(t.particle)\n",
    "print(n)\n",
    "random.seed(5)\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "for i in range(max(t.particle)+1-n):\n",
    "    colors.append(\"#00FFFF\")\n",
    "c = []\n",
    "for p in t.particle:\n",
    "    c.append(colors[p])\n",
    "t[\"color\"] = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a18d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_particles = []\n",
    "for i in range(nFrames-1):\n",
    "    a = t.loc[t.frame == i].sort_values('particle').particle.values\n",
    "    b = t.loc[t.frame == i+1].sort_values('particle').particle.values\n",
    "    ind = np.where(np.in1d(a, b)==False)[0]\n",
    "    if ind.size > 0:\n",
    "        lost_particles.append([i, a[ind]])\n",
    "\n",
    "print(\"Total problems:\", len(lost_particles))\n",
    "if len(lost_particles) > 0: \n",
    "    print(f\"First failure occurred at frame {lost_particles[0][0]}\")\n",
    "    f1 = lost_particles[0][0]\n",
    "    f2 = lost_particles[0][0]+1\n",
    "    print(t.loc[t.frame == f1].sort_values('particle').particle.values)\n",
    "    print(t.loc[t.frame == f2].sort_values('particle').particle.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86195d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(lost_particles)>0: \n",
    "    fig, (ax, ax1) = plt.subplots(1, 2)\n",
    "    df = t.loc[t['frame'] == f1, [\"x\", \"y\", \"color\", \"particle\"]]\n",
    "    ax.scatter(df.x, df.y, s=50, ec = \"w\", facecolor = df.color)\n",
    "    #ax.scatter(df.loc[df.particle==43].x, df.loc[df.particle==43].y, s=100)\n",
    "    #ax.scatter(df.loc[df.particle==82].x, df.loc[df.particle==82].y, s=100)\n",
    "    ax.imshow(data[f1])\n",
    "\n",
    "    df1 = t.loc[t['frame'] == f2, [\"x\", \"y\", \"color\"]]\n",
    "    ax1.scatter(df1.x, df1.y, s=50, ec = \"w\", facecolor = df1.color)\n",
    "    ax1.imshow(data[f2])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tp.filter_stubs(t, nFrames/2)\n",
    "# Compare the number of particles in the unfiltered and filtered data.\n",
    "print('Before:', t['particle'].nunique())\n",
    "print('After:', t1['particle'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931aaae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "tp.plot_traj(t1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf138ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(f\"1: {len(t1[t1['particle'] == 0].x)}\")\n",
    "plt.plot(t1[t1['particle'] == 0].x, t1[t1['particle'] == 0].y, linewidth=.1)\n",
    "plt.plot(t1[t1['particle'] == 1].x, t1[t1['particle'] == 1].y, linewidth=.1)\n",
    "plt.plot(t1[t1['particle'] == 2].x, t1[t1['particle'] == 2].y, linewidth=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bd424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rawTrajs.loc[(rawTrajs.frame == 0) , [\"x\", \"y\", \"color\"]]\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(df.x, df.y, facecolors = 'none', edgecolors = df.color, s = 150)\n",
    "ax.imshow(data[0])\n",
    "if save_verb: plt.savefig(\"../results/location_example.png\",  bbox_inches='tight')\n",
    "if show_verb: \n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(frame):\n",
    "    df = rawTrajs.loc[(rawTrajs.frame == frame) & (rawTrajs.particle == red_particle_idx) , [\"x\",\"y\",\"color\"]]\n",
    "    graph.set_offsets(df)\n",
    "    graph.set_edgecolor(df.color)\n",
    "    graph2.set_data(data[frame])\n",
    "    title.set_text('frame = {}'.format(frame))\n",
    "    return graph\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "title = ax.set_title('frame = 0')\n",
    "df = rawTrajs.loc[(rawTrajs.frame == 0) & (rawTrajs.particle == red_particle_idx), [\"x\",\"y\",\"color\"]]\n",
    "\n",
    "graph = ax.scatter(df.x, df.y, facecolors = 'none', edgecolors = df.color, s = 150)\n",
    "\n",
    "graph2 = ax.imshow(data[0])\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, 100, interval = 5, blit=False)\n",
    "if 0: ani.save('../results/video/tracking.mp4', fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "if anim_show_verb:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e379a5a4",
   "metadata": {},
   "source": [
    "# estimate error in the tracking\n",
    "\n",
    "I note that between frames 18300 and 18900 a droplet 40 seems stable and isolated.\\\n",
    "Then applying a rectangular mask around it I compute the \"benchmark\" position of the droplet using Canny Edge Detection and Hough Transform.\\\n",
    "Finally I confront the tracking result with the benchmark and different window sizes of smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6552bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply mask to perform edge detection only on the benchmark particle\n",
    "@pims.pipeline\n",
    "def crop2(image, x1, y1, x2, y2):   \n",
    "    npImage = np.array(image)\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.rectangle([(x1, y1), (x2, y2)], fill = 255)\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = npImage[:, :, 1] * npAlpha\n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa16f714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark particle: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deprecated pixel format used, make sure you did set range correctly\n",
      "deprecated pixel format used, make sure you did set range correctly\n"
     ]
    }
   ],
   "source": [
    "startFrame = 18300\n",
    "endFrame = 18900\n",
    "framesArray = np.arange(startFrame, endFrame, 1) \n",
    "\n",
    "rawTrajs = pd.read_parquet(\"./results/parquet/pre_merge_tracking.parquet\")\n",
    "benchmark_particle_id = 40\n",
    "print(\"Benchmark particle:\", benchmark_particle_id)\n",
    "rawTraj = rawTrajs.loc[(rawTrajs.frame.between(startFrame, endFrame-1)) & (rawTrajs.particle == benchmark_particle_id)]\n",
    "if 1: ref = list(pims.open('./data/movie.mp4')[startFrame:endFrame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "162b5325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deprecated pixel format used, make sure you did set range correctly\n",
      " (repeated 18649 more times)\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "deprecated pixel format used, make sure you did set range correctly\n"
     ]
    }
   ],
   "source": [
    "# apply mask to perform edge detection only on the benchmark particle\n",
    "y1 = rawTraj.iloc[0].y - 50\n",
    "x1 = rawTraj.iloc[0].x - 50\n",
    "y2 = rawTraj.iloc[0].y + 110\n",
    "x2 = rawTraj.iloc[0].x + 120\n",
    "if 1: ref_masked = list(crop2(pims.open('./data/movie.mp4'), x1, y1, x2, y2)[startFrame:endFrame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4829c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (8, 6))\n",
    "ax.imshow(ref[0])\n",
    "ax.scatter(rawTraj.iloc[0].x, rawTraj.iloc[0].y, s=150, facecolors='none', edgecolors='b')\n",
    "ax.set(title = \"Selection of benchmark particle\", xlabel = \"x [px]\", ylabel = \"y [px]\")\n",
    "ax1.imshow(ref_masked[0])\n",
    "ax1.scatter(rawTraj.iloc[0].x, rawTraj.iloc[0].y, s=150, facecolors='none', edgecolors='b')\n",
    "ax1.set(title = \"Masked video\", xlabel = \"x [px]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/error_estimation/masked_frame.png\", bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662cfae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed to check that only particle 40 is selected by the mask\n",
    "fig = plt.figure()\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(frame):\n",
    "    df = rawTraj.loc[rawTraj.frame == startFrame + frame, [\"x\",\"y\", \"color\"]]\n",
    "    graph.set_offsets(df)\n",
    "    graph2.set_data(ref_masked[frame])\n",
    "    title.set_text('frame = {}'.format(startFrame + frame))\n",
    "    return graph\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "title = ax.set_title(f'frame = {startFrame}')\n",
    "df = rawTraj.loc[rawTraj.frame == startFrame, [\"x\",\"y\", \"color\"]]\n",
    "\n",
    "graph = ax.scatter(df.x, df.y, facecolors = 'none', edgecolors= df.color, s = 150)\n",
    "\n",
    "graph2 = ax.imshow(ref_masked[0])\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, endFrame-startFrame, interval = 2, blit=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b6de5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:06<00:00, 99.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of problems: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "circles = []\n",
    "problems = 0\n",
    "\n",
    "for i in tqdm(range(0, len(ref_masked))):\n",
    "    img = ref_masked[i]\n",
    "    \"\"\"\n",
    "                    -- this works fine !!!!! --\n",
    "    # Apply Canny Edge Detection to find edges in the image\n",
    "    edges = cv2.Canny(img, 30, 30)\n",
    "    # Apply the Hough Transform to find circles in the image \n",
    "    temp = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, minDist=20, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "    if temp is not None:\n",
    "        circles.append(temp[0][0])\n",
    "   \"\"\"\n",
    "    \n",
    "    # this gives better results\n",
    "    temp = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, 1.5, minDist=1, param1=300, param2=0.6, minRadius=10, maxRadius=21)\n",
    "    if temp is not None:\n",
    "        circles.append(temp[0][0])\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        problems += 1\n",
    "print(\"Number of problems:\", problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38934f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(len(circles))\n",
    "y = np.zeros(len(circles))\n",
    "d = np.zeros(len(circles))\n",
    "\n",
    "for i in range(len(circles)):\n",
    "    x[i] = circles[i][0]\n",
    "    y[i] = circles[i][1]\n",
    "    d[i] = circles[i][2]\n",
    "    \n",
    "benchmark_traj = pd.DataFrame({\"x\": x, \"y\": y, \"d\": d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59d14fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE with raw trajectory: 4.191993973958964\n"
     ]
    }
   ],
   "source": [
    "tracking_pos = np.sqrt(rawTraj.x**2 + rawTraj.y**2)\n",
    "\n",
    "benchmark_pos = np.sqrt(x**2 + y**2)\n",
    "mse_raw = ((benchmark_pos - tracking_pos)**2).mean()\n",
    "print(\"MSE with raw trajectory:\", mse_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1488998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "def get_smooth_trajs(trajs, nDrops, windLen, orderofPoly):\n",
    "    # Trajectory Smoothing: using a Savgol Filter in order to drop the noise due to the tracking procedure\n",
    "    ret = trajs.copy()\n",
    "    for i in range(nDrops):\n",
    "        ret.loc[ret.particle == i, \"x\"] = savgol_filter(trajs.loc[trajs.particle == i].x.values, windLen, orderofPoly)\n",
    "        ret.loc[ret.particle == i, \"y\"] = savgol_filter(trajs.loc[trajs.particle == i].y.values, windLen, orderofPoly)    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5201bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE smoothing window 30: 1.6294871210727186\n"
     ]
    }
   ],
   "source": [
    "windLen = 30\n",
    "smoothTrajs = get_smooth_trajs(rawTrajs, 50, windLen, 2)\n",
    "smoothTraj = smoothTrajs.loc[(smoothTrajs.frame.between(startFrame, endFrame-1)) & (smoothTrajs.particle == benchmark_particle_id)]\n",
    "tracking_smooth_pos = np.sqrt(smoothTraj.x**2 + smoothTraj.y**2)\n",
    "mse = ((benchmark_pos - tracking_smooth_pos)**2).mean()\n",
    "print(f\"MSE smoothing window {windLen}:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab93cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax.plot(framesArray, benchmark_pos, label = \"benchmark\")\n",
    "ax.plot(framesArray, tracking_pos, label = \"tracking\")\n",
    "ax.set_title(\"Confront with raw traj\")\n",
    "ax1.plot(framesArray, benchmark_pos, label = \"benchmark\")\n",
    "ax1.plot(framesArray, tracking_smooth_pos, label = \"tracking\")\n",
    "ax1.set_title(f\"Confront with smooth traj (window = {windLen})\")\n",
    "ax.legend()\n",
    "ax1.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/error_estimation/benchmark_confront_wind30.png\", bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "109f09cf",
   "metadata": {},
   "source": [
    "## MSE ANALYSIS OF THE SMOOTHING WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b38d7bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [02:47<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "windLenList = np.arange(3, 100, 1)\n",
    "mse = np.zeros(len(windLenList))\n",
    "\n",
    "for k in tqdm(range(len(windLenList))):\n",
    "    smoothTrajs = get_smooth_trajs(rawTrajs, 50, windLenList[k], 2)\n",
    "    smoothTraj = smoothTrajs.loc[(smoothTrajs.frame.between(startFrame, endFrame-1)) & (smoothTrajs.particle == benchmark_particle_id)]\n",
    "    tracking_smooth_pos = np.sqrt(smoothTraj.x**2 + smoothTraj.y**2)\n",
    "    mse[k] = ((benchmark_pos - tracking_smooth_pos)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d34e8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deprecated pixel format used, make sure you did set range correctly\n",
      " (repeated 18649 more times)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "ax.hlines(mse_raw, windLenList[0], windLenList[-1], 'r', label = \"raw\")\n",
    "ax.plot(windLenList, mse, label = \"smooth\")\n",
    "ax.set_title(\"MSE vs smoothing window\")\n",
    "ax.set_xlabel(\"Smoothing window\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.legend(loc='center right')\n",
    "plt.savefig(\"./results/error_estimation/mse_vs_window.png\", bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "300bd97a",
   "metadata": {},
   "source": [
    "# MERGING ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "preMerge = data[32268]\n",
    "merge = data[32269]\n",
    "postMerge = data[32270]\n",
    "\n",
    "# feature location with minMass, have some problems but the spurious effect are solved\n",
    "f = tp.locate(preMerge, dropSize, minmass = minMass, separation = sep, topn = nDrops, engine = 'numba')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(f['mass'], bins = 20)\n",
    "ax1.set(xlabel='mass', ylabel='count')\n",
    "ax2.imshow(preMerge)\n",
    "ax2.plot(f.x, f.y, 'bo')\n",
    "plt.suptitle(f\"Number of features found: {len(f)}\")\n",
    "plt.show()\n",
    "\n",
    "f = tp.locate(merge, dropSize, minmass = minMass, separation = sep, topn = nDrops-1, engine = 'numba')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(f['mass'], bins = 20)\n",
    "ax1.set(xlabel='mass', ylabel='count')\n",
    "ax2.imshow(merge)\n",
    "ax2.plot(f.x, f.y, 'bo')\n",
    "plt.suptitle(f\"Number of features found: {len(f)}\")\n",
    "\n",
    "f = tp.locate(postMerge, dropSize, minmass = minMass, separation = sep, topn = nDrops-1, engine = 'numba')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(f['mass'], bins = 20)\n",
    "ax1.set(xlabel='mass', ylabel='count')\n",
    "ax2.imshow(postMerge)\n",
    "ax2.plot(f.x, f.y, 'bo')\n",
    "plt.suptitle(f\"Number of features found: {len(f)}\")\n",
    "\n",
    "plt.show()\n",
    "tp.subpx_bias(f)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d03f01ef291c499e995b04207f4c53df5fb0240f9f8862c7ea43be3c52b56d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
