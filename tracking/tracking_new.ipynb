{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 17:01:51.636523: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize model with versatile fluorescence pretrained weights...\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n",
      "StarDist2D(2D_versatile_fluo): YXC → YXC\n",
      "├─ Directory: None\n",
      "└─ Config2D(n_dim=2, axes='YXC', n_channel_in=1, n_channel_out=33, train_checkpoint='weights_best.h5', train_checkpoint_last='weights_last.h5', train_checkpoint_epoch='weights_now.h5', n_rays=32, grid=(2, 2), backbone='unet', n_classes=None, unet_n_depth=3, unet_kernel_size=[3, 3], unet_n_filter_base=32, unet_n_conv_per_depth=2, unet_pool=[2, 2], unet_activation='relu', unet_last_activation='relu', unet_batch_norm=False, unet_dropout=0.0, unet_prefix='', net_conv_after_unet=128, net_input_shape=[None, None, 1], net_mask_shape=[None, None, 1], train_shape_completion=False, train_completion_crop=32, train_patch_size=[256, 256], train_background_reg=0.0001, train_foreground_only=0.9, train_sample_cache=True, train_dist_loss='mae', train_loss_weights=[1, 0.2], train_class_weights=(1, 1), train_epochs=800, train_steps_per_epoch=400, train_learning_rate=0.0003, train_batch_size=8, train_n_val_patches=None, train_tensorboard=True, train_reduce_lr={'factor': 0.5, 'patience': 80, 'min_delta': 0}, use_gpu=False)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('image', cmap='gray')\n",
    "%matplotlib ipympl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from stardist import _draw_polygons\n",
    "from stardist.models import StarDist2D\n",
    "print(\"Initialize model with versatile fluorescence pretrained weights...\")\n",
    "model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "print(model)\n",
    "from csbdeep.utils import normalize\n",
    "import skimage\n",
    "\n",
    "\n",
    "from scipy.optimize import dual_annealing, minimize\n",
    "\n",
    "from tifffile import imsave, imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(cap, frame, x1, y1, x2, y2, w, h, preprocess):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "    ret, image = cap.read()\n",
    "    if preprocess:\n",
    "        npImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        alpha = Image.new('L', (w, h), 0)\n",
    "        draw = ImageDraw.Draw(alpha)\n",
    "        draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "        npAlpha = np.array(alpha)\n",
    "        npImage = npImage*npAlpha\n",
    "        ind = np.where(npImage == 0)\n",
    "        npImage[ind] = npImage[200, 200]\n",
    "        kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5,-1],\n",
    "                           [0, -1, 0]])\n",
    "        # sharpen image https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "        npImage = cv2.filter2D(src=npImage, ddepth=-1, kernel=2*kernel)\n",
    "        npImage = npImage[y1:y2, x1:x2]\n",
    "        return normalize(npImage)\n",
    "    elif not preprocess:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        raise ValueError(\"preprocess must be a boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video has 540000 frames with a resolution of 640x480 and a framerate of 30 fps\n"
     ]
    }
   ],
   "source": [
    "video_selection = \"25b-25r\"\n",
    "system_name     = f\"{video_selection} system\"\n",
    "source_path     = \"./data/25b25r-1.mp4\" \n",
    "xmin, ymin, xmax, ymax = 100, 35, 530, 465\n",
    "nDrops = 50\n",
    "\n",
    "save_path = './25b_25r/new/'\n",
    "\n",
    "video = cv2.VideoCapture(source_path)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, first_frame = video.read()\n",
    "\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Video has {n_frames} frames with a resolution of {w}x{h} and a framerate of {fps} fps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD TRAINING DATASET -- USING HOUGH CIRCLE METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_hough(cap, frame, x1, y1, x2, y2, w, h):\n",
    "\tcap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "\tret, image = cap.read()\n",
    "\tnpImage = np.array(image)\n",
    "\talpha = Image.new('L', (w, h), 0)\n",
    "\tdraw = ImageDraw.Draw(alpha)\n",
    "\tdraw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\tnpAlpha = np.array(alpha)\n",
    "\tnpImage = cv2.cvtColor(npImage, cv2.COLOR_BGR2GRAY)*npAlpha \n",
    "\tind = np.where(npImage == 0)\n",
    "\tnpImage[ind] = npImage[200, 200]\n",
    "\tnpImage = npImage[y1:y2, x1:x2]\n",
    "\treturn npImage #normalize(npImage)\n",
    "\t\n",
    "def hough_loc_frame(correct_n, frame, img, parameters):\n",
    "\tfound_circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, **parameters)\n",
    "\tif found_circles is not None:\n",
    "\t\treturn np.hstack((found_circles[0], (np.ones((found_circles.shape[1], 1), dtype=int)*frame),\\\n",
    "\t\t\t\t\t\t\tnp.ones((found_circles.shape[1], 1), dtype=int)*found_circles.shape[1]))\n",
    "\telse:\n",
    "\t\treturn np.hstack((np.ones((1, 3))*-1, np.array([[frame, 0]])))\n",
    "\t\t\n",
    "def hough_feature_location(sample_frames, correct_n, params):\n",
    "\ttemp = []\n",
    "\tfor frame in tqdm(sample_frames):\n",
    "\t\timg = get_frame_hough(video, frame, xmin, ymin, xmax, ymax, w, h)\n",
    "\t\ttemp.append(hough_loc_frame(correct_n, frame, img, params))\n",
    "\t\n",
    "\ttemp_df = pd.DataFrame(np.concatenate([arr for arr in temp]), columns = [\"x\", \"y\", \"d\", \"frame\", \"nDroplets\"])\n",
    "\ttemp_df[\"frame\"] = temp_df[\"frame\"].astype(int)\n",
    "\ttemp_df[\"nDroplets\"] = temp_df[\"nDroplets\"].astype(int)\n",
    "\terr_frames = temp_df.loc[temp_df.nDroplets != correct_n].frame.unique().astype(int)\n",
    "\tloss = err_frames.shape[0]/sample_frames.shape[0]\n",
    "\treturn temp_df, err_frames, loss\n",
    "\n",
    "def optimize_params(x, *args):\n",
    "\tframes, correct_n = args\n",
    "\tparams = {\"dp\":x[0], \"minDist\":int(x[1]), \"param1\":x[2], \"param2\":x[3], \"minRadius\":int(x[4]), \"maxRadius\":int(x[5])}\n",
    "\terrs = 0\n",
    "\tfor i in tqdm(frames):\n",
    "\t\timg = get_frame_hough(video, i, xmin, ymin, xmax, ymax, w, h)\n",
    "\t\tfound_circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, **params)\n",
    "\t\tif (found_circles is not None) and (found_circles.shape[1] == correct_n):\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\terrs += 1\n",
    "\t\t\t\n",
    "\tloss = errs/frames.shape[0]\n",
    "\ta = [loss, x[0], int(x[1]), x[2], x[3], int(x[4]), int(x[5])]\n",
    "\tprint(a)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "random.seed(0)\n",
    "sample_frames = np.sort(np.array(random.sample(range(n_frames), n_samples)), axis=0)\n",
    "\n",
    "test_params = {\"dp\":1.5, \"minDist\":10, \"param1\":20, \"param2\":0.7, \"minRadius\":5, \"maxRadius\":30}\n",
    "\n",
    "temp_df, err_frames, loss = hough_feature_location(sample_frames, nDrops, test_params)\n",
    "print(loss, err_frames)\n",
    "temp_df_test = temp_df.loc[temp_df.frame == err_frames[1]]\n",
    "test_img = get_frame_hough(video, err_frames[1], xmin, ymin, xmax, ymax, w, h)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.imshow(test_img, cmap=\"gray\")\n",
    "for i in range(temp_df_test.nDroplets.iloc[0]):\n",
    "    circle = plt.Circle((temp_df_test.x.iloc[i], temp_df_test.y.iloc[i]), temp_df_test.d.iloc[i], color='r', fill=True, alpha=0.5)\n",
    "    ax.add_artist(circle)\n",
    "ax.set(xticks=[], yticks=[], title=f\"Frame {err_frames[1]} -- {temp_df_test.nDroplets.iloc[0]} droplets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramters of HoughCircles --> dp, minDist, param1, param2, minRadius, maxRadius\n",
    "init_guess =  [2, 5, 20, 0.7, 7, 12] # initial guess for the parameters\n",
    "params_bounds = [(1, 3), (1, 10), (1, 100), (0.3, 1), (5, 10), (10, 15)] # bounds for the parameters\n",
    "\n",
    "opt_result = dual_annealing(optimize_params, x0 = init_guess, args = (sample_frames, nDrops), bounds = params_bounds, maxiter = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './25b_25r/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:53<00:00,  8.82it/s]\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    n_samples = 1000\n",
    "    random.seed(0)\n",
    "    sample_frames = np.sort(np.array(random.sample(range(n_frames), n_samples)), axis=0)\n",
    "    test_frame = get_frame(video, sample_frames[-1], xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "    sample_video = np.zeros((n_samples, test_frame.shape[0], test_frame.shape[1]), dtype=test_frame.dtype)\n",
    "    for i in tqdm(range(len(sample_frames))):\n",
    "        sample_video[i] = get_frame(video, sample_frames[i], xmin, ymin, xmax, ymax, w, h, True)\n",
    "        imsave(f\"train/test/train_{i}.png\", sample_video[i])\n",
    "    # multipage tif\n",
    "    #imsave('multipage.tif', sample_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SETUP\n",
    "n_samples = 10000\n",
    "#sample_frames = np.linspace(0, n_frames - 1, n_samples, dtype=int)\n",
    "random.seed(0)\n",
    "sample_frames = np.sort(np.array(random.sample(range(n_frames), n_samples)), axis=0)\n",
    "\n",
    "img = get_frame(video, sample_frames[-1], xmin, ymin, xmax, ymax, w, h, True)\n",
    "labels_test, dict_test = model.predict_instances(img, predict_kwargs = {'verbose':False}) \n",
    "test = skimage.measure.regionprops_table(labels_test, properties=('centroid', 'area'))\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 6), sharex=True, sharey=True)\n",
    "coord, points, prob = dict_test['coord'], dict_test['points'], dict_test['prob']\n",
    "ax.imshow(img, cmap='gray'); \n",
    "ax.set(title = 'Preprocessed Image', xlabel='X [px]', ylabel='Y [px]')\n",
    "ax1.imshow(img, cmap='gray'); \n",
    "_draw_polygons(coord, points, prob, show_dist=True)\n",
    "ax1.set(title = f\"Stardist result\", xlabel='X [px]', ylabel='Y [px]')\n",
    "plt.suptitle(f\"Stardist result on frame {sample_frames[-1]}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f'example_sharp2.png', dpi = 500)\n",
    "plt.close()\n",
    "\n",
    "if 0:\n",
    "    area, x, y, prob, framesList = [], [], [], [], []\n",
    "    for frame in tqdm(sample_frames):\n",
    "        segmented_image, dict_test = model.predict_instances(get_frame(video, frame, xmin, ymin, xmax, ymax, w, h, True), \\\n",
    "                                                            predict_kwargs = {'verbose' : False})\n",
    "        test = skimage.measure.regionprops_table(segmented_image, properties=('centroid', 'area'))\n",
    "\n",
    "        area   += list(test['area'])\n",
    "        y      += list(test['centroid-0'])\n",
    "        x      += list(test['centroid-1'])\n",
    "        prob   += list(dict_test['prob'])\n",
    "        framesList += list(np.ones(len(list(test['centroid-0'])))*frame)\n",
    "    # save data\n",
    "    print(\"Saving data...\")\n",
    "    raw_detection_df = pd.DataFrame({'x':x, 'y':y, 'area':area, 'prob':prob, 'frame':framesList})\n",
    "    raw_detection_df['frame'] = raw_detection_df.frame.astype('int')\n",
    "    raw_detection_df['r'] = np.sqrt(raw_detection_df.area/np.pi)\n",
    "    raw_detection_df.sort_values(by=['frame', 'prob'], ascending=[True, False], inplace=True)\n",
    "    raw_detection_df.to_parquet(save_path + 'df_test_sharp2.parquet')\n",
    "else:\n",
    "    raw_detection_df = pd.read_parquet(save_path + 'df_test_10000_sharp2.parquet')\n",
    "\n",
    "# analyze the result of raw features location\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 4))\n",
    "ax[0, 0].plot(raw_detection_df.frame.unique(), raw_detection_df.groupby('frame').count().x.values, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(raw_detection_df.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].hist(raw_detection_df.r, bins=100, density=True)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Density', title='Radius distribution')\n",
    "ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='Probability distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + 'raw_features_sharp2.png', dpi = 500)\n",
    "plt.close()\n",
    "\n",
    "try:\n",
    "    selected_frame = sample_frames[np.where(raw_detection_df.groupby('frame').count().x.values < nDrops)[0][0]]\n",
    "except:\n",
    "    selected_frame = sample_frames[np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0][0]]\n",
    "\n",
    "img = get_frame(video, selected_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_title(f\"Frame {selected_frame}\")\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == selected_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == selected_frame].x.values[i], raw_detection_df.loc[raw_detection_df.frame == selected_frame].y.values[i]), \\\n",
    "                                raw_detection_df.loc[raw_detection_df.frame == selected_frame].r.values[i], color='r', fill=False))\n",
    "plt.savefig(save_path + f'example_of_spurious_effect_sharp2.png', dpi = 500)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter found features\n",
    "print(\"Errors pre filtering:\", len(np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0]), \"/\", len(raw_detection_df.frame.unique()))\n",
    "\n",
    "rmax, rmin = 12, 6.3\n",
    "filtered_df = raw_detection_df.loc[raw_detection_df.r.between(rmin, rmax)]\n",
    "filtered_df = filtered_df.groupby('frame').apply(lambda x: x.nlargest(nDrops, 'prob'))\n",
    "filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Errors after filtering:\", len(np.where(filtered_df.groupby('frame').count().x.values != nDrops)[0]), \"/\", len(filtered_df.frame.unique()))\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 4))\n",
    "ax[0, 0].plot(filtered_df.frame.unique(), filtered_df.groupby('frame').count().x.values, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(filtered_df.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].hist(filtered_df.r, bins=100, density=True)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Density', title='Radius distribution')\n",
    "ax[1, 1].scatter(filtered_df.r, filtered_df.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='Probability distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + 'filtered_features_sharp2.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame = filtered_df.loc[filtered_df.prob == min(filtered_df.prob)].frame.values[0]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "ax.set_title(f\"Frame {test_frame}\")\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax.plot(filtered_df.loc[filtered_df.prob == min(filtered_df.prob)].x, filtered_df.loc[filtered_df.prob == min(filtered_df.prob)].y, 'b.')\n",
    "ax1.imshow(get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_features(sample_frames, run_verb, save_verb):\n",
    "    if run_verb:\n",
    "        feature_properties_dict = {'frame':[], 'centroid-1':[], 'centroid-0':[], 'area':[], 'r':[], 'eccentricity':[],\\\n",
    "                                   'prob':[], 'area_bbox':[], 'area_convex':[], 'area_filled':[], 'axis_major_length':[],\\\n",
    "                                   'axis_minor_length':[], 'bbox-0':[], 'bbox-1':[], 'bbox-2':[], 'bbox-3':[],\\\n",
    "                                   'equivalent_diameter_area':[], 'euler_number':[], 'extent':[], 'feret_diameter_max':[],\\\n",
    "                                   'inertia_tensor-0-0':[], 'inertia_tensor-0-1':[], 'inertia_tensor-1-0':[],\\\n",
    "                                   'inertia_tensor-1-1':[], 'inertia_tensor_eigvals-0':[], 'inertia_tensor_eigvals-1':[],\\\n",
    "                                   'label':[]}\n",
    "        for frame in tqdm(sample_frames):\n",
    "            img = get_frame(video, frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "            segmented_image, dict_test = model.predict_instances(img, predict_kwargs = {'verbose' : False})\n",
    "\n",
    "            feature_properties = skimage.measure.regionprops_table(segmented_image, \\\n",
    "                                                                   properties=('area', 'area_bbox', 'area_convex', 'area_filled',\\\n",
    "                                                                               'axis_major_length', 'axis_minor_length',\\\n",
    "                                                                               'bbox', 'centroid', 'eccentricity', \\\n",
    "                                                                               'equivalent_diameter_area', 'euler_number', 'extent',\\\n",
    "                                                                               'feret_diameter_max', 'inertia_tensor',\\\n",
    "                                                                               'inertia_tensor_eigvals', 'label'))\n",
    "\n",
    "            for key in feature_properties.keys():\n",
    "                feature_properties_dict[key] += list(feature_properties[key])\n",
    "                \n",
    "            feature_properties_dict['prob']  += list(dict_test['prob'])\n",
    "            feature_properties_dict['frame'] += list(np.ones(len(list(feature_properties['centroid-0'])))*frame)\n",
    "        # save data\n",
    "        print(\"Saving data to dataframe...\")\n",
    "        feature_properties_dict['r'] = np.sqrt(np.array(feature_properties_dict['area'])/np.pi)\n",
    "        raw_detection_df = pd.DataFrame(feature_properties_dict)\n",
    "        raw_detection_df.rename(columns={'centroid-0': 'y', 'centroid-1': 'x'}, inplace=True)\n",
    "        raw_detection_df['frame'] = raw_detection_df.frame.astype('int')\n",
    "        raw_detection_df.sort_values(by=['frame', 'prob'], ascending=[True, False], inplace=True)\n",
    "        if save_verb: \n",
    "            raw_detection_df.to_parquet(save_path + f'raw_detection_{video_selection}_from_{startFrame}_to_{endFrame}.parquet')\n",
    "    else:\n",
    "        raw_detection_df = pd.read_parquet(save_path + f'raw_detection_{video_selection}_from_{startFrame}_to_{endFrame}.parquet')\n",
    "\n",
    "    return raw_detection_df\n",
    "\n",
    "def filter_detection_data(r_min, r_max, raw_detection_df, nDrops):\n",
    "    # filter found features\n",
    "    print(\"Frames with spurious effects pre filtering:\", len(np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0]), \"/\", len(raw_detection_df.frame.unique()))\n",
    "\n",
    "    filtered_df = raw_detection_df.loc[raw_detection_df.r.between(rmin, rmax)]\n",
    "    filtered_df = filtered_df.groupby('frame').apply(lambda x: x.nlargest(nDrops, 'prob'))\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "    print(\"Frames with spurious effects after filtering:\", len(np.where(filtered_df.groupby('frame').count().x.values != nDrops)[0]), \"/\", len(filtered_df.frame.unique()))\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startFrame = 0\n",
    "endFrame = 10000\n",
    "print(f\"Processing from {int(startFrame/fps)} s to {int(endFrame/fps)} s\")\n",
    "\n",
    "sample_frames = np.arange(startFrame, endFrame, 1, dtype=int)\n",
    "run_verb = False\n",
    "save_verb = False\n",
    "raw_detection_df = detect_features(sample_frames, run_verb, save_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame0 = raw_detection_df.loc[(raw_detection_df.frame == 0) & (raw_detection_df.label == 1)]\n",
    "frame1 = raw_detection_df.loc[(raw_detection_df.frame == 1) & (raw_detection_df.label == 1)]\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax.imshow(get_frame(video, sample_frames[0], xmin, ymin, xmax, ymax, w, h, True), cmap='gray')\n",
    "ax.plot(frame0.x, frame0.y, 'r.')\n",
    "ax1.imshow(get_frame(video, sample_frames[1], xmin, ymin, xmax, ymax, w, h, True), cmap='gray')\n",
    "ax1.plot(frame1.x, frame1.y, 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the result of raw features location\n",
    "n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "ax[0, 0].plot(raw_detection_df.frame.unique(), n_feature_per_frame, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(raw_detection_df.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(save_path + 'raw_features.png', dpi = 500)\n",
    "plt.show()\n",
    "\n",
    "try:\n",
    "    selected_frame = sample_frames[np.where(raw_detection_df.groupby('frame').count().x.values < nDrops)[0][0]]\n",
    "except:\n",
    "    selected_frame = sample_frames[np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0][0]]\n",
    "\n",
    "img = get_frame(video, selected_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_title(f\"Example of spurious effect at frame {selected_frame}\")\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == selected_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == selected_frame].x.values[i], raw_detection_df.loc[raw_detection_df.frame == selected_frame].y.values[i]), \\\n",
    "                                raw_detection_df.loc[raw_detection_df.frame == selected_frame].r.values[i], color='r', fill=False))\n",
    "#plt.savefig(save_path + f'example_of_spurious_effect.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax, rmin = 12.5, 6.3\n",
    "filtered_df = filter_detection_data(rmin, rmax, raw_detection_df, nDrops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(8, 4))\n",
    "ax[0, 0].plot(filtered_df.frame.unique(), filtered_df.groupby('frame').count().x.values, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(filtered_df.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].hist(filtered_df.r, bins=100, density=True)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Density', title='Radius distribution')\n",
    "ax[1, 1].scatter(filtered_df.r, filtered_df.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='Probability distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + 'filtered_features.png', dpi = 500)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_frame = sample_frames[np.where(filtered_df.groupby('frame').count().x.values != nDrops)[0][0]]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "ax.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == test_frame].x.values[i],\\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].y.values[i]), \\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax1.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax1.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax1.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "plt.suptitle(f\"Filtered detection at a frame with spurious effects\")\n",
    "plt.show()\n",
    "\n",
    "test_frame = filtered_df.loc[filtered_df.r == min(filtered_df.r)].frame.values[0]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "\n",
    "ax.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == test_frame].x.values[i],\\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].y.values[i]), \\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax1.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax1.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax1.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "plt.suptitle(f\"Filtered detection with minimum radius detected\")\n",
    "plt.show()\n",
    "\n",
    "test_frame = filtered_df.loc[filtered_df.r == max(filtered_df.r)].frame.values[0]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "\n",
    "ax.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == test_frame].x.values[i],\\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].y.values[i]), \\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax1.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax1.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax1.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "plt.suptitle(f\"Filtered detection with maximum radius detected\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
