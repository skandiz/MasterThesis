{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:15:22.321441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:15:39.829063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n",
      "StarDist2D(2D_versatile_fluo): YXC → YXC\n",
      "├─ Directory: None\n",
      "└─ Config2D(n_dim=2, axes='YXC', n_channel_in=1, n_channel_out=33, train_checkpoint='weights_best.h5', train_checkpoint_last='weights_last.h5', train_checkpoint_epoch='weights_now.h5', n_rays=32, grid=(2, 2), backbone='unet', n_classes=None, unet_n_depth=3, unet_kernel_size=[3, 3], unet_n_filter_base=32, unet_n_conv_per_depth=2, unet_pool=[2, 2], unet_activation='relu', unet_last_activation='relu', unet_batch_norm=False, unet_dropout=0.0, unet_prefix='', net_conv_after_unet=128, net_input_shape=[None, None, 1], net_mask_shape=[None, None, 1], train_shape_completion=False, train_completion_crop=32, train_patch_size=[256, 256], train_background_reg=0.0001, train_foreground_only=0.9, train_sample_cache=True, train_dist_loss='mae', train_loss_weights=[1, 0.2], train_class_weights=(1, 1), train_epochs=800, train_steps_per_epoch=400, train_learning_rate=0.0003, train_batch_size=8, train_n_val_patches=None, train_tensorboard=True, train_reduce_lr={'factor': 0.5, 'patience': 80, 'min_delta': 0}, use_gpu=False)\n"
     ]
    }
   ],
   "source": [
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib ipympl\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.rcParams['font.size'] = 8\n",
    "mpl.rc('image', cmap='gray')\n",
    "import trackpy as tp\n",
    "tp.quiet()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, json\n",
    "import pims\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "from scipy.optimize import dual_annealing, linear_sum_assignment\n",
    "from scipy.spatial import distance_matrix\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import skimage\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D\n",
    "from stardist.data import test_image_nuclei_2d\n",
    "from stardist.plot import render_label\n",
    "from csbdeep.utils import normalize\n",
    "from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()\n",
    "# initialize model with versatile fluorescence pretrained weights\n",
    "model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pims.pipeline\n",
    "def preprocessing(image, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Preprocessing function for the data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : pims.Frame\n",
    "        Frame of the video.\n",
    "    x1 : int\n",
    "        x coordinate of the top left corner of the ROI. (region of interest)\n",
    "    y1 : int\n",
    "        y coordinate of the top left corner of the ROI.\n",
    "    x2 : int    \n",
    "        x coordinate of the bottom right corner of the ROI.\n",
    "    y2 : int    \n",
    "        y coordinate of the bottom right corner of the ROI.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    npImage : np.array\n",
    "        Preprocessed image.\n",
    "    \"\"\"\n",
    "    npImage = np.array(image)\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = cv2.cvtColor(npImage, cv2.COLOR_BGR2GRAY)*npAlpha\n",
    "    ind = np.where(npImage == 0)\n",
    "    npImage[ind] = npImage[200, 200]\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5,-1],\n",
    "                   [0, -1, 0]])\n",
    "    # sharpen image https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "    image_sharp = cv2.filter2D(src=npImage, ddepth=-1, kernel=kernel)\n",
    "    #npImage = cv2.medianBlur(npImage, 5)\n",
    "    #npImage = normalize(npImage)\n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing(pims.open('./data/movie.mp4'), 40, 55, 895, 910)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.imshow(data[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './stardist_res/sharp_post/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    preprocessed_data = np.zeros((30000, data[0].shape[0], data[0].shape[1]), dtype=data[0].dtype)\n",
    "    for i in tqdm(range(30000)):\n",
    "        preprocessed_data[i] = data[i]\n",
    "    #np.savez_compressed(path + 'preprocessed_data.npz', data=preprocessed_data) # --> 15 min\n",
    "else:\n",
    "    preprocessed_data = np.load(path + 'preprocessed_post_merge.npz')['data'] # --> 3 min\n",
    "\n",
    "correct_n = 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST\n",
    "frame = -1\n",
    "img = preprocessed_data[frame]\n",
    "labels_test, dict_test = model.predict_instances(normalize(img), predict_kwargs = {'verbose':False}) \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 5))\n",
    "ax.imshow(labels_test)\n",
    "ax.scatter(dict_test['points'][:,1], dict_test['points'][:,0], c='r', s=5)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "coord, points, prob = dict_test['coord'], dict_test['points'], dict_test['prob']\n",
    "ax = plt.subplot(121)\n",
    "ax.imshow(img, cmap='gray'); #plt.axis('off')\n",
    "ax.set(title = 'Preprocessed Image', xlabel='x', ylabel='y')\n",
    "ax1 = plt.subplot(122, sharex=ax, sharey=ax)\n",
    "ax1.imshow(img, cmap='gray'); #plt.axis('off')\n",
    "_draw_polygons(coord, points, prob, show_dist=True)\n",
    "ax1.set(title = 'Stardist result', xlabel='x', ylabel='y')\n",
    "#ax.set(xlim=(200, 600), ylim=(200, 600))\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'stardist_test.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run:\n",
    "    ## SEGMENT ALL FRAMES AND SAVE THEM IN A NPZ FILE \n",
    "    ## COMPUTE THE FEATURES AND SAVE THEM IN A DATAFRAME\n",
    "    nFrames = 10000\n",
    "    segm_preload = np.zeros((nFrames, 960, 920), dtype=np.int8)\n",
    "    area, x, y, prob = [], [], [], []\n",
    "\n",
    "    for frame in tqdm(range(nFrames)):\n",
    "        segm_preload[frame], dict_test = model.predict_instances(normalize(data[frame]), predict_kwargs = {'verbose':False})\n",
    "        test = skimage.measure.regionprops_table(segm_preload[frame], properties=('centroid', 'area'))\n",
    "        area += list(test['area'])\n",
    "        x += list(test['centroid-0'])\n",
    "        y += list(test['centroid-1'])\n",
    "        prob += list(dict_test['prob'])\n",
    "        frames += list(np.ones(len(test))*frame)\n",
    "\n",
    "    df = pd.DataFrame({'x':x, 'y':y, 'area':area, 'prob':prob})\n",
    "    df.to_parquet('./data/df.parquet')\n",
    "    print(df)\n",
    "\n",
    "    # Save the labeled elements using numpy.savez_compressed\n",
    "    np.savez_compressed(path, data=segm_preload)\n",
    "else:\n",
    "    labeled_elements = np.load(path + 'segm.npz')['labeled_elements'] #'data'\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(labeled_elements[-1], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path + 'df.parquet')\n",
    "df = df.loc[df.r.between(15, 30)]\n",
    "print(\"frames:\", len(df.frame.unique()))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.plot(df.frame.unique(), df.groupby('frame').count().x.values)\n",
    "ax.axhline(correct_n, color='r')\n",
    "plt.show()\n",
    "#df = df.loc[df.r.between(15, 30)]\n",
    "\n",
    "df = df.groupby('frame').apply(lambda x: x.nlargest(49, 'prob'))\n",
    "df = df.reset_index(drop=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_frames = np.where(df.groupby('frame').count().x != correct_n)[0] + df.frame.min()\n",
    "print(len(err_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 4))\n",
    "ax[0, 0].plot(df.frame.unique(), df.groupby('frame').count().x.values)\n",
    "ax[0, 1].plot(df.r, '.')\n",
    "ax[1, 0].hist(df.area, bins=100, density=True)\n",
    "ax[1, 1].scatter(df.r, df.prob, s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmmeh_frames = df.loc[df.r > 24].frame.unique()\n",
    "print(mmmeh_frames)\n",
    "frame = mmmeh_frames[0]\n",
    "df_plot = df.loc[df.frame == frame]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.imshow(preprocessed_data[frame - df.frame.min()])\n",
    "for i in range(len(df_plot)):\n",
    "    ax.add_artist(plt.Circle((df_plot.x.values[i], df_plot.y.values[i]), df_plot.r.values[i], color='r', fill=False))\n",
    "ax.set(title='Labeled elements', xlabel='x', ylabel='y')\n",
    "ax1.set(title='Preprocessed image', xlabel='x', ylabel='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "#                                         LINK FEATURES WITH TRACKPY                                        #\n",
    "#############################################################################################################\n",
    "if 1:\n",
    "    t = tp.link_df(df, 150, memory = 3, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "    #print(t)\n",
    "    t = t.sort_values(['frame', 'particle'])\n",
    "\n",
    "    # CREATE COLOR COLUMN AND SAVE DF\n",
    "    n = max(t.particle)\n",
    "    print(n)\n",
    "    random.seed(5)\n",
    "    colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "    for i in range(max(t.particle)+1-n):\n",
    "        colors.append(\"#00FFFF\")\n",
    "    c = []\n",
    "    for p in t.particle:\n",
    "        c.append(colors[p])\n",
    "    t[\"color\"] = c\n",
    "    trajectory = t.copy()\n",
    "    print(trajectory)\n",
    "    trajectory.to_parquet(path + 'df_linked.parquet')\n",
    "else:\n",
    "    trajectory = pd.read_parquet(path + 'df_linked.parquet')\n",
    "    print(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5, 5))\n",
    "anim_running = True\n",
    "\n",
    "def onClick(event):\n",
    "    global anim_running\n",
    "    if anim_running:\n",
    "        ani.event_source.stop()\n",
    "        anim_running = False\n",
    "    else:\n",
    "        ani.event_source.start()\n",
    "        anim_running = True\n",
    "\n",
    "def update_graph(frame):\n",
    "    df = trajectory.loc[(trajectory.frame == frame) , [\"x\", \"y\", \"color\", \"r\"]]\n",
    "    for i in range(len(df)):\n",
    "        graph[i].center = (df.x.values[i], df.y.values[i])\n",
    "        graph[i].radius = df.r.values[i]\n",
    "    graph2.set_data(preprocessed_data[frame-trajectory.frame.min()])\n",
    "    title.set_text('Tracking raw - frame = {}'.format(frame))\n",
    "    return graph\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "title = ax.set_title('Tracking stardist + trackpy - frame = 0')\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "df = trajectory.loc[(trajectory.frame == trajectory.frame.min()), [\"x\", \"y\", \"color\", \"r\"]]\n",
    "\n",
    "graph = []\n",
    "for i in range(len(df)):\n",
    "    graph.append(ax.add_artist(plt.Circle((df.x.values[i], df.y.values[i]), df.r.values[i], color = df.color.values[i],\\\n",
    "                                           fill = False, linewidth=1)))\n",
    "graph2 = ax.imshow(preprocessed_data[0])\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, range(trajectory.frame.min(), trajectory.frame.max(), 1), interval = 5, blit=False)\n",
    "if 1: \n",
    "    writer = matplotlib.animation.FFMpegWriter(fps = 30, metadata = dict(artist='Matteo Scandola'), extra_args=['-vcodec', 'libx264'])\n",
    "    ani.save(path + 'tracking.mp4', writer=writer, dpi = 300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
