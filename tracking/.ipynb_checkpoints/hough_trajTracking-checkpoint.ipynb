{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib ipympl\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.rcParams['font.size'] = 8\n",
    "mpl.rc('image', cmap='gray')\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "import matplotlib.animation\n",
    "writervideo = matplotlib.animation.FFMpegWriter(fps=30)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, json\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "tp.quiet()\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "from scipy.optimize import dual_annealing, minimize\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "import random\n",
    "\n",
    "run_analysis_verb = False\n",
    "show_verb = True\n",
    "save_verb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_frame(correct_n, frames[i], data_preload[i], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@joblib.delayed\n",
    "def loc_frame_parallel(correct_n, frame, img, parameters):\n",
    "\tfound_circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, **parameters)\n",
    "\tif (found_circles is not None) and (found_circles.shape[1] == correct_n):\n",
    "\t\treturn np.hstack((found_circles[0], (np.ones((correct_n, 1), dtype=int)*frame), np.ones((correct_n, 1), dtype=int)*correct_n))\n",
    "\telif (found_circles is not None) and (found_circles.shape[1] != correct_n):\n",
    "\t\treturn np.hstack((np.zeros((correct_n, 3)), (np.ones((correct_n, 1), dtype=int)*frame), np.ones((correct_n, 1), dtype=int)*found_circles.shape[1]))\n",
    "\telse:\n",
    "\t\treturn np.hstack((np.zeros((correct_n, 3)), (np.ones((correct_n, 1), dtype=int)*frame), np.zeros((correct_n, 1), dtype=int)))\n",
    "\n",
    "def loc_frame(correct_n, frame, img, parameters):\n",
    "\tfound_circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT_ALT, **parameters)\n",
    "\tif (found_circles is not None) and (found_circles.shape[1] == correct_n):\n",
    "\t\treturn np.hstack((found_circles[0], (np.ones((correct_n, 1), dtype=int)*frame), np.ones((correct_n, 1), dtype=int)*correct_n))\n",
    "\telif (found_circles is not None) and (found_circles.shape[1] != correct_n):\n",
    "\t\treturn np.hstack((np.zeros((correct_n, 3)), (np.ones((correct_n, 1), dtype=int)*frame), np.ones((correct_n, 1), dtype=int)*found_circles.shape[1]))\n",
    "\telse:\n",
    "\t\treturn np.hstack((np.zeros((correct_n, 3)), (np.ones((correct_n, 1), dtype=int)*frame), np.zeros((correct_n, 1), dtype=int)))\n",
    "\n",
    "def hough_feature_location(data_preload, frames, correct_n, params, parallel_verb):\n",
    "    parallel = joblib.Parallel(n_jobs = -2)\n",
    "    temp = parallel(\n",
    "        loc_frame_parallel(correct_n, frames[i], data_preload[i], params)\n",
    "        for i in range(len(frames)) \n",
    "    )\n",
    "    temp = pd.DataFrame(np.array(temp).reshape(len(frames)*correct_n, 5), columns = [\"x\", \"y\", \"d\", \"frame\", \"nDroplets\"])\n",
    "    err_frames = temp.loc[temp.nDroplets != correct_n].frame.unique().astype(int)\n",
    "    loss = err_frames.shape[0]/frames.shape[0]\n",
    "    return temp, err_frames, loss\n",
    "\n",
    "def optimize_params(x, *args):\n",
    "    data_preload, frames, correct_n = args\n",
    "    params = {\"dp\":x[0], \"minDist\":int(x[1]), \"param1\":x[2], \"param2\":x[3], \"minRadius\":int(x[4]), \"maxRadius\":int(x[5])}\n",
    "    _, _, loss = hough_feature_location(data_preload, frames, correct_n, params, True)\n",
    "    return loss\n",
    "\n",
    "def plot_optimization_results(opt_result_df, slot2):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(np.arange(0, len(opt_result_df.loss), 1), opt_result_df.loss, 'b-')\n",
    "    ax.set_ylabel(\"loss\", color = 'b') \n",
    "    ax1 = ax.twinx() \n",
    "    ax1.plot(np.arange(0, len(opt_result_df[slot2]), 1), opt_result_df[slot2], 'r.')\n",
    "    ax1.set_ylabel(slot2, color='r')\n",
    "    ax.grid()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "@pims.pipeline\n",
    "def hough_preprocessing(image, x1, y1, x2, y2):    \n",
    "    #image = cv2.GaussianBlur(image, ksize = [7,7], sigmaX = 1.5, sigmaY = 1.5)\n",
    "    npImage = np.array(image)\n",
    "    # Create same size alpha layer with circle\n",
    "    alpha = Image.new('L', (920, 960), 0)\n",
    "\n",
    "    draw = ImageDraw.Draw(alpha)\n",
    "    draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\n",
    "    # Convert alpha Image to numpy array\n",
    "    npAlpha = np.array(alpha)\n",
    "    npImage = cv2.cvtColor(npImage, cv2.COLOR_BGR2GRAY)*npAlpha #npImage[:, :, 1] * npAlpha\n",
    "    \n",
    "    ind = np.where(npImage == 0)\n",
    "    # npImage[200, 200] color of the border to swap with the black\n",
    "    npImage[ind] = npImage[200, 200]\n",
    "    npImage = cv2.medianBlur(npImage, 3)\n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deprecated pixel format used, make sure you did set range correctly\n"
     ]
    }
   ],
   "source": [
    "# SETUP\n",
    "preload_load_data = False # takes 20 min\n",
    "merge_frame = 32269\n",
    "data = hough_preprocessing(pims.open('./data/movie.mp4'), 40, 55, 895, 910)\n",
    "if preload_load_data: \n",
    "    data_preload = list(data[:merge_frame])\n",
    "\n",
    "startFrame = 0\n",
    "endFrame = merge_frame\n",
    "frames = np.arange(startFrame, endFrame, 1)\n",
    "frames_opt = np.sort(random.sample(list(frames), 5000))\n",
    "correct_n = 50\n",
    "default_parameters = {\"dp\": 1.5, \"minDist\": 15, \"param1\": 100, \"param2\": 0.8, \"minRadius\": 15, \"maxRadius\": 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     writer\u001b[39m.\u001b[39mwriterow([\u001b[39m'\u001b[39m\u001b[39mdp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mminDist\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mparam1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mparam2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mminRadius\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmaxRadius\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m opt_result \u001b[39m=\u001b[39m dual_annealing(optimize_params, x0 \u001b[39m=\u001b[39;49m [\u001b[39m1.5\u001b[39;49m, \u001b[39m15\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m0.9\u001b[39;49m, \u001b[39m15\u001b[39;49m, \u001b[39m25\u001b[39;49m], args \u001b[39m=\u001b[39;49m (data_preload, frames_opt[:\u001b[39m1000\u001b[39;49m], correct_n),\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                             bounds \u001b[39m=\u001b[39;49m [(\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m), (\u001b[39m5\u001b[39;49m, \u001b[39m20\u001b[39;49m), (\u001b[39m80\u001b[39;49m, \u001b[39m200\u001b[39;49m), (\u001b[39m0.3\u001b[39;49m, \u001b[39m1\u001b[39;49m), (\u001b[39m5\u001b[39;49m, \u001b[39m20\u001b[39;49m), (\u001b[39m20\u001b[39;49m, \u001b[39m40\u001b[39;49m)], maxiter \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m, callback\u001b[39m=\u001b[39;49mcallback)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyenv3/lib/python3.10/site-packages/scipy/optimize/_dual_annealing.py:706\u001b[0m, in \u001b[0;36mdual_annealing\u001b[0;34m(func, bounds, args, maxiter, minimizer_kwargs, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0, local_search_options)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[39m# starting strategy chain\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m val \u001b[39m=\u001b[39m strategy_chain\u001b[39m.\u001b[39;49mrun(i, temperature)\n\u001b[1;32m    707\u001b[0m \u001b[39mif\u001b[39;00m val \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    708\u001b[0m     message\u001b[39m.\u001b[39mappend(val)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyenv3/lib/python3.10/site-packages/scipy/optimize/_dual_annealing.py:299\u001b[0m, in \u001b[0;36mStrategyChain.run\u001b[0;34m(self, step, temperature)\u001b[0m\n\u001b[1;32m    296\u001b[0m x_visit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_dist\u001b[39m.\u001b[39mvisiting(\n\u001b[1;32m    297\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menergy_state\u001b[39m.\u001b[39mcurrent_location, j, temperature)\n\u001b[1;32m    298\u001b[0m \u001b[39m# Calling the objective function\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m e \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc_wrapper\u001b[39m.\u001b[39;49mfun(x_visit)\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m e \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menergy_state\u001b[39m.\u001b[39mcurrent_energy:\n\u001b[1;32m    301\u001b[0m     \u001b[39m# We have got a better energy value\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menergy_state\u001b[39m.\u001b[39mupdate_current(e, x_visit)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyenv3/lib/python3.10/site-packages/scipy/optimize/_dual_annealing.py:382\u001b[0m, in \u001b[0;36mObjectiveFunWrapper.fun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    381\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 382\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(x, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n",
      "\u001b[1;32m/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb Cell 5\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m data_preload, frames, correct_n \u001b[39m=\u001b[39m args\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdp\u001b[39m\u001b[39m\"\u001b[39m:x[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mminDist\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mint\u001b[39m(x[\u001b[39m1\u001b[39m]), \u001b[39m\"\u001b[39m\u001b[39mparam1\u001b[39m\u001b[39m\"\u001b[39m:x[\u001b[39m2\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mparam2\u001b[39m\u001b[39m\"\u001b[39m:x[\u001b[39m3\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mminRadius\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mint\u001b[39m(x[\u001b[39m4\u001b[39m]), \u001b[39m\"\u001b[39m\u001b[39mmaxRadius\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mint\u001b[39m(x[\u001b[39m5\u001b[39m])}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m _, _, loss \u001b[39m=\u001b[39m hough_feature_location(data_preload, frames, correct_n, params, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "\u001b[1;32m/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb Cell 5\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhough_feature_location\u001b[39m(data_preload, frames, correct_n, params, parallel_verb):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     parallel \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mParallel(n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     temp \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         loc_frame_parallel(correct_n, frames[i], data_preload[i], params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(frames)) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     temp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(np\u001b[39m.\u001b[39marray(temp)\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(frames)\u001b[39m*\u001b[39mcorrect_n, \u001b[39m5\u001b[39m), columns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39md\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnDroplets\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matteoscandola/MasterThesis/tracking/hough_trajTracking.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     err_frames \u001b[39m=\u001b[39m temp\u001b[39m.\u001b[39mloc[temp\u001b[39m.\u001b[39mnDroplets \u001b[39m!=\u001b[39m correct_n]\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39munique()\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyenv3/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/pyenv3/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/envs/pyenv3/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyenv3/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/pyenv3/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define a function to print the current best score and set of parameters\n",
    "def callback(x, f, context):\n",
    "    print(f'Current score: {f}, Best parameters: {x}')\n",
    "    # Save the current best score and set of parameters to a CSV file\n",
    "    with open('optimization_results.csv', mode = 'a', newline='') as file:\n",
    "       writer = csv.writer(file)\n",
    "       writer.writerow(list(x) + [f])\n",
    "\n",
    "# Clear the contents of the CSV file before starting the optimization\n",
    "with open('optimization_results.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['dp', 'minDist', 'param1', 'param2', 'minRadius', 'maxRadius', 'loss'])\n",
    "opt_result = dual_annealing(optimize_params, x0 = [1.5, 15, 100, 0.9, 15, 25], args = (data_preload, frames_opt[:1000], correct_n),\\\n",
    "                            bounds = [(1, 3), (5, 20), (80, 200), (0.3, 1), (5, 20), (20, 40)], maxiter = 2, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_verb = True\n",
    "run_optimization_verb = True\n",
    "if optimization_verb:\n",
    "    if run_optimization_verb:\n",
    "        # Define a function to print the current best score and set of parameters\n",
    "        def callback(x, f, context):\n",
    "            print(f'Current score: {f}, Best parameters: {x}')\n",
    "            # Save the current best score and set of parameters to a CSV file\n",
    "            with open('optimization_results.csv', mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(list(x) + [f])\n",
    "\n",
    "        # Clear the contents of the CSV file before starting the optimization\n",
    "        with open('optimization_results.csv', mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['dp', 'minDist', 'param1', 'param2', 'minRadius', 'maxRadius', 'loss'])\n",
    "        bounds = [(1, 3), (5, 20), (80, 200), (0.3, 1), (5, 20), (20, 40)]\n",
    "        opt_result = dual_annealing(optimize_params, x0 = [1.5, 15, 200, 0.9, 15, 25], args = (data_preload, frames_opt[:100], correct_n),\\\n",
    "                                    bounds = bounds, maxiter = 1000, callback=callback)\n",
    "    else:\n",
    "        try:\n",
    "            opt_result_df = pd.read_csv(\"./results/tracking_data/hough/pre_merge_optimization.csv\", sep=\"\\t\").sort_values(\"loss\", ascending=False)\n",
    "            opt_result_df = opt_result_df.sort_values(\"loss\", ascending=False)\n",
    "            optimized_parameters = opt_result_df.iloc[-1]\n",
    "            optimized_parameters = {\"dp\": optimized_parameters.dp, \"minDist\": optimized_parameters.minDist,\\\n",
    "                                    \"param1\": optimized_parameters.param1, \"param2\": optimized_parameters.param2,\\\n",
    "                                    \"minRadius\": int(optimized_parameters.minRadius), \"maxRadius\": int(optimized_parameters.maxRadius)}\n",
    "            parameters = optimized_parameters\n",
    "            print(\"Optimized parameters:\", parameters)\n",
    "            fig, ax = plt.subplots(1, 1, figsize = (10, 3))\n",
    "            ax.plot(opt_result_df.loss.values)\n",
    "            ax.set_ylabel(\"loss\")\n",
    "            ax.set_xlabel(\"iteration\")\n",
    "            ax.grid()\n",
    "            plt.show()\n",
    "        except:\n",
    "            raise Exception(\"No optimization results found\")\n",
    "else:\n",
    "    parameters = default_parameters\n",
    "    print(\"Default parameters:\", parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = 2.50993504   8.00993504 109.88808087   0.70993504  14.88808087 34.88808087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_err_frame(trial_f):\n",
    "    temp = cv2.HoughCircles(data_preload[trial_f], cv2.HOUGH_GRADIENT_ALT, **params)[0]\n",
    "\n",
    "    fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "    ax.imshow(data_preload[trial_f])\n",
    "    ax.set_title(f\"Error frame: {trial_f} --> {temp.shape[0]} droplet found\")\n",
    "    for i in range(temp.shape[0]):\n",
    "        ax.add_artist(plt.Circle((temp[i, 0], temp[i, 1]), temp[i, 2], color='r', fill=False))\n",
    "    ax1.scatter(temp[:,2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"dp\": .5, \"minDist\": 13, \"param1\": 80, \"param2\": 0.6, \"minRadius\": 11, \"maxRadius\": 29}\n",
    "pre_merge_df, err_frames, error = hough_feature_location(data_preload, frames_opt, correct_n, params, False)\n",
    "print(\"Error:\", error)\n",
    "print(\"Error frames:\", err_frames)\n",
    "if len(err_frames) > 0:\n",
    "    analyze_err_frame(err_frames[10])\n",
    "if len(err_frames) == 0:\n",
    "    pre_merge_df, err_frames, error = hough_feature_location(data_preload, frames, correct_n, params, False)\n",
    "    print(\"Error:\", error)\n",
    "    print(\"Error frames:\", err_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    # save to txt parameters:\n",
    "    with open('./results/tracking_data/hough/hough_pre_merge.txt', 'w') as f:\n",
    "        f.write(json.dumps(parameters))\n",
    "    pre_merge_df, err_frames, error = hough_feature_location(data_preload, frames, correct_n, parameters, False)\n",
    "    pre_merge_df.to_parquet(\"./results/tracking_data/hough_pre_merge.parquet\")\n",
    "else:\n",
    "    try:\n",
    "        parameters = json.load(open('./results/tracking_data/hough/hough_pre_merge.txt'))\n",
    "        pre_merge_df = pd.read_parquet(\"./results/tracking_data/hough/hough_pre_merge.parquet\")\n",
    "        print(parameters)\n",
    "        display(pre_merge_df)\n",
    "    except:\n",
    "        raise Exception(\"No pre merge data found, run analysis first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (pre_merge_df.frame.values[::correct_n]).astype(int)\n",
    "print(f\"Number of frames: {len(frames)}\")\n",
    "err_frames = pre_merge_df.loc[pre_merge_df.nDroplets != correct_n].frame.unique().astype(int)\n",
    "print(f\"Percentage of error: {len(err_frames)}/{len(frames)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
