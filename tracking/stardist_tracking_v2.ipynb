{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 16:44:07.020260: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('image', cmap='gray')\n",
    "%matplotlib ipympl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from stardist import _draw_polygons\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "import skimage\n",
    "\n",
    "from scipy.optimize import dual_annealing, minimize\n",
    "\n",
    "from tifffile import imsave, imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.988092, nms_thresh=0.3.\n",
      "StarDist2D(modified_2D_versatile_fluo): YXC → YXC\n",
      "├─ Directory: /Users/matteoscandola/MasterThesis/tracking/models/modified_2D_versatile_fluo\n",
      "└─ Config2D(n_dim=2, axes='YXC', n_channel_in=1, n_channel_out=33, train_checkpoint='weights_best.h5', train_checkpoint_last='weights_last.h5', train_checkpoint_epoch='weights_now.h5', n_rays=32, grid=(2, 2), backbone='unet', n_classes=None, unet_n_depth=3, unet_kernel_size=[3, 3], unet_n_filter_base=32, unet_n_conv_per_depth=2, unet_pool=[2, 2], unet_activation='relu', unet_last_activation='relu', unet_batch_norm=False, unet_dropout=0.0, unet_prefix='', net_conv_after_unet=128, net_input_shape=[None, None, 1], net_mask_shape=[None, None, 1], train_shape_completion=False, train_completion_crop=32, train_patch_size=[256, 256], train_background_reg=0.0001, train_foreground_only=0.9, train_sample_cache=True, train_dist_loss='mae', train_loss_weights=[1, 0.2], train_class_weights=(1, 1), train_epochs=800, train_steps_per_epoch=400, train_learning_rate=0.0003, train_batch_size=8, train_n_val_patches=None, train_tensorboard=True, train_reduce_lr={'factor': 0.5, 'patience': 80, 'min_delta': 0}, use_gpu=False)\n"
     ]
    }
   ],
   "source": [
    "# stardist model trained for 50 epochs on synthetic dataset\n",
    "#model_choice = 'synthetic'\n",
    "# stardist model trained on hough-circle dataset     \n",
    "#model_choice = 'hough' \n",
    "# stardist model trained for 50 epochs on synthetic dataset starting from the pretrained 2D versatile fluo model\n",
    "model_choice = 'synthetic_modified_2D_versatile_fluo' \n",
    "\n",
    "if model_choice == 'hough':\n",
    "    model = StarDist2D(None, name = 'stardist_1707523110.807234', basedir = './models/')\n",
    "elif model_choice == 'synthetic_modified_2D_versatile_fluo':\n",
    "    model = StarDist2D(None, name = 'modified_2D_versatile_fluo', basedir = './models/')\n",
    "elif model_choice == 'synthetic':\n",
    "    model = StarDist2D(None, name = 'stardist_synthetic_1707847742.498359', basedir = './models/')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_sharp(cap, frame, x1, y1, x2, y2, w, h, preprocess):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "    ret, image = cap.read()\n",
    "    if preprocess:\n",
    "        npImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        alpha = Image.new('L', (w, h), 0)\n",
    "        draw = ImageDraw.Draw(alpha)\n",
    "        draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "        npAlpha = np.array(alpha)\n",
    "        npImage = npImage*npAlpha\n",
    "        ind = np.where(npImage == 0)\n",
    "        npImage[ind] = npImage[200, 200]\n",
    "        kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5,-1],\n",
    "                           [0, -1, 0]])\n",
    "        # sharpen image https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "        npImage = cv2.filter2D(src=npImage, ddepth=-1, kernel=2*kernel)\n",
    "        npImage = npImage[y1:y2, x1:x2]\n",
    "        return normalize(npImage)\n",
    "    elif not preprocess:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        raise ValueError(\"preprocess must be a boolean\")\n",
    "    \n",
    "\n",
    "def get_frame(cap, frame, x1, y1, x2, y2, w, h):\n",
    "\tcap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "\tret, image = cap.read()\n",
    "\tnpImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\talpha = Image.new('L', (w, h), 0)\n",
    "\tdraw = ImageDraw.Draw(alpha)\n",
    "\tdraw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\tnpAlpha = np.array(alpha)\n",
    "\tnpImage = npImage*npAlpha\n",
    "\tind = np.where(npImage == 0)\n",
    "\tnpImage[ind] = npImage[200, 200]\n",
    "\tnpImage = npImage[y1:y2, x1:x2]\n",
    "\treturn cv2.resize(npImage, (500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video has 540000 frames with a resolution of 640x480 and a framerate of 30 fps\n"
     ]
    }
   ],
   "source": [
    "video_selection = \"25b-25r\"\n",
    "#video_selection = \"49b-1r\"\n",
    "\n",
    "system_name     = f\"{video_selection} system\"\n",
    "\n",
    "if video_selection == \"25b-25r\":\n",
    "    source_path     = \"./data/25b25r-1.mp4\" \n",
    "    xmin, ymin, xmax, ymax = 95, 30, 535, 470\n",
    "    nDrops = 50\n",
    "    save_path = './25b_25r/synthetic_trained/'\n",
    "\n",
    "elif video_selection == \"49b-1r\":\n",
    "    source_path     = \"./data/49b1r.mp4\"\n",
    "    xmin, ymin, xmax, ymax = 20, 50, 900, 930\n",
    "    nDrops = 50\n",
    "    save_path = './49b_1r/synthetic_trained/'\n",
    "\n",
    "video = cv2.VideoCapture(source_path)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Video has {n_frames} frames with a resolution of {w}x{h} and a framerate of {fps} fps\")\n",
    "_, first_frame = video.read()\n",
    "first_frame = first_frame[ymin:ymax, xmin:xmax]\n",
    "\n",
    "preprocessed_img = get_frame(video, 0, xmin, ymin, xmax, ymax, w, h)\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 6), sharex=True, sharey=True)\n",
    "ax.imshow(cv2.resize(cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB), (500, 500)))\n",
    "ax.set(title = \"Original video at frame 0\", xlabel = \"X [px]\", ylabel = \"Y [px]\")\n",
    "ax1.imshow(preprocessed_img)\n",
    "ax1.set(title = \"Preprocessed video at frame 0\", xlabel = \"X [px]\", ylabel = \"Y [px]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f\"preprocessed_frame_0_{model_choice}.pdf\", format = \"pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: d5d350d5f8c145ddac323b7802358ed1\n",
      "No such comm: d5d350d5f8c145ddac323b7802358ed1\n",
      "No such comm: d5d350d5f8c145ddac323b7802358ed1\n",
      "No such comm: d5d350d5f8c145ddac323b7802358ed1\n",
      "No such comm: d5d350d5f8c145ddac323b7802358ed1\n",
      "No such comm: d5d350d5f8c145ddac323b7802358ed1\n",
      "No such comm: 1d7601502eb14126bd5eaaf9fd19beac\n",
      "No such comm: 1d7601502eb14126bd5eaaf9fd19beac\n",
      "No such comm: 1d7601502eb14126bd5eaaf9fd19beac\n",
      "No such comm: 1d7601502eb14126bd5eaaf9fd19beac\n",
      "No such comm: 1d7601502eb14126bd5eaaf9fd19beac\n",
      "No such comm: 1d7601502eb14126bd5eaaf9fd19beac\n"
     ]
    }
   ],
   "source": [
    "selected_frame = n_frames-1\n",
    "img = get_frame(video, selected_frame , xmin, ymin, xmax, ymax, w, h)\n",
    "segmented_image, dict_test = model.predict_instances(normalize(img), predict_kwargs = {'verbose' : False})\n",
    "n_feature_detected = len(dict_test['prob'])\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 6), sharex=True, sharey=True)\n",
    "ax.imshow(img)\n",
    "ax.set(title = 'Preprocessed Image', xlabel='X [px]', ylabel='Y [px]')\n",
    "ax1.imshow(segmented_image)\n",
    "ax1.set(title = f\"Stardist result\", xlabel='X [px]', ylabel='Y [px]')\n",
    "plt.suptitle(f\"Detection at frame {selected_frame}-- {n_feature_detected} features detected\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f'stardist_example_{model_choice}.pdf', format='pdf')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 6), sharex=True, sharey=True)\n",
    "coord, points, prob = dict_test['coord'], dict_test['points'], dict_test['prob']\n",
    "ax.imshow(img)\n",
    "ax.set(title = 'Preprocessed Image', xlabel='X [px]', ylabel='Y [px]')\n",
    "ax1.imshow(img)\n",
    "_draw_polygons(coord, points, prob, show_dist=True)\n",
    "ax1.set(title = f\"Stardist result at frame {selected_frame} -- {n_feature_detected} features detected\", xlabel='X [px]', ylabel='Y [px]')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f'stardist_example2_{model_choice}.pdf', format='pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_features(sample_frames):\n",
    "    feature_properties_dict = {'frame':[], 'centroid-1':[], 'centroid-0':[], 'area':[], 'r':[], 'eccentricity':[],\\\n",
    "                                'prob':[], 'area_bbox':[], 'area_convex':[], 'area_filled':[], 'axis_major_length':[],\\\n",
    "                                'axis_minor_length':[], 'bbox-0':[], 'bbox-1':[], 'bbox-2':[], 'bbox-3':[],\\\n",
    "                                'equivalent_diameter_area':[], 'euler_number':[], 'extent':[], 'feret_diameter_max':[],\\\n",
    "                                'inertia_tensor-0-0':[], 'inertia_tensor-0-1':[], 'inertia_tensor-1-0':[],\\\n",
    "                                'inertia_tensor-1-1':[], 'inertia_tensor_eigvals-0':[], 'inertia_tensor_eigvals-1':[],\\\n",
    "                                'label':[]}\n",
    "    for frame in tqdm(sample_frames):\n",
    "        img = get_frame(video, frame, xmin, ymin, xmax, ymax, w, h)\n",
    "        segmented_image, dict_test = model.predict_instances(normalize(img), predict_kwargs = {'verbose' : False})\n",
    "\n",
    "        feature_properties = skimage.measure.regionprops_table(segmented_image, \\\n",
    "                                                                properties=('area', 'area_bbox', 'area_convex', 'area_filled',\\\n",
    "                                                                            'axis_major_length', 'axis_minor_length',\\\n",
    "                                                                            'bbox', 'centroid', 'eccentricity', \\\n",
    "                                                                            'equivalent_diameter_area', 'euler_number', 'extent',\\\n",
    "                                                                            'feret_diameter_max', 'inertia_tensor',\\\n",
    "                                                                            'inertia_tensor_eigvals', 'label'))\n",
    "\n",
    "        for key in feature_properties.keys():\n",
    "            feature_properties_dict[key] += list(feature_properties[key])\n",
    "            \n",
    "        feature_properties_dict['prob']  += list(dict_test['prob'])\n",
    "        feature_properties_dict['frame'] += list(np.ones(len(list(feature_properties['centroid-0'])))*frame)\n",
    "    # save data\n",
    "    print(\"Saving data to dataframe...\")\n",
    "    feature_properties_dict['r'] = np.sqrt(np.array(feature_properties_dict['area'])/np.pi)\n",
    "    raw_detection_df = pd.DataFrame(feature_properties_dict)\n",
    "    raw_detection_df.rename(columns={'centroid-0': 'y', 'centroid-1': 'x'}, inplace=True)\n",
    "    raw_detection_df['frame'] = raw_detection_df.frame.astype('int')\n",
    "    raw_detection_df.sort_values(by=['frame', 'prob'], ascending=[True, False], inplace=True)\n",
    "    raw_detection_df.to_parquet(save_path + f'raw_detection_{video_selection}_{model_choice}.parquet')\n",
    "    return raw_detection_df\n",
    "\n",
    "def filter_detection_data(r_min, r_max, raw_detection_df, nDrops):\n",
    "    # filter found features\n",
    "    print(\"Frames with spurious effects pre filtering:\", len(np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0]), \"/\", len(raw_detection_df.frame.unique()))\n",
    "\n",
    "    filtered_df = raw_detection_df.loc[raw_detection_df.r.between(rmin, rmax)]\n",
    "    filtered_df = filtered_df.groupby('frame').apply(lambda x: x.nlargest(nDrops, 'prob'))\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "    print(\"Frames with spurious effects after filtering:\", len(np.where(filtered_df.groupby('frame').count().x.values != nDrops)[0]), \"/\", len(filtered_df.frame.unique()))\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    startFrame = 0\n",
    "    endFrame = 10000\n",
    "    print(f\"Processing from {int(startFrame/fps)} s to {int(endFrame/fps)} s\")\n",
    "    sample_frames = np.arange(startFrame, endFrame, 1, dtype=int)\n",
    "\n",
    "#\n",
    "sample_frames = np.sort(np.random.choice(np.arange(0, n_frames, 1, dtype=int), 1000, replace=False))\n",
    "run_verb = True\n",
    "save_verb = True\n",
    "raw_detection_df = detect_features(sample_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the result of raw features location\n",
    "n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "ax[0, 0].plot(raw_detection_df.frame.unique(), n_feature_per_frame, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(raw_detection_df.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + f'raw_features_{model_choice}.png', dpi = 500)\n",
    "plt.close()\n",
    "\n",
    "try:\n",
    "    selected_frame = sample_frames[np.where(raw_detection_df.groupby('frame').count().x.values < nDrops)[0][0]]\n",
    "except:\n",
    "    selected_frame = sample_frames[np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0][0]]\n",
    "\n",
    "img = get_frame(video, selected_frame, xmin, ymin, xmax, ymax, w, h)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_title(f\"Example of spurious effect at frame {selected_frame}\")\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == selected_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == selected_frame].x.values[i], raw_detection_df.loc[raw_detection_df.frame == selected_frame].y.values[i]), \\\n",
    "                                raw_detection_df.loc[raw_detection_df.frame == selected_frame].r.values[i], color='r', fill=False))\n",
    "plt.savefig(save_path + f'example_of_spurious_effect_{model_choice}.png', dpi = 500)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax, rmin = 12.5, 6.3\n",
    "filtered_df = filter_detection_data(rmin, rmax, raw_detection_df, nDrops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(8, 4))\n",
    "ax[0, 0].plot(filtered_df.frame.unique(), filtered_df.groupby('frame').count().x.values, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(filtered_df.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].hist(filtered_df.r, bins=100, density=True)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Density', title='Radius distribution')\n",
    "ax[1, 1].scatter(filtered_df.r, filtered_df.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='Probability distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + 'filtered_features.png', dpi = 500)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_frame = sample_frames[np.where(filtered_df.groupby('frame').count().x.values != nDrops)[0][0]]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "ax.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == test_frame].x.values[i],\\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].y.values[i]), \\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax1.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax1.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax1.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "plt.suptitle(f\"Filtered detection at a frame with spurious effects\")\n",
    "plt.show()\n",
    "\n",
    "test_frame = filtered_df.loc[filtered_df.r == min(filtered_df.r)].frame.values[0]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "\n",
    "ax.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == test_frame].x.values[i],\\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].y.values[i]), \\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax1.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax1.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax1.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "plt.suptitle(f\"Filtered detection with minimum radius detected\")\n",
    "plt.show()\n",
    "\n",
    "test_frame = filtered_df.loc[filtered_df.r == max(filtered_df.r)].frame.values[0]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "\n",
    "ax.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == test_frame].x.values[i],\\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].y.values[i]), \\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax1.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax1.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax1.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "plt.suptitle(f\"Filtered detection with maximum radius detected\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
