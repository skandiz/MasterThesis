{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('image', cmap='gray')\n",
    "import matplotlib.animation\n",
    "\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from stardist import _draw_polygons\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "import skimage\n",
    "from scipy.optimize import dual_annealing, minimize\n",
    "from tifffile import imsave, imread\n",
    "from utils import filter_detection_data, get_frame #detect_features,\n",
    "import trackpy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.989263, nms_thresh=0.3.\n",
      "Video has 540000 frames with a resolution of 640x480 and a framerate of 30 fps\n"
     ]
    }
   ],
   "source": [
    "#model_name = 'stardist_trained'          # stardist model trained for 50 epochs on simulated synthetic dataset\n",
    "model_name = 'modified_2D_versatile_fluo' # stardist model trained for 150 epochs on simulated dataset starting from the pretrained 2D versatile fluo model\n",
    "model = StarDist2D(None, name = model_name, basedir = './models/')\n",
    "\n",
    "video_selection = \"25b25r-1\" # \"49b1r\"\n",
    "if video_selection == \"25b25r-1\":\n",
    "    xmin, ymin, xmax, ymax = 95, 30, 535, 470    \n",
    "elif video_selection == \"49b1r\":\n",
    "    xmin, ymin, xmax, ymax = 20, 50, 900, 930\n",
    "\n",
    "save_path       = f'./{video_selection}/{model_name}/'\n",
    "source_path     = f'./data/{video_selection}.mp4'\n",
    "system_name     = f'{video_selection} system'\n",
    "nDrops = 50\n",
    "\n",
    "video = cv2.VideoCapture(source_path)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video has {n_frames} frames with a resolution of {w}x{h} and a framerate of {fps} fps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_verb = False\n",
    "detect_verb = False\n",
    "link_verb = False\n",
    "interp_verb = False\n",
    "\n",
    "startFrame = 0\n",
    "endFrame = 539999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_verb: \n",
    "    n_samples = 100\n",
    "    test_detection(n_samples, n_frames, nDrops, video_selection, model, model_name, video, xmin, ymin, xmax, ymax, w, h, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if detect_verb:\n",
    "    print(f'Processing from {int(startFrame/fps)} s to {int(endFrame/fps)} s')\n",
    "    sample_frames = np.arange(startFrame, endFrame, 1, dtype=int)\n",
    "    raw_detection_df = detect_features(sample_frames, False, video_selection, model, model_name, video, xmin, ymin, xmax, ymax, w, h, save_path)\n",
    "    \n",
    "    n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "    ax[0, 0].plot(raw_detection_df.frame.unique(), n_feature_per_frame, '.')\n",
    "    ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "    ax[0, 1].plot(raw_detection_df.r, '.')\n",
    "    ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "    ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "    ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "    ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "    ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path + f'raw_features_{model_name}_{startFrame}_{endFrame}.png', dpi = 500)\n",
    "    plt.close()\n",
    "else:\n",
    "    raw_detection_df = pd.read_parquet(save_path + f'raw_detection_25b25r-1_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet')\n",
    "    sample_frames = raw_detection_df.frame.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 618 / 540000 --> 0.11%\n",
      "Max number of consecutive errors: 15\n"
     ]
    }
   ],
   "source": [
    "err_frames = np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0]\n",
    "print(f'Number of errors: {len(err_frames)} / {len(sample_frames)} --> {len(err_frames)/len(sample_frames)*100:.2f}%')\n",
    "condition = np.ediff1d(err_frames)\n",
    "condition[condition == 1] = True\n",
    "condition[condition != 1] = False\n",
    "max_n_of_consecutive_errs = max(np.diff(np.where(np.concatenate(([condition[0]], condition[:-1] != condition[1:], [True])))[0])[::2])\n",
    "print(f'Max number of consecutive errors: {max_n_of_consecutive_errs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linking trajectories...\n"
     ]
    }
   ],
   "source": [
    "if link_verb:\n",
    "    print('Linking trajectories...')\n",
    "    cutoff = 100\n",
    "    mem = max_n_of_consecutive_errs + 1\n",
    "    t = tp.link_df(raw_detection_df, cutoff, memory = mem, link_strategy = 'hybrid', neighbor_strategy = 'KDTree', adaptive_stop = 1)\n",
    "    #print(t)\n",
    "    t = t.sort_values(['frame', 'particle'])\n",
    "    trajectories = tp.filter_stubs(t, 25)\n",
    "    # CREATE COLOR COLUMN AND SAVE DF\n",
    "    n = max(trajectories.particle)\n",
    "    print(f'N of droplets: {n + 1}')\n",
    "    random.seed(5)\n",
    "    colors = ['#'+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(n)]\n",
    "    for i in range(max(trajectories.particle)+1-n):\n",
    "        colors.append('#00FFFF')\n",
    "    c = []\n",
    "    for p in t.particle:\n",
    "        c.append(colors[p])\n",
    "    trajectories['color'] = c\n",
    "    trajectories = trajectories.reset_index(drop=True)\n",
    "    trajectories.to_parquet(save_path + f'raw_tracking_25b25r-1_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet', index = False)\n",
    "else:\n",
    "    print('Importing linked trajectories...')\n",
    "    trajectories = pd.read_parquet(save_path + f'raw_tracking_25b25r-1_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing interpolated trajectories...\n"
     ]
    }
   ],
   "source": [
    "if interp_verb:\n",
    "    print('Interpolating trajectories...')\n",
    "    interp_trajectories = trajectories.groupby('particle').apply(interpolate_trajectory)\n",
    "    interp_trajectories = interp_trajectories.reset_index(drop=True)\n",
    "    interp_trajectories['particle'] = interp_trajectories['particle'].astype(int)\n",
    "    interp_trajectories = interp_trajectories.sort_values(['frame', 'particle'])\n",
    "    interp_trajectories.to_parquet(save_path + f'interpolated_tracking_25b25r-1_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet', index=False)\n",
    "else:\n",
    "    print('Importing interpolated trajectories...')\n",
    "    interp_trajectories = pd.read_parquet(save_path + f'interpolated_tracking_25b25r-1_modified_2D_versatile_fluo_{startFrame}_{endFrame}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_test = interp_trajectories.loc[interp_trajectories.frame.isin(err_frames)]\n",
    "fig, ax = fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "def update_graph(frame):\n",
    "    df = traj_test.loc[(traj_test.frame == frame), [\"x\", \"y\", \"r\", 'color']]\n",
    "    for i in range(len(df)):\n",
    "        graph[i].center = (df.x.values[i], df.y.values[i])\n",
    "        graph[i].radius = df.r.values[i]\n",
    "    graph2.set_data(get_frame(video, frame, xmin, ymin, xmax, ymax, w, h, False))\n",
    "    title.set_text(f'{system_name} Tracking -- t = {round(frame/fps, 1)} s')\n",
    "    return graph\n",
    "\n",
    "title = ax.set_title(f'{system_name} Tracking -- t = {0} s')\n",
    "ax.set(xlabel = 'X [px]', ylabel = 'Y [px]')\n",
    "df = traj_test.loc[(traj_test.frame == min(traj_test.frame.unique())), [\"x\", \"y\", \"r\", 'color']]\n",
    "graph = []\n",
    "for i in range(len(df)):\n",
    "    graph.append(ax.add_artist(plt.Circle((df.x.values[i], df.y.values[i]), df.r.values[i], color = df.color.values[i],\\\n",
    "                                           fill = True, alpha = 0.5, linewidth=1)))\n",
    "graph2 = ax.imshow(get_frame(video, 0, xmin, ymin, xmax, ymax, w, h, False))\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, traj_test.frame.unique(), interval = 5, blit=False)\n",
    "writer = matplotlib.animation.FFMpegWriter(fps = 30, metadata = dict(artist='Matteo Scandola'), extra_args=['-vcodec', 'libx264'])\n",
    "ani.save(f'./{save_path}/tracking_video_errors.mp4', writer=writer, dpi = 200)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
