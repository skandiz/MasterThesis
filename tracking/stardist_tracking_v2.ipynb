{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('image', cmap='gray')\n",
    "%matplotlib ipympl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from stardist import _draw_polygons\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "import skimage\n",
    "\n",
    "from scipy.optimize import dual_annealing, minimize\n",
    "\n",
    "from tifffile import imsave, imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stardist model trained on hough-circle dataset\n",
    "#model = StarDist2D(None, name = 'stardist_1707523110.807234', basedir = './models/')\n",
    "\n",
    "# stardist model trained for 50 epochs on synthetic dataset starting from the pretrained 2D versatile fluo model\n",
    "#model = StarDist2D(None, name = 'modified_2D_versatile_fluo', basedir = './models/')\n",
    "\n",
    "# stardist model trained for 50 epochs on synthetic dataset\n",
    "model = StarDist2D(None, name = 'stardist_synthetic_1707847742.498359', basedir = './models/')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_sharp(cap, frame, x1, y1, x2, y2, w, h, preprocess):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "    ret, image = cap.read()\n",
    "    if preprocess:\n",
    "        npImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        alpha = Image.new('L', (w, h), 0)\n",
    "        draw = ImageDraw.Draw(alpha)\n",
    "        draw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "        npAlpha = np.array(alpha)\n",
    "        npImage = npImage*npAlpha\n",
    "        ind = np.where(npImage == 0)\n",
    "        npImage[ind] = npImage[200, 200]\n",
    "        kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5,-1],\n",
    "                           [0, -1, 0]])\n",
    "        # sharpen image https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "        npImage = cv2.filter2D(src=npImage, ddepth=-1, kernel=2*kernel)\n",
    "        npImage = npImage[y1:y2, x1:x2]\n",
    "        return normalize(npImage)\n",
    "    elif not preprocess:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        raise ValueError(\"preprocess must be a boolean\")\n",
    "    \n",
    "\n",
    "def get_frame(cap, frame, x1, y1, x2, y2, w, h):\n",
    "\tcap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "\tret, image = cap.read()\n",
    "\tnpImage = np.array(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\talpha = Image.new('L', (w, h), 0)\n",
    "\tdraw = ImageDraw.Draw(alpha)\n",
    "\tdraw.pieslice(((x1, y1), (x2, y2)), 0, 360, fill=255)\n",
    "\tnpAlpha = np.array(alpha)\n",
    "\tnpImage = npImage*npAlpha\n",
    "\tind = np.where(npImage == 0)\n",
    "\tnpImage[ind] = npImage[200, 200]\n",
    "\tnpImage = npImage[y1:y2, x1:x2]\n",
    "\treturn cv2.resize(npImage, (500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_selection = \"25b-25r\"\n",
    "video_selection = \"49b-1r\"\n",
    "\n",
    "system_name     = f\"{video_selection} system\"\n",
    "\n",
    "if video_selection == \"25b-25r\":\n",
    "    source_path     = \"./data/25b25r-1.mp4\" \n",
    "    xmin, ymin, xmax, ymax = 95, 30, 535, 470\n",
    "    nDrops = 50\n",
    "    save_path = './25b_25r/synthetic_trained/'\n",
    "\n",
    "elif video_selection == \"49b-1r\":\n",
    "    source_path     = \"./data/49b1r.mp4\"\n",
    "    xmin, ymin, xmax, ymax = 20, 50, 900, 930\n",
    "    nDrops = 50\n",
    "    save_path = './49b_1r/synthetic_trained/'\n",
    "\n",
    "video = cv2.VideoCapture(source_path)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Video has {n_frames} frames with a resolution of {w}x{h} and a framerate of {fps} fps\")\n",
    "_, first_frame = video.read()\n",
    "\n",
    "preprocessed_img = get_frame(video, 0, xmin, ymin, xmax, ymax, w, h)\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5), sharex=True, sharey=True)\n",
    "ax.imshow(cv2.resize(cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB), (500, 500)))\n",
    "ax.set(title = \"Original video at frame 0\", xlabel = \"X [px]\", ylabel = \"Y [px]\")\n",
    "ax1.imshow(preprocessed_img)\n",
    "ax1.set(title = \"Preprocessed video at frame 0\", xlabel = \"X [px]\", ylabel = \"Y [px]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"preprocessed_frame_0.pdf\", format = \"pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_frame(video, 0, xmin, ymin, xmax, ymax, w, h)\n",
    "segmented_image, dict_test = model.predict_instances(normalize(img), predict_kwargs = {'verbose' : False})\n",
    "n_feature_detected = len(dict_test['prob'])\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5), sharex=True, sharey=True)\n",
    "ax.imshow(img)\n",
    "ax.set(title = 'Preprocessed Image', xlabel='X [px]', ylabel='Y [px]')\n",
    "ax1.imshow(segmented_image)\n",
    "ax1.set(title = f\"Stardist result\", xlabel='X [px]', ylabel='Y [px]')\n",
    "plt.suptitle(f\"Detection -- {n_feature_detected} features detected\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + 'stardist_example.pdf', format='pdf')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize = (10, 5), sharex=True, sharey=True)\n",
    "coord, points, prob = dict_test['coord'], dict_test['points'], dict_test['prob']\n",
    "ax.imshow(img)\n",
    "ax.set(title = 'Preprocessed Image', xlabel='X [px]', ylabel='Y [px]')\n",
    "ax1.imshow(img)\n",
    "_draw_polygons(coord, points, prob, show_dist=True)\n",
    "ax1.set(title = f\"Stardist result -- {n_feature_detected} features detected\", xlabel='X [px]', ylabel='Y [px]')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + 'stardist_example2.pdf', format='pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_features(sample_frames, run_verb, save_verb):\n",
    "    if run_verb:\n",
    "        feature_properties_dict = {'frame':[], 'centroid-1':[], 'centroid-0':[], 'area':[], 'r':[], 'eccentricity':[],\\\n",
    "                                   'prob':[], 'area_bbox':[], 'area_convex':[], 'area_filled':[], 'axis_major_length':[],\\\n",
    "                                   'axis_minor_length':[], 'bbox-0':[], 'bbox-1':[], 'bbox-2':[], 'bbox-3':[],\\\n",
    "                                   'equivalent_diameter_area':[], 'euler_number':[], 'extent':[], 'feret_diameter_max':[],\\\n",
    "                                   'inertia_tensor-0-0':[], 'inertia_tensor-0-1':[], 'inertia_tensor-1-0':[],\\\n",
    "                                   'inertia_tensor-1-1':[], 'inertia_tensor_eigvals-0':[], 'inertia_tensor_eigvals-1':[],\\\n",
    "                                   'label':[]}\n",
    "        for frame in tqdm(sample_frames):\n",
    "            img = get_frame(video, frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "            segmented_image, dict_test = model.predict_instances(img, predict_kwargs = {'verbose' : False})\n",
    "\n",
    "            feature_properties = skimage.measure.regionprops_table(segmented_image, \\\n",
    "                                                                   properties=('area', 'area_bbox', 'area_convex', 'area_filled',\\\n",
    "                                                                               'axis_major_length', 'axis_minor_length',\\\n",
    "                                                                               'bbox', 'centroid', 'eccentricity', \\\n",
    "                                                                               'equivalent_diameter_area', 'euler_number', 'extent',\\\n",
    "                                                                               'feret_diameter_max', 'inertia_tensor',\\\n",
    "                                                                               'inertia_tensor_eigvals', 'label'))\n",
    "\n",
    "            for key in feature_properties.keys():\n",
    "                feature_properties_dict[key] += list(feature_properties[key])\n",
    "                \n",
    "            feature_properties_dict['prob']  += list(dict_test['prob'])\n",
    "            feature_properties_dict['frame'] += list(np.ones(len(list(feature_properties['centroid-0'])))*frame)\n",
    "        # save data\n",
    "        print(\"Saving data to dataframe...\")\n",
    "        feature_properties_dict['r'] = np.sqrt(np.array(feature_properties_dict['area'])/np.pi)\n",
    "        raw_detection_df = pd.DataFrame(feature_properties_dict)\n",
    "        raw_detection_df.rename(columns={'centroid-0': 'y', 'centroid-1': 'x'}, inplace=True)\n",
    "        raw_detection_df['frame'] = raw_detection_df.frame.astype('int')\n",
    "        raw_detection_df.sort_values(by=['frame', 'prob'], ascending=[True, False], inplace=True)\n",
    "        if save_verb: \n",
    "            raw_detection_df.to_parquet(save_path + f'raw_detection_{video_selection}_from_{startFrame}_to_{endFrame}.parquet')\n",
    "    else:\n",
    "        raw_detection_df = pd.read_parquet(save_path + f'raw_detection_{video_selection}_from_{startFrame}_to_{endFrame}.parquet')\n",
    "    return raw_detection_df\n",
    "\n",
    "def filter_detection_data(r_min, r_max, raw_detection_df, nDrops):\n",
    "    # filter found features\n",
    "    print(\"Frames with spurious effects pre filtering:\", len(np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0]), \"/\", len(raw_detection_df.frame.unique()))\n",
    "\n",
    "    filtered_df = raw_detection_df.loc[raw_detection_df.r.between(rmin, rmax)]\n",
    "    filtered_df = filtered_df.groupby('frame').apply(lambda x: x.nlargest(nDrops, 'prob'))\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "    print(\"Frames with spurious effects after filtering:\", len(np.where(filtered_df.groupby('frame').count().x.values != nDrops)[0]), \"/\", len(filtered_df.frame.unique()))\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startFrame = 0\n",
    "endFrame = 10000\n",
    "print(f\"Processing from {int(startFrame/fps)} s to {int(endFrame/fps)} s\")\n",
    "\n",
    "sample_frames = np.arange(startFrame, endFrame, 1, dtype=int)\n",
    "run_verb = False\n",
    "save_verb = False\n",
    "raw_detection_df = detect_features(sample_frames, run_verb, save_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame0 = raw_detection_df.loc[(raw_detection_df.frame == 0) & (raw_detection_df.label == 1)]\n",
    "frame1 = raw_detection_df.loc[(raw_detection_df.frame == 1) & (raw_detection_df.label == 1)]\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax.imshow(get_frame(video, sample_frames[0], xmin, ymin, xmax, ymax, w, h, True), cmap='gray')\n",
    "ax.plot(frame0.x, frame0.y, 'r.')\n",
    "ax1.imshow(get_frame(video, sample_frames[1], xmin, ymin, xmax, ymax, w, h, True), cmap='gray')\n",
    "ax1.plot(frame1.x, frame1.y, 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the result of raw features location\n",
    "n_feature_per_frame = raw_detection_df.groupby('frame').count().x.values\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize = (8, 4))\n",
    "ax[0, 0].plot(raw_detection_df.frame.unique(), n_feature_per_frame, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(raw_detection_df.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].scatter(raw_detection_df.r, raw_detection_df.eccentricity, s=0.1)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Eccentricity', title='R-eccentricity correlation')\n",
    "ax[1, 1].scatter(raw_detection_df.r, raw_detection_df.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='R-Probability correlation')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(save_path + 'raw_features.png', dpi = 500)\n",
    "plt.show()\n",
    "\n",
    "try:\n",
    "    selected_frame = sample_frames[np.where(raw_detection_df.groupby('frame').count().x.values < nDrops)[0][0]]\n",
    "except:\n",
    "    selected_frame = sample_frames[np.where(raw_detection_df.groupby('frame').count().x.values != nDrops)[0][0]]\n",
    "\n",
    "img = get_frame(video, selected_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_title(f\"Example of spurious effect at frame {selected_frame}\")\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == selected_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == selected_frame].x.values[i], raw_detection_df.loc[raw_detection_df.frame == selected_frame].y.values[i]), \\\n",
    "                                raw_detection_df.loc[raw_detection_df.frame == selected_frame].r.values[i], color='r', fill=False))\n",
    "#plt.savefig(save_path + f'example_of_spurious_effect.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax, rmin = 12.5, 6.3\n",
    "filtered_df = filter_detection_data(rmin, rmax, raw_detection_df, nDrops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(8, 4))\n",
    "ax[0, 0].plot(filtered_df.frame.unique(), filtered_df.groupby('frame').count().x.values, '.')\n",
    "ax[0, 0].set(xlabel = 'Frame', ylabel = 'N of droplets', title = 'N of droplets per frame')\n",
    "ax[0, 1].plot(filtered_df.r, '.')\n",
    "ax[0, 1].set(xlabel = 'Feature index', ylabel = 'Radius [px]', title = 'Radius of features detected')\n",
    "ax[1, 0].hist(filtered_df.r, bins=100, density=True)\n",
    "ax[1, 0].set(xlabel = 'Radius [px]', ylabel='Density', title='Radius distribution')\n",
    "ax[1, 1].scatter(filtered_df.r, filtered_df.prob, s=0.1)\n",
    "ax[1, 1].set(xlabel = 'Radius [px]', ylabel='Probability', title='Probability distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + 'filtered_features.png', dpi = 500)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_frame = sample_frames[np.where(filtered_df.groupby('frame').count().x.values != nDrops)[0][0]]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "ax.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == test_frame].x.values[i],\\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].y.values[i]), \\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax1.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax1.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax1.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "plt.suptitle(f\"Filtered detection at a frame with spurious effects\")\n",
    "plt.show()\n",
    "\n",
    "test_frame = filtered_df.loc[filtered_df.r == min(filtered_df.r)].frame.values[0]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "\n",
    "ax.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == test_frame].x.values[i],\\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].y.values[i]), \\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax1.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax1.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax1.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "plt.suptitle(f\"Filtered detection with minimum radius detected\")\n",
    "plt.show()\n",
    "\n",
    "test_frame = filtered_df.loc[filtered_df.r == max(filtered_df.r)].frame.values[0]\n",
    "img = get_frame(video, test_frame, xmin, ymin, xmax, ymax, w, h, True)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(10, 5), sharex=False, sharey=False)\n",
    "\n",
    "ax.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax.imshow(img, cmap='gray')\n",
    "for i in range(len(raw_detection_df.loc[raw_detection_df.frame == test_frame])):\n",
    "    ax.add_artist(plt.Circle((raw_detection_df.loc[raw_detection_df.frame == test_frame].x.values[i],\\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].y.values[i]), \\\n",
    "                            raw_detection_df.loc[raw_detection_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "ax1.set(title = f\"Filtered detection at frame {test_frame}\", xticks=[], yticks=[])\n",
    "ax1.imshow(img, cmap='gray')\n",
    "for i in range(len(filtered_df.loc[filtered_df.frame == test_frame])):\n",
    "    ax1.add_artist(plt.Circle((filtered_df.loc[filtered_df.frame == test_frame].x.values[i],\\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].y.values[i]), \\\n",
    "                            filtered_df.loc[filtered_df.frame == test_frame].r.values[i], color='r', fill=True, alpha=0.5))\n",
    "plt.suptitle(f\"Filtered detection with maximum radius detected\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
